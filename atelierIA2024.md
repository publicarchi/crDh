# Atelier Communs et IA

5 + Participants

Lucie Gianola, chargée de mission recherche et innovation DGLFLF. Issue du traitement automatique des langues. Thèse détection automatique d’informations dans les procédures judiciaires.

Jean-Philippe Moreux. Chef de mission IA Bnf, adapter la Bnf à l’IA. Passé ingénieur qui s’occupe diffusion de contenu numérique.

Synapse C.

Virginie, numérique et territoire, enjeux inégalités numériques. Enjeu linguistique au Qc dans une perspective communicationnelle.

Inégalités de langues dans l’environnement.

Jean-Philippe

## Corpus et Bnf

- Données, tutelles et partenaires privés.
- Travail ancien à la BNF origine projets de recherche mais aussi la numérisation. 2005 Google, et conversion à la numérisation. Utilisation IA pour nos propres activités 2011 à aujourd’hui.
- 2015, demandes de corpus textuels massifs
- 2019, identifiation enjeu établissement --> feuille de route 2019-2020. Dire que une question stratégique et pas seulement technologique.
- 2022 disruption avec l’arrivée de OpenAI et ChatGPT. S’est aperçu que pas forcément outillé pour répondre. Demande de plus en plus importante des chercheurs.
- 2023 État devenu plus pressant pour mieux collaborer avec le secteur privés pour faire émerger des acteurs opérationnels sur la langue française
  Modification feuille de route : approche bicéphale
  - profiter solutions IA pour mieux travailler
  - contribuer à la recherche et soutenir
- Sommet IA à Paris 2025

Ensemble de projets avec coloration IA. Programmes expérimentation ou recherche fondamentale.

Projets de R&D. Pas seulemnt du texte, acteurs industriels qui font émerger des modèles hybrides. Ex. INA+ INRIA Gallica Snoop. Recherche massive sur ensemble des contenus icono 2019-2020 1,2M images.

Datacatalogue v1 et 2, convention INRIA.

SCAI Sorbonne LLM chat mot pour dialoguer avec les utilisateurs et nous aider à mieux comprendre ce que cherchent les utilisateurs.

Recherche par mots clefs à production de requetes.

Extraction information structurée en une passe.

Océrisation partitions musicales.

EPITA IGN

Mistral, etc. nouvelle typologie d’acteur. Lauréat France relance 2030. Appel à partenariat culture et industrie. Projet hybride.

Comment passe d’un modèle pensé dans le cadre de l’essor des HN. Collections as data. Silos à des corpus textuels et images préparés pour des usages scientifiques pour faciliter la vie des chercheurs. Théorisés par collègues am. Ouverture des données API et corpus textuels.

Pensé dans une ambition de travail collaboratif, partenaires académiques et privés. Plus récemment démocratisation IA et IA capitalistique, continue à fonctionner mais ne satisfait pas tous les besoins. Plus les mêmes types de collaborations. Relation contractuelle avec acteurs privés. Demandent de la masse, de la données. Rôle des bib moins valorisé. Rôle des tutelles qui échappe.

Sommet de la Francophonie rappelle certain nb ambitions, pas nouvelles. Continuer satisfaire besoins spécifiques des cherchueers collections sous droits mais aussi enjeux de protection du Droit d’auteur de plus en plus prégnant.

Ex. 2022 à 2023, pb charge des infrastructures pour la demande. Gallica 50 000 usages par jours. Et APIs pour les chercheurs. Beaucoup de pression sur les portails web, limitation des usages. Gestionnaire API. = passage modèle ouvert sans limites à un modèle où voit apparaitre des ponts levis. Et ouvrir plus ou moins en fonction de qui vous êtes.

Chez nos collègues européens idem. Bib royale KBR Pays Bas janavier 2024. Arrêt moissonnage. Statement on commercial generative AI.

Déclartaion robot. Idem, radios et télévisions. PAs encore engagé. Mais impacte potentiel sur la découvrabilité. Or engagement être décourvable. Si restreint robot, idem.

Enjeux opérationnels. Quid du classifeur, quid des corpus produits. Aujourd’hui décidé avec juridique que INRIA pourrait sortir le classifier car pas un modèle génératif.

Peut-on sortir le corpus de fragments ? Contenus sous droits. Prise de risque pas possible. Le faire conserver par Huma-Num.

## Lucie

16h35

Projet porté depuis deux ans et demi. Recrutée par la DLFLF. Créer un lieu de références pour les langues de France. Rénovation château de Villers-Coterets. Lieu où signature ordonnance qui décrète l’usage du Fr dans les documents officiels. Choisi comme date. Château en ruine. Lieux dédié à la francophonie, parcours muséal sur le fr, la francophonie et langues de France.

Idée de créer un lieu qui serait une plaque tournante des technologies de la langue. Pas limité à l’IA. Une approche qui n’est pas nouvelles. TEchniques différentes qui existaient déjà. Calculatrice pourrait être une IA.

Technologies de la langue. Aujourd’hui LLM qui fonctionnent mais plus tard, peut être autre chose. Pour des raisons de technologies, de disponibilités des données. Dans certains contextes, masse de données nécessaire n’existe pas encore, où même pas numérisé. Parfois même pb de polices de caractères. Diversité culturelle et linguistique.

Constat que nbx acteurs existants en Fr, un des plus anciens labos créé dans les années 60. Par rapport à la discipline qui a princiaplement émergé dans le contexte de la traduction automatique. Rapport Alpa qui a été démenti par les technologies. Hiver de la technologies. LIMSI aujorud’hui LISON ? paris saclay.

Tissus et recherche qui existe depuis longtemps. MCC qui cherche à lui donner un coup de pouce, mettre huile dans les rouages. Bnf partenariats courants. Mais dans ma thèse beaucoup de pédagogie à faire pour expliquer ce que pouvait faire.

Moteurs de recherche, traduction automatique.

Projet Langue:IA déjà dans les cartons. Coup de projecteur qui nous a aidé pour convaincre. Mais en même temps beaucoup de pression car intérêt politique qui s’est renforcé.

Sur la question des communs, aspects culture très intéressants mais aussi beaucoup d’institutions qui produisent beaucoup de texte et de données. Et qui avant ChatGPT ne se rendaient pas compte que disposait de ces données et que pouvaient en faire qqchose.

Aimerait que leur réflexe ne soit pas de se tourner vers les acteurs qui font le plus de bruits. Un projet institution culturelle rendue compte que fonds de conférences et de podcast enregistrés pour indexer. Passage par Chat GPT problème car fonds récupéré d’une richesse énorme.

But mettre en relation ceux qui ont les dons.

Virginie. Projet intéressant et pertinent. Qu’est-ce que prendra comme forme que cela va prendre et dans les deux présentations. Question de l’exploitabilité des données. Est-ce qu’il n’y a pas là un enjeu au sens de changer la mission de certains organismes. Cas Bnf et que les données ont une valeur différente ?

Garde-t-on même mission promotion diversité linguistique

Pour la Bnf ce qui a changé par rapport aux projets de recherche tournant 2010-2020 avec ambition partenariat public privé et comme enjeu de faire émerger des acteurs européens dans la transition numérique. Ce qui a changé, sans doute inéquité d’échelle entre des acteurs dominants monopolistiques ou étatique. Institutions confrontés à des moissonnage des collections par des acteurs privés. Pas de collaboration, aspiration des contenus. Plutôt là le changement. Cette fois-ci plus tellement en position de discuter avec ces acteurs sauf à fermer Gallica.

Sur la forme de Langues IA. Un consortium de configuration constitué pour des premieres phases d’ingénieure. CNRS, INRIA et représentants du secteur industriel. Souhaite mettre en place une équipe.

Institutions qui découvrant ses données viendrait nous voir pour identifier quoi faire. Ex. le Monde diplomatique qui se demande ce que pourrait faire pour favoriser la diversité culturelle.

Autre question peut être plus large. Vient moins de l’aspect technologique. Plus politiques linguistiques. Dans quelle mesure dans tout cela est pris en compte la question des usages et des attitudes des utilisateurs dans le choix de la langue à utiliser.

Il y a-t-il dans ce type de projets une réflexion sur ce type de questions et comment prend la peine du choix utilisateurs ?

Dans langues IA dimension de médiation culturelle à destination du grand public car implanté à côté de la cité qui reçoit public. Discussion avec artistes et designer pour construction d’une voix de synthèse pour comprendre comment fonctionne.

Se souvenir que des technologies critiquables. Et possibilité de demander des comptes.

Enfants et apprentissage.

Quelque chose qui arrive régulièrement lors de l’apparition de nouvelles technologies. Exemple quand ordinateur arrivait. Possibilité de faire avancer les mentalités. Mais parfois pas même nécessaire de savoir comment fonctionne pour que n’ait plus peur. Ex. ordinateur. 

Surtout la démocratisation de ces outils là, et le fait que les gens voient ce que cela peut leur apporter.

Virginie, revient sur la question de la diversité linguistique comment fait pour que l’utilisateur puisse choisir la langue dans laquelle va intervenir.

- Recours à l’anglais par défaut ?
- Mais aussi langues minoritaires dans la langue où plus de ressources. Des études qui montrent que parfois outils disponibles mais pas langue utilisée car présume que l’outil pas efficace.

Utilisation de ces grands modèles de langue a un effet vertueux car ils sont multilingues. Modèles qui parlent plus ou moins en fr, mais services de moins bonne qualité qu’en anglais. Cherche à développer des modèles aussi effiaces en anglais et en Français.

Exemple du projet collaf, faire en sorte que puisse avoir des modèles qui soient en capacité de dialoguer avec des utilisateurs dans langue minoritaires.

Un enjeu relativement généraliser. Personne dans une langue minoritaire plus de difficultés à accéder à des contenus dans langues plus ou moins parler.

Difficulté entraîner grand modèle textuel, d’où collaboration. Mais autres bib nationale choisi de développer modèles pour langues (norvégien, suédois). Sinon personne ne le fera pour eux.

Lucie, pour aller dans le sens de Virginie, une langue pas outillée technologiquement, une langue en danger car ne peut pas l’utiliser dans l’espace numérique. Aller plus loin que question linguistique. Modèles qui parlent bien le français. Pb aujourd’hui le contenu. Ex. interroge agent conversationnel mistral, réponse carte bancaire format américain et pas fr.

Avocats et bareau, et réponses dans principe common law.

Exemple études sur la fracture numérique. Un temps où seulement angle de l’accès, depuis décalage vers les usages et motifvations usage du numérique. Mais aussi bénéfice.

Synapse C, travaillent beaucoup sur l’aspect découvrabilité des contenus culturels. Enjeux que beaucoup d’institutions disposent de données, souvent mal ou pas structurées. Par ailleurs travail en cours avec le gouvernement du Qc pour disposer d’un référentiel commun en culture.

Travaillent actuellement sur la possibilité d’enrichir les données en culture en les reliant entre elles. Par exemple, travaille beaucoup sur les arts de la scène. Possibilité d’enrichir les œuvres à partir des informations. Utilisation de l’IA pour extraire des métadonnées sur des contenus écrits. Dossier sur lesquel réfléchir beaucoup et souhaite travailler d’avantage.

Plusieurs freins qui peuvent se présenter. On sait que les organisations culturelles ont pour beaucoup des budgets limités qui rendent parfois compliqué le financement de telles initiatives.

Rapidement se pose évidemment la question de la propriété intellectuelle. Le sujet préoccupe beaucoup les organisations culturelles. Autre enjeu qui revient beaucoup, celui de la peur d’être remplacé et peur que peuvent avoir les gens en général de l’IA. Contrairement à la Révolution industrielle où changements liés à la main d’œuvre. Ici travail intellectuel qui se trouve challengé. Même si pour le moment reste limité.

Des défis sur lesquels se penchent aussi beaucoup, celui de la billeterie. Information sensible que ne souhaite pas non plus offrir directement aux acteurs du privés. Beaucoup de recherche sur les différentes politiques des outils d’IA sur lesquels peuisse s’appuyer pour amliorer nos outils de production. Avace mais naturellement un sujet qui nous intéresse beaucoup.

Autres avenues que souhaite explorer. La capacité de faire de la validation de traiteemnt de données. S’assurer que les données fournies par les clients soient de qualité. Que rapidement puisse lever un drapeau si données pas complètes ou problématiques.

Enfin sur l’enrichissement de données. Sûr que quand on travaille sur beaucoup de contenus. Entraîner les moteurs pour mieux traiter les données mises à disposition mais aussi améliorer les algorithmes de vulgarisation. 

Exemple en musique, des informations basiques. Ne va pas beaucoup plus loin. Si prend l’exemple de netflix. Voit que permet d’aller plus loin, voir quel sujet traité. Ex. sujets taggués LGBTQ. Possibilité de cibler ces personnes et conversion possibles.

Industrie en manque de ressource. Un outil en capacité d’augmenter la productivité des travailleurs et réduire coûts de communication. Mais réclame investissement de départ. Potentiel important.

## Discussion

Manque d’outils numériques qui me fait faire une thèse sur le sujet. Souvent gens débordés, donc très difficile de produire des données pouvant être partagé, pas seulement manque de volonté. Tt question manque du public. Ensemble culturel, collections, n’intéressait pas les personnes. Quand parle de type de données, de quoi parle-t-on ?

Des données de différentes nature. Travaillent surtout sur les données d’usages, données d’usagers, personnelles, achat. Mais il y a ussi les données descriptives. Les deux grands types de données sur lesquelles travaille. Parfois joue aussi avec des données comptables.

Camille, web sémantique. Comment relie technologies avec l’IA ? 

Intéressant car vraiment une période transitoire. Un outil qui va probablement beaucoup changer la façon dont les recherches pourront être faites sur le web. Avec les modèles linguistiques va pouvoir dépasser ce référencement mécanique pour aller vers un référencement naturel. Sans doute possibilité améliorer référencement grâce à ces technologies.

Possibilité extraire texte dense et en compréndre son essence. Exemple 100 œuvres et faire ressortir les trois thèmes majeurs pour en faire une table de métadonnées référentes.

Utilisation sémantique pour enrichir.

RAG très à la mode. Principe d’un grand modèle de langue. Entraîné sur un corpus. Aller récupérer de la connaissance.

Nathalie, est-ce que serait une manière. Vu que LLM capables de produire du Fr, possibilité de produire des corpus de contenus complémentaires. Comment améliorer la pertinence culturelle et géographique de ces modèles. Vers quelles pistes aller pour résoudre enjeu de la pertinence.

Corpus synthétique pour régler plusieurs pb. Manque de ressources pour aspects locaux mais aussi personnels. Pour versions B en gardant les schémas statistiques.

Aujourd’hui gd modèles entraînés sur 4 ou 5% de français. Peut déjà tenter de donner plus de Fr pour accéder à une meilleure connaissance du substrat culturel. Peut tenter interroger pas seulement base apprentissage mais autres bases de données.

Question des licences. Communs. Pour les institutions patrimoniales. Institutions culturelles pas des détenteurs de droits. Régit pas le code du patrimoine culturel. Pb qui se posent surtout sur des corpus sous droits. Pas capacité de répondre sans risque.

Avant pouvait dire que acteurs publics. Avait le cadre réglementaire pour répondre à cette typologie de demandes. Mais production pas des modèles de langue mais des résultats de recherche. Pas des grands modèels. Entités nouvelles pour le cadre réglementaire. Car ni algorithme, ni base de données. Pas vraiment anticipé par l’exception TDM? à notre avis.

Modèles hybrides, modèles nouveaux. Attend qu’émerge modèle réglementaire stable. Engagé à travailler ce sujet avec INRIA. Mais au moins expliquer cas d’usages et cas d’usages privés.

Nicolas. Pendant ce temps les acteurs privés s’approprient le contenu. Et si arrive plus tard, il sera trop tard.

JFM déjà pris. Voit les traces pour autant faire des propositions. Dire ce qui se passe. Parle d’OpenAI mais aussi pt startups. Aussi enjeux accessibilitépour les personnes en situation de handicap.

Nbx projets portés aussi par des acteurs intéressants.

Discussion convention wikifrancophone.

Des pistes d’actions qui vont dans le même sens quand regarde ce qu’a fait wikimédias pour négocier avec des géants de la tech les termes de la relation. Ex. Bnf s’en va vers ça avec le contrôle d’API. Avoir des grands acteurs pour controler usage. Comment dans le même temps partenariat peut permettre de développer des outils et des services qui bénéficient à d’autres acteurs publics ou de plus petite taille. Comment s’en servir comme levier pour outil des secteurs qui ne sont pas prioritaires.

Législatif mais aussi technique. 



## Questions

Question fouille de données et exception TDM

Importance prise par les acteurs privés dans ce domaine. Dans le cas de la Bnf, cf. Bnf Partenariat.

- Comment garantir un égal accès aux corpus etc.
- privilége commercial
- en quoi peut entre en contradiction avec intéret ouverture.

Quelles contradictions.

Exception TDM. Demande des chercheurs. Prise de risque.

Licences IA

**Technologies de la langue**

**Création de commun numérique**

- gestion, etc



Acteurs privés

Human in the loop

Communs numériques et gestion des données