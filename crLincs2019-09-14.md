# LINCS Meeting 14 septembre 2019



5 min presentation

**The “Paris guidebooks” are some of inevitable sources for art history of the XVII and XVIIIth centuries.** This project is leaded by Marianne Cojannot Leblanc within the cluster of excellence Pasts and Present, in collaboration with Bnf and Modyco’s research team.

The Paris Guidebooks project **consists to numerize a textual corpus, to edit it in XML-TEI, and to apply a semantic annotation in the aim to expose it in the Linked Open Data**. 

One of the stakes of the corpus instrumentation lies in the ability to **take full advantage of the huge numerical resources today availble in art history**. 

### Corpora

### Use of the Text Encoding initiative for text structuration

Named entities (persName, orgName, placeName, objectName) are marked in the corpora.

The **indexing of the content is a huge task** as the corpora can be seen according to many perspective (general historic information, topography, history of art, taste, etc.). We choose **to engage in a collaborative process for indexing** that benefits from the opportunity of Linked Open Data.

In effect, most of our entities are already described by cultural institution.

Indexes are described with the names and dates TEI module. It does a pretty good job for people, and globally for places (mostly enough for us) but the situation is more complicated for works of art. We are using the new objet element that was introduced recently. But it’s current content model doesn’t fit our objects.

Currently simple identification information with links to available sources as LOD. But we plan to move forward a deeper description **to build a patrimonial parisian Gazetteer**.

Choices of representation informed by CIDOC-CRM (as the ontology used by the Labex ModRef project).

Use of BaseX and a lightweight publication framework we’ve developed with colleagues in TEI. Conception oriented to publish content as a textual API and content negotiation.

- TEI mapping
- XQuery mapping (we wanna create)

Data Sample



## Peter F. Patel-Scheider, Knowledge Representation and LINCS

Spécialiste du web sémantique. Pas un spécialiste du monde culturel. Mais intéressé par la manière dont utilise les choses que développe.

Chercheur de longue date dans la représentation des connaissance, logique descriptive (sous-jacente OWL). Il a conçu une grande partie de OWL Web Ontology Language.

Travaillé dans la Silicon Valley.

Caveat, opinion personnel, ne connaît pas le domaine, ni quels sont réellement les problèmes.

Promouvoir expertise, culture investigation. Dissemination des connaissances. Aimerait tous que les connaissances que vous développez par exemple soient accessibles sur Wikipédia.

- utilisation de techniques de représentation de connaissances
- comment disséminer ? utiliser langages et ontologies existantes et se connecter à de larges entrepôts de données : Google Knowledge Graph, Amazon, IBM, Ebay... mais sans doute pas vraiment ce que l’on cible.
- Quelques dépôt publics : Linked Data Cloud, Freebase, DBpedia, Scham.org, Wikidata. Probablement pas aussi vastes que le Google Knowledge Graph, mais Google KG ingère à peu près tout.

Ontologie de DBPedia très limitée. Mais aussi Wikidata projet de la fondation Wikimedia, connexion avec autres projets. Un graph de connaissance, pour l’essentiel répertoire de faits.

**Wikidata**

Projet de la fondation Wikimedia

Connexion avec Wikipedia et les autres projets de Wikimedia

Un Knowledge Graph

- triple facts
  mais plus que ça
  - ranks (faits peuvent être dupliqués)
  - qualifiers
  - references
- Simple ontology language (similaire à RDFs)
- Constraints

Nombreux outils : éditeur de faits, vérification de contraintes, exportations, etc.

Wikidata propose plusieurs catégories : Human et Personne. Description pour distinguer (un pb). 

Un projet multilingue

https://www.wikidata.org/wiki/Q215627

https://www.wikidata.org/wiki/Q5

Exemple Berlin et quantité d’information disponible sur cette ville.

Exemple de Ship type questionnable

Couleur et problèmes de taxonomie.

Pas vraiment du RDF, des pb.

Le travail

- trouver bonne manière de représenter l’information culturelle qui corresponde à Wikidata. Peut-être mapper vers Wikidata.
- écrire logiciels pour représentation connaissance.
- Trouver bonne manière de dire les choses, et le faire

D’autres l’un fait. GLAM. Mais peut vouloir être un peu meilleur. Ontologie de Wikidata pas géniale ni bien intégrée. Beaucoup de qualifiers, peu de temporels.

Faire partie de leur communauté.

Exploiter tous les aspects représentationnels de Wikidata

Créer infrastructure locale

Créer des bonnes pratiques

Powerful ontologies = inférences, description. Mais trouver voie qui permet d’y arriver. D’abord construire choses. D’abord avoir taxonomie.

Avoir bonne représentation pour LINCS, dissémination aisée de l’information. Améliorations de Wikidata.

Build a logic for Knowledge Graphs (incluant Wikidata), comment formaliser ce contenu de manière à ce que puisse faire des inférences. Pour le moment pas encore dans Wikidata.

Construire les raisonneurs pour cette logique.

## Discussion

Enjeu en humanités pas tant de savoir quels sont les faits, mais plutôt de les remettre en perspective.

Avec références Wikidata représente choses rapportées par telle ou telle source.

Question sur l’utilisation de Wikibase, peut supposer que vient avec une certaine structure de données (par une structure ontologie). Ensemble d’ontologies que peut créer autour de ce modèle de données qui est très neutre. Outils pas construits sur wikibase mais autour de wikibase. Rapports parfois plus complexes. Beaucoup de flexibilité qui permet de dire ce que veut faire comme communauté.

Wikidata 26000 personnes, mais sans doute seulement une centaine de personnes qui gèrent le projet.

Là où sans doute pas bien fait, beaucoup de travail sur les classes linéennes (espèces, etc.) puis ajouté classes OWL, etc.

Communauté, discuter de la manière dont le travail conduit dans ce projet peut être utile pour le projet.

Wikidata projet philosophie de Wikipédia que gens ne dirigent pas sur manière de représenter les choses. Groupes différents ayant notions différentes. Manque peut-être un peu de contrôle central.

## Présentation

Susan, frustrée par le fait que les choses ne dialoguent pas les unes avec les autres. Volonté de connecter les données que nos communautés ont créé.

Brésilien Victoria. Projet ambitieux, mais faire des compromis. Aime le fait d’habiter dans un pays good enough.

Partenaire européen. Read London.

Connie.

Collègues travaillant sur visualisation réseaux artistiques.

Geoffrey Rockwell

Laura Mandell

## Project overview

Importance contacts personnels et rencontres physiques pour se connaître. Balance entre communauté servie et techniciens. Faire en sorte que gens comprennent les préoccupations des autres.

Créer des débats sur des questions qui importent. C’est la raison pour laquelle nous avons introduit dans le programme des provocateurs.

Confirmer l’agenda du projet et de définir les composants qui peuvent commencer rapidement.

Partager vos lumières avec autres membres.

https://tinyurl.com/lincsnotes

/#lincsproject

LINCS will convert, enhance, mobilize, link, and make accessible existing datasets, and thereby enable research on the vast and heterogeneous body of data relevant to human culture, history, and knowledge, both in Canada and throughout the world.

Restructuration prévue par le gouvernement libéral. Sans doute dernier financement. Projet court 3 ans. 6 universités impliquées. 5M de financement. 8 partenaires créateurs. 48 recherches et équipes techniques.

Envisage formation de 200 personnes HQP

Projet qui bénéficie de logiciels existant mais qui va aussi probablement donner lieu à la création de nouveaux logiciels.

Compute Canada Cloud, pour hébergement. Dans le contexte réorganisation occasion mémo avoir ce dont nous avons besoin.

Formations (DHSite, DH@Guelph, DHSI). Conférences. Documentation.

https://www.uvic.ca/humanities/english/people/regularfaculty/jenstad-janelle.php

https://www.library.yorku.ca/web/about-us/contact-us/librarian-archivist-profiles/sacassin/

Projet lancé le 1er janvier 2020

Postes de directeur exécutif et de directeur technique.

LOUD Linked Open Usable Data !!

comment utiliser les données de manière à respecter les différences.

Janelle Jenstad, https://www.uvic.ca/humanities/english/people/regularfaculty/jenstad-janelle.php

The Map of Early Modern London, cf. https://mapoflondon.uvic.ca

## Questions de recherche

Problématiques de représentation.

Repositionnement des sujets en rapport à la justice sociale. Type de représentation, de son périmètre mais aussi question de l’accès ouvert et de la participation du public. Il y a des opportunités dans ce projet pour aborder question représentation.

Si pense les choses comme humanistes, pensez-vous vraiment que les ontologies le moyen pour gérer la complexité ? car finalement toujours une simplification. Comment faites vous avec cette tension.

Projet diffère des projets habituels au sens où sans doute moins proche de la spécialité. Besoin de penser les choses à un niveau global. Sans doute besoin précisément d’avoir des retours sur le fait qu’a réduit ou pas les données. Sans doute besoin d’un financement de recherche pour explorer cela. Parvenir à de nouvelles réponses sur les SameAs, voir comment fonctionne à travers des jeux de données. Les ontologies sont bonnes dès lors que travaille dans un domaine, mais dès qu’aborde identité, devient un pb. 

Mettre en rapport avec les fake news, voir rapport avec l’ontologie. Gens qui font des déclarations en publics, nombre de personnes pas les outils pour évaluer ces prétentions. LOD une manière de suivre les liens. Cf. Orwell anticipe le téléphone portable : est-il possible de suivre le lien. Question autorité de l’archive. Quid de l’autorité FCI qui donne beaucoup d’argent.

Wikidata une ontologie croudsourcée. Wikipédia marche car beaucoup de gens voulant la modifier. Pas le cas de Wikidata et un de ses problèmes principaux.

Change, augmentation, disclaiming autorité.

Est-il possible de unlinker ? Dépend si parle de statement ou pas.

## SIMSSA

Single Interface for Music Score Searching and Analysis

CRSH/FRQSC financement

Contenu

- Rodan Gamera, Aruspix
- IIIF
- Verovio
- Early music (copyright et aime)
- Gradsourcing to correct errors

Search and analysis,

- MEI Music Encoding Initiative
- Diva.js (based on IIIF)
- Musiclibs
- SIMSSA DB (Formerly ELVIS)

Reconnaissance optique. 

OMR au centre... partenariat avec bibliothèques

Optical Music Recognition OMR

## Ontology bootcamp

Deb Stacey

Définition A shared conceptualisation

Keeping it simple. Would you make a distinction between taxonomy and ontology. Cf. Steve this morning.

Impossible to have completeness ? Domain ontology. Which part of the world are we covering ? **How would you define our domain ? What is our community ?** Has a data provider, which part of my research should be involved.

What about using only schema.org if our objective is discoverability ? Wouldn’t it be enough ? People would only have to look at our content ? why do you wanna make it machine processable ?

How do you place the issue of reuse according to the specificity of a done project.

Ontology aide identifier nature des choses mais peuvent aussi vous empêcher de voir les choses dont elles ne rendent pas compte. Perte de nuance.

Reasoning ? inference, but on what would we like to reason ? Technics you said that doesn’t scale very well. Garder simple.

Wouldn’t it be better to stay in the only field of literature ? and even there, as literature speaks of everything, is it really possible ? What would be the benefits ?

- Satisfactability
- Subsumption
- Consistency
- Check individual
- Retrieval of individuals
- Realization of an individual

I don’t understand anything about ontologies. how does sharing an ontology can help me. **Search and inference for who ?** SPARQL, do you think every body should learn it ? Is the issue technical or the difficulty is more in relation to the domain

**Foundational ontology** build on top of them. Superset ex BFO, Dolce, CIDOC, GFO, SUMO

BFO Basic Formal Ontology très objective développée pour biologie.


Question savoir si peut prendre partie ontology. Dépend de ce que prend. Si prend ontologie fondation tout doit être construit à partir d’elle.

**CIDOC conceived for alignment. How much does this should impact my project, or the things I’m doing**

Dynamic ontologies. Embrasser le changement plutôt que lutter contre. Data drive. Laisser le domaine développer le secteurs. Pas vraiment versionning.

Ontologie qui oblige à être explicite sur ce que documente. Où au moins être clair sur ce que documente.

Peut être que ne pourrait pas arriver à s’entendre. Mais pour nous dans les humanités la partie la plus difficile. Car beaucoup lié à la formulation.

Si parvient à montrer les choses à échelle suffisante alors qqch. Si n’essayer pas alors signifie que dans notre bac à sable.

**Appart form the entities description, does our TEI data are really subjected to be express as RDF ?** Which part of our information should precisely be shared. 

Ontology SIG failed many time. Reason, different perspective. 2 reasons : or note the objective of TEI or wouldn’t it be better to have something else than the TEI ?

Is there any chance that ODD could be useful here for us ? How to transform content model, include names dates module

## Storage and Publishing Platforms

Stacy and Lisa) + discussion

Penser où le projet doit résider par rapport à la communauté. Ne peut se contenter d’extraire des informations. Faire en sorte que le projet soit aussi réciproque.

Ne peut seulement considérer comme ontologie quelque part. Mais sinon comme si outsider venant utiliser les contenus.

WikiClub, GLAM Sumit à la Gallery Ontario

Une communauté distincte de Wikipédia, un gout différent.

Grand nombre de bib. Bibliothèque de Wales première résidence

Nombreuses bibliothèques liant leur données.

Utilisation Wikibase

- LinkedJazz
- Enslaved
- German National Library
- Wiki fact
- Rhizome
- Lingua Libra
- OCLC Report publié mais sans code ou tutoriaux.

## Wikibase

Si choix de Wikibase, bien considérer que va contraindre notre travail.

Question long-term preservation. Pas format standard. Dump, et possibilité importation.

Question réification. Manière d’assigner identifiant à une déclaration pour pouvoir y faire référence. Alors peut parler de sa certitude, sa provenance. Predicats deviennent des propriétés des déclarations.

Quad représentation très neutre. Pb savoir si un fait sur le monde ou ... alors si ne sait pas cause pb.

Dans Wikibase, toutes les déclarations pas les faits, mais les statements sur les faits. 

Hernandez et al 2015, pour réification pas de différence efficacité.

De quoi avons nous besoin ? quality factor ? logique de haut niveau ? etc.

En tous les cas besoin de pouvoir dire des choses sur des statements.

Facile de créer des ontologies, etc. En tous les cas un modèle de donnée lié au logiciel et être conscient que des limitations, etc.

https://www.mediawiki.org/wiki/Wikibase/DataModel/Primer

https://www.mediawiki.org/wiki/Wikibase/DataModel

Blazegraph SPARQL endpoint

https://www.blazegraph.com

http://tinkerpop.apache.org

Wikidata VizQuery

Search and Visualization Tools

Gremlinator, http://jens-lehmann.org/files/2018/grades_litmus.pdf

Collaboration avec Diffbot

Partage code qui permet de créer notre KG. De même utilisation modèles Knowledgenet (comme ImageNet)

Utilisation de Spacy pour reconnaissance des mots

# LINCS 15 septembre 2019

HuViz

Nerge

Spyral un effort pour prendre elles fonctionnalités de Voyant et permettre à des utilisateurs de faire du codage en ayant accès à l’arrière du moteur de voyant dans le contexte de littérateur programmant ou code et texte combiné.

Continuation du travail conduit avec rhetotica et effet rhétorique. Donal Knuth.

Projet actuel plus focalisé sur la question de réplication en termes d’archéologie des médias. Recréer moments du passé avec l’analyse de texte.

Exemple pour avoir world cloud des entités nommées, possible générer listes et l’injecter dans un nuage de mots.

Jupiter notebook collection pour l’analyse de texte. 

Pourquoi un nouveau carnet

- zero setup comme pour voyant seulement visiter la page
- domain specific text mining in DH
- leverage voyant, common tools et visualisations disponibles
- javascript-based. You can get dangerous fast !
- pedagogical commons. Sharable are discoverable

Essayer de créer un environnement moins intimidant. Aborder seulement l’analyse de texte. Javascript-based même si aime Python, javascript plus facile à utiliser et plus rapide à apprendre pour devenir dangereux. Par ailleurs transférable dans word press et ailleurs.

Arrière plan html, donc si un fichier sur le disque peut l’ouvrir dans n’importe quel navigateur.

## WordPress for LOD

- csv import
- custom domain model
- taxonomy support
- full-text indexing
- rdf export

à partir de fichiers de tableur.

LGLC Prosopography

https://prosopography.lglc.ca





Access tool

- Question of copyrights
- Who can access what they want

