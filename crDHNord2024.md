# DHNord 2024

https://journees-dhnord2024.sciencesconf.org/resource/page/id/6

## Atelier PictorIA

### Panel: Innovation, traitement et visualisation des données multimodales et médiation culturelle en SHS

*Modération: Philippe Useille (Université Polytechnique des Hauts-de-France (UPHF) - MESHS)*

*Julien Schuh (Université Paris Nanterre - MSH Mondes)*

Collaboration avec DHNord qui permet à PictorIA d’organiser une journée. Remerciements des acteurs. Quelques mots sur le consortium PictorIA. Consortium Huma-Num dédié à l’analyse automatique des images par l’utilisation d’outils de traitement automatique des images.

Après période de numérisation massive des archives, face à des difficultés pour traiter humainement ces informations. Désormais des outils développés permettant d’industrialiser les processus cognitifs pour apréhender ces documents. Mais outils principalement développés dans des perspectives commerciales ou ultra-contemporaines. Or travaille sur des données anciennes, souvent déteriorées, images anciennes d’objests ayant subis différentes dégradations. Pb d’absence. Mais aussi le contenu même des contenus que nous travaillons situés dans une histoire ancienne. Et souvent modèles entraînés sur des contenus contemporains ou dans lesquelles les données anciennes perdues. Conduit à des faux positifs. 

Créer une communauté de gens intéressés sur ces questions. Mais besoin de se former ou de réentrainer les modèles pour répondre à leurs propres enjeux de recherche. Essayer de créer des standards ou des pratiques communes. Perte d’efficacité ou risque de créer des standards ne pouvant communiquer ensemble. Ex. IIIF. Sait que doit réfléchir collectivement à ce que veut faire de ces outils.

Site du consortium, cartographier ce qui existe. Sélectionner certain nombre d’outils, les mettre en avant.

https://pictoria.hypotheses.org

#### La recherche en SHS au sein de la Fédération de Recherche Sciences et Cultures du Visuel (FR-SCV)

*Yann Coello (Sciences Cognitives et Sciences Affectives (SCALab) / FR-SCV)*

https://fr-scv.fr

https://fr-scv.univ-lille.fr

>En favorisant les échanges et les interactions entre les UMR CRIStAL, IRHIS et SCAlab (CNRS/Univ Lille), la **Fédération de Recherche Sciences et Cultures du Visuel** (FR CNRS SCV 2052) coordonne un programme scientifique pluridisciplinaire visant à étudier, à l'aide des équipements numériques de pointe de la plateforme Equipex Continuum, les processus visuels et les cultures visuelles dans les sociétés passées et contemporaines. Par l'implantation de la FR SCV **au cœur du site d'innovation Plaine Images**, les chercheurs et ingénieurs développent des projets de recherche interdisciplinaires en collaboration avec les artistes et les Industries Créatives et Culturelles.

Projet né d’un 

FR CNRS 2052 Sciences & Cultures du visuel. Société Vanoutryve fermée en 1973. Métropole qui a voulu créer nouvelle dynamique autour de l’image. Autour de 2000. Inauguration Plaine Images, 2012.

Créer un lieu de rencontre interdisciplinaire qui s’appuie sur les outils numériques dans le champ des industries créatives et culturelles. Travail avec trois UMR. Laboratoire **IRHIS** (histoire et histoire de l’art, culture visuelle), Laboratoire informatique **CRIStAL** (sciences du numérique, IA et modélisation), **SCALab** Sciences cognitives et sciences affectives.

Développer un programme de recherche interdisciplinaire pour étudier les manifestations visuelles du passé et contemporaine. Installation dans les bâtiments de l’Imaginarium sur le site de Plaine Images qui accueille 150 entreprises. Développement d’une plateforme technologique labellisée équipex. En relation avec les entreprises de Plaine Images.

Labellisation 2012 Equipe, renouvellement en 2021 dans le cadre de l’équipex Continum qui constitue un réseau de plateformes de réalité virtuelle. Devenus infrastructure de recherche en 2022 pour RV. Relation avec le Fresnoy, école d’art. Artistes en résidence. Picture école modélisation 3D. Artfix, effets spéciaux.

Accueil d’entreprises en résidences, etc. Débute en 2010, en travaillant dans un RTP réseau thématique pluridisciplinaire financé par le CNRS dans la dynamique IRIS. Lauréat équipex en 2012 6M, développement projet autour des Visual studies. Puis obtention CPER 2 à 3M sur 7 à 8 ans. Permet d’animer la recherche sur du temps long avec des projets larges qui incluent de nombreux partenaires. Projets très utiles pour la structuration de la recherche.

CNRS a accepté de nous créer en tant que structure indépendante. Fédération de recherche en 2021. Nouveau projet Continum et nv CPER. Projet COMET sur le métayers ciblé à Lille sur la fédération 2023 (lancement 17 janvier 2025). Projet régional.

Projets qui permettent de travailler sous la forme d’appel à projets et de financements pour accéder aux équipements. Appels à projets, résidences d’artistes, thèses, etc. Formations déterminantes sur des thématiques concernant IA. Générer des dynamiques utiles pour associer les chercheurs et les entreprises.

Plusieurs axes

- construction historique du visuel (Elise Baillieul https://pro.univ-lille.fr/elise-baillieul/enseignements)
- perception cognition en environnement numérique
- modélisation visualisation interaction (données complexes, multimodales, environnement virtuel)
- arts sciences et technologies

100 chercheurs, 5 titulaires et 11 ingénieurs sur contrat. Pas pérenne car surtout financés sur appel à projets. 

Essaye de créer une chaîne d’ingénieurie spécialisée.

Fil rouge compétences

- historiens spécialisés dans la restitution numérique
- infographistes 2D-3D
- Modélsiateur 3D
- Animateur 3D
- Interatcion homme-machine
- Traitement du signal
- Valorisation-transfert

Occulométrie. Restitution numérique de sites anciens disparu. Exemple Camp du drap d’or.

Mise à disposition présentation visuelle utilisant les outils numériques incitant à l’interaction. 

Partie analyse du comportement. Nombreux équipements classiques en sciences cognitives permettant de projeté à haute qualité. Casques avec bonne définition visuelle, etc.

Dispositif TORE, courbe dans toutes ces dimensions. Qualité immersion forte par rapport aux faces des CAVE qui créent des disruptions visuelle. Système de doubvle point de vue. Permet étudier des situation où des personnes doivent interagir sur le même objet.

Tapis de marche pour visualiser des environnements virtuels pour se déplacer dans un site archéologique ou historique. Évite l’utilisation de manettes qui créent inconfort.

Big Blake

Well, expositions de Whistler (Isabelle Enaud-Lechien)

Recontext, restituttion site des tombes. Restitution des peintures en place. Formats très dégradés. Reconstitution du mobilier funéraire. Des hypothèses faites par les chercheurs à partir de mobilier de la même époque conservé à Lille.

Travail sur les rites funéraires.

Projet Get-in-Past. Représentation des danses anciennes à partir de documents anciens. Numérisation des documents avec Computer vision. Reconnaissance automatique puis animation en modélisation MOCAP motion capture pour faire de la médiation culturelle.

Projet qui fait travailler les trois laboratoires au sein de la fédération. 

Rencontre chercheurs et artistes autour création. Interopérabilité des systèmes comment regrouper outils visualisation : Unity, ... engine, dans outils utilisables pour les artistes. Dessin 3D dans un espace numérique. Création visuelle et sonore. Des systèmes différents associés.

#### Discussions et échange avec le public

Effet proteus concernant impact des agents virtuels.

Des projets concernant le droit du numérique avec Juliette Sénéchal. Questions des responsabilités et des accès. Responsabilités.

Pas de travail sur la génération automatique de scènes 3D à partir de scènes 2D. Question du stockage des données et de leur mise à disposition. Cherche à travailler avec Huma-Num pour la formalisation de certains standards de modélisation 3D. Veulent constituer centre d’expertise sur cette question. Pour la génération automatique, pas encore abordé. Des questions importantes car limites des ingénieurs.

Idée du dernier projet un peu cela, créer une plateforme permettant à des artistes de se connecter à n’importe quel environnement pour interagir avec cette plateforme.

Commencé à travailler avec [Houdini](https://www.sidefx.com/products/houdini/) pour certaines restitution automatique de ville. Pour pouvoir se concentrer sur les bâtiments pour lesquels dispose de sources.

Comment se passent les partenariats. Faut-il arriver avec un projet.

Laurence Parrot, coordinateur institutionnelle. Engage à la contacter pour des projets. Si sciences et culture du visuel peut accueillir. Ensuite voir ce que représente en termes d’investissement. Si projet simple sans trop de développement et surtout accès aux équipements facile. Si plus complexe doit travailler avec les ingénieurs. Projets sur appel à projet plus de chances d’être retenus.

### Panel: Vision par ordinateur

*Modération: Daniel Foliard (LARCA – Université Paris Cité)*

#### Projet ERC Discover

*Mathieu Aubry (Ecole des Ponts ParisTech (ENPC))*

https://erc-discover.github.io

https://aikon-platform.github.io

Diplômé Poly, Ingénier des Ponts et Chaussées. Chercheur au laboratoire Imagine école des ponts.

Chercheur en vision artificielle et non en histoire. Le projet sur lequel travaille le plus consiste à faire qqchose assez natruel pour les humains, regarder ensemble d’images et repérer ensemble de choses cohérentes.

Lorsque regarde images satellites, identifie rapidement des éléments récurents. Construire des algorithmes de vision artificielle pour faire ce genre de choses.

Travail débuté sur des enjeux d’histoire de l’art où besoin de détecter des choses semblables. Pas forcément des choses qui aient des noms. Avec des historiens des sciences, pouvoir trouver des copies dans des manuscrits. Ensemble de textes modifiés au cours du temps, ensemble de choses parfois modifiées ou recombinées. Analyse visuelle de texte, si exemple de différents documents formes élémentaires qui sont des lettres que pourrait vouloir comparer entre docuements.

Comment avec des outils de vision artificielle avancer en paléographie. Présentation plateforme à destination des historiens qu’est actuellement en train de construire pour intégrer différents outils d’IA pour comparaison, etc.

Pour l’analyse de texte, avoir un algorithme qui va essayer de découvrir l’alphabet, formes des lettres et reconstruire différentes formes de textes. Positionner lettre à différents endroits et donner couleurs. Apprend prototype des différentes lettres que peut ensuite comparer ou visualiser. Exemple alphabét chiffré. 

Ce type d’analyse permet de faire de la paléographie. Exemple développé dans le cadre d’une thèse. Collecte d’un ensemble de ms avec deux types d’écriture standards, Textualis du N et du S. Et comparaison avec ce qu’en disent les paléographes. Voir sur plein de ms différents alphabet.

Ensuite prototypes que peu comparer et analyses confrontables. Permet aussi de faire des analyses plus fines sur certaines lettres au niveau d’un corpus.

AIKON platform. Construite à partir de deux projets menés ces dernières années : ANR VHS et ANR EIDA. Objectif d’étendre l’utilisation de cette plateforme pour continuer à ajouter des outils dedans. Exemple détection illustrations, plateforme de similarité.

Permet d’ajouter des documents avec métadonnées, possibilité extraire illustrations contenus et de les visualiser. Exemple ms botanique. Possibilité de changer notion de similarité. Possibilité d’annotation des similarité.

Projet EIDA pour les diagrammes astronomiques. Besoin extraire les primitives géométriques de ces diagrammes. Idée de pouvoir comparer les diagrammes et de faire des éditions critiques en comparant ces diagrammes.

Plusieurs algorithmes présents dans cette plateforme. Manière dont sont conçus. Dans tous les cas, travail avec les historiens pour comprendre les besoins et formaliser la tâche qu’ils ont besoin de résoudre. Nombreuses notions de copie différente. Besoin d’aller chercher des exemples. Première chose faite. Ensuite générer des données synthètiques pour produire premiers résultats suffisamment bons pour être corrigés par les historiens par des annotations pour améliorer le traitement.

Réalisé sur 4 problématiques différentes : détectiond ’illustrations, la recherche de similarité, la vectorisation de diagramme, la reconnaissance de textes (à inclure). 

Génération de données synthétiques. Pas nécessairement besoin d’être réalistes. Possibilité d’apprendre copies et éléments entre les deux. Ensemble qui permet de générer des algorithmes fonctionnant sur différentes tâches.

Certains nombres d’algorithmes standards IA. Mais pour découverte formes identifiques dans des gd bases de données. Pas de solutions std. Nbx problèmes que HA ont qui peuvent se ramener à ça.

#### L’IA et les données de Notre-Dame de Paris: de la théorie à la pratique

*Kévin Réby et Anaïs Guillem (ERC n-Dame_Heritage, Modèles et simulations pour l'Architecture et le Patrimoine (MAP) - CNRS)*

Architecte archéologue de formation, formée sur les questions de représentation de connaissances. Termine doctorat à Munich. Données complexes, hétérogènes et intégration de données. Comment transforme de l’information et de la connaissance en utilisant des ontologies. Questions spatio-temporelles, argumentation et hypothètiques. Vocabulaires, etc. IA neuro-symbolique.

Kévin Réby informatien, spécialisé en deep learning. Dès que nb données et label peut faire plein de choses, classifications, etc. Intéret de pouvoir travailler avec des experts. Exploiter puissance Deep Learning et IA peu classique que va présenter.

Projet ERC, complexe dense avec 10aine de groupes de travail thématiques. Structure, bois, accoustique, décoration, etc. qui regroupent 200 chercheurs produisant des données hétérogènes avec des modèles différents et des problèmatiques distinctes. Gros enjeux d’intégration de données. Idée de voir comment utiliser l’IA pour intégrer tout cela.

Exemples d’interogénéité des données. Outils Aïoli basé sur la photogrammétrie. Outils qui vient être complémenté ArchéoGrid pour archivage. OpenTheso pour les vocabulaires.

Question de l’interopérabilité entre les outils mais aussi dans les workflow. En IA plusieurs courants historiques :

- GOFAI KR. (« Good old fashioned artificial intelligence ») Logique, ontologies et systèmes experts
  trouver conceptualisation partagée entre les humains pour se comprendre. Utilisation ontologies SKOS, CIDOC-CRM. Deux niveaux : ontologies et données pour travailler sur du raisonnement, des inférences, règles pour enrichir les données.
- ML et DL
  apprentissage statistique, où le but utiliser grandes quantités de données pour retrouver des pattern caché dans les données. Au lieu d’avoir systéme expert où humain définissent les règles. Mais va produire ces règles automatiquement. Effet de noir car ne va pas pouvoir expliquer comment ces catégories produites. 

Besoin des deux systèmes pour pouvoir profiter des avantages de l’un comem de l’autre. Enjeu important de la qualité des données. Mieux vaut en avoir moins de bonne qualité que de mauavises.

**IA neurosymbolique**. Autre tendance qui est en train de se renouveller ces dernieres années. Consiste à trouver une interaction entre ces deux tendances. Nouveaux journaux, etc.

Ex. Intéret LLM pour enrichir des graphes de connaissances. Friction créative enrichissante. À la fois du raisonnement ou de l’entrainement sur ces données. Tantôt faire de l’extraction que de la représentation.

Première chose faite travailler sur la segmentation sémantiques des images. Reconnaissance des éléments et associer des classes aux pixels. Des images annotées à la main et données textuelles dans OpenTheso.

Premier modèle utilisé SAM entraîné sur 100M images zéro shot learning. Capacité de généralisation et reconnaitre des objets jamais vus lors de l’entraînement. Plus possibilité d’utiliser un prompt. Dans les expériences, fonctionnait mieux avec la bonding box. Donc autre modèle pour générer bounding box, puis utilisation SAM pour reocnnaître segment. Plus CLIP pour donner label correspondants. Mais derniere étape ne fonctionnait pas car images jamais vus. Utilisation des données textuelles dans OpenTheso pour les lables produits apr les humains.

DINO Déterction objets. Knowledge distilation

Donne ensuite à SAM pour détection masques

Puis association label CLIP

Inteprétation sémantique 

- identification des phénomènes de dégradation, etc.

CLIP réutilise les données situées dans OpenTheso, outil de gestion de thesaurus. Réutlisation de ces vocabulaires contrôlés structurés en SKOS.

Utilisation LLM. Prompt pattern pour extraire connaissance.

AUtre expériemnetation Semantics of Complex Spatial Data. Interrogation de requêtes spatiales complexes. Méréologie et topologie. 

#### Discussions et échange avec le public

Évolution des pratiques des chercheurs, meilleure reconnaissance des besoins concernant les métadonnées. Automatise aussi au maximum.

Peut utiliser plateforme Jean Zay

Comment monter des outils génériques qui répondent à des tâches courantes et fréquentes. Mutualisation et calcul.

Exemples montrés pour ND, tous sans entraînement. Donc peut êrte réalisé facilement sur un ordinateur local. Maintenant fine-tuning, besoin de passer sur Jean Zay. Prend plusieurs jours.

### Panel: Circulations d'images

*Modération: Marion Charpier (Musée des Arts Décoratifs (MAD))*

#### Circulation d’images dans la presse ancienne

*Daniel Foliard (Laboratoire de recherche sur les cultures anglophones (LARCA) – Université Paris Cité), Julien Schuh (MSH Mondes, Université Paris Nanterre)*

Projet qui débute l’année prochaine. Depuis plusieurs années essaye de développer des chaînes qui intègrent des outils de reconnaissance automatique des images pour répondre aux enjeux de massification issues de la numérisation massive des documents patrimoniaux pour répondre à des questions SHS.

Archives d’objets créés au moment de la massification de la production d’images. Moment où photographie et techniques impression reconfigurent le paysage de la culture visuelle. Comment redonner vie à ces archives massives et produire des processus de remémoration actives pour que ces bases de données configurées selon des protocoles ou des configuration bibliothéconomiques ne répondent pas aux manières dont ces objets sont utilisés par des humains. Archives mortes car des formats pas directement appropriables. Comment en refaire des éléments d’analyse historique et d’appropriation. Comment recréer du lien entre ces images. Passer du désordre documentaire au domaine du vivant. Outils analyse puissants de ces fonds numérisés.

Adapter ces outils à nos propres pratiques de recherche en se demandant comment reconfigure nos pratiques de recherche et directement adossés à des corpus d’institutions patrimoniales.

Consortium. Question des agences photographiques d’images. Rejoints par l’image center de Toronto (collection Black Star). Agence Roger Viollet.

LIPAD et LIP6 deux labos IA.

Créer jeux de données de terrain. Pb similarités. Deux fonds clefs, Black Star (Live Time et ...). Fond moins connu, fonds Forbin donné au Ministère de la Défense. Agent clef dans la naissance de la culture visuelle française qui a agi comme agence image, joue le rôle de traducteur de la culture anglophone. Fond brut qui sera numérisé intégralement 60 000 images. Réécrire l’histoire de ce fonds en l’entraînant sur les fonds Roll et Roger Viollet ainsi que Library of Congress pour faire un lien entre le contenu visuel de ces images et la sémantique. Fonds sans métadonnées.

Exemple 

- Dégradation par reproduction rotogravures, sur lesquelles les systèmes ne fonctionnent pas bien. 
- Retouches par recadrage
- Tampons origines et métadonnées

Automatisâtion et enrichissement des métadonnées. Pouvoir extrapoler à autres fonds comme *Le Petit Parisien*.

Programme de recherche chargé à l’intersection Computer vision, etc. Ateliers réguliers. Premier à Toronto en mars prochain. Arriver à une plateforme qui puisse être de l’ordre de l’alphabétisation pour les historiens de la photographie et des archives.

#### Circulation d’images : Projet ANR CROBORA / Les voies des images

*Matteo Treleani et Shiming Shen (SIC.Lab - Université Cote d'Azur)*

https://crobora.hypotheses.org

Projet ANR terminé en juillet dernier. Idée du projet de pouvoir travailler sur l’image de l’Europe à travers un ensemble de reprise d’archives européennes, France et Italie.

Travailler sur l’administration des images. Transports, voies du visible. Une perspective du matérialisme numérique où regarde les logiques circulatoires du visible à travers les éléments techniques, socio-documentaires qui régissent leur fonctionnement. On pourrait donc dire que l’on considère les images comme des documents d’archives. Un prisme circulatoire pour travailler sur les images de manière opératoire.

Toutes les images sont réalisées, documentées stockées pour être retransmise. Il y a donc une logique archivistique qui gouverne le monde des médias. Et même que le monde industriel repose sur ces réemplois. Logique de réemployabilité. Mode de circulation qui en conséquence influence ce mode de circulation. Malgré UGC, répétition qui est la norme et ne fait qu’exploser avec le numérique, mais déjà le cas dans le monde audiovisuel.

Deux conséquences : interroger les images à travers la notion de reprise. Analyser tout ce qui est diffusé au moins deux fois. En deuxième lieu, fragmenter les émissions pour analyser les images qui les compose. Souvent patchwork d’archives issues de différentes sources. Passer de l’unité télévisuelle de l’émission ou du sujet du JT pour en saisir les séquences qui la compose.

Selon étude avec FigerPrint ⅔ contenus télévisuels sont des reprises. Un point de repère car plus en réalité (car différents biais, logiciel n’analyse que des séquences de 7s min). Dans le corpus entre 75 et 100% des sujets constitués de reprise. JT du soir 2000 et 2021, chaînes françaises et italienne. Contenu du dépôt légal INA.

Exemple Signature du traité de Rome. Se concentrer sur la circulation d’une image spécifique.

Trouver deux images dans le corpus. Mesure de similarité cosinus pour trouver images similaires. Seuil fixé à 0,80.

Partenariat avec l’INA pour utiliser [SNOOP](https://www.ina.fr/institut-national-audiovisuel/equipe-recherche/projet-snoop). Apprentissage par renforcement. Importe une image et recherche images similaires dans flux en ligne YouTube ou DailyMotion.

Détection de sentiments autour d’une même séquence. Évolution des tendances thématiques des reportages.

Modèles multimodaux comme CLIP. Souvent relation entre le texte et l’image très figée. étiquetage thématique très limité. D’un point de vue sémiotique, le sens en production, un processus dynamique qui dépend beaucoup du contexte. Raison pour laquelle mis en avant l’utilisation de la vision par ordinateur pour étudier la circulation du sens des images.

#### Discussions et échange avec le public

Vocabulaire colonial, s’intéresser à la question circulation image et compréhension géopolitique. Forbin progressiste qui achète certaines imaegs pour mettre en valeur des événements peu couverts. Exemple Tripolitaine.

Problèmes de reconnaissance de similarité avec les modes de reproduction. Dégradation des papiers, différents types de numérisation, et modes de reproduction. Système pas suffisamment robuste. Nous a forcé à créer des images synthétiques en imaginant des dégradations extrêmes. Procédé roto... avant le demi-ton. Pb de cache qui oblige à repenser les approches. De bons résultats. Aussi un aspect de retouches massives. Des images parfois extrêmement composites ! photomontages, etc. Pose beaucoup de questions sur l’image comme source.

Tracer les origine un travail très important. Automatisatisation du travail possible mais le faire à grande échelle compliqué. Besoin de disposer de sources importantes. Périmètre important pour chaque séquence.

Depuis les origines de la circulation de photographie de masse, question de véritée posée. Important d’avoir un discours sur ces questions. Mais que les photographies soient vraies ou pas à cette échelle pas le pb. Analyser l’image comme un processus.

### Panel: IA et institutions patrimoniales

*Modération: Jean-Christophe Carius (Institut National d’Histoire de l’Art (INHA))*

#### HTR, correction d'OCR, fouille d'images, segmentation de journaux : panorama des projets IA à la BnF

*Sébastien Cretin (Bibliothèque nationale de France (BnF))* Expert - chef de projet OCR et formats éditoriaux 
01 53 79 57 76 [sebastien.cretin@bnf.fr](mailto:sebastien.cretin@bnf.fr)

Panorama rapide des projets en IA menés à la Bnf. Premières preuves de concept qui datent de 2016 autour de la fouille d’images, rassemblement d’images par similarité. Adhésion communauté IA4LAM et conviction que nécessaire de rédiger une feuille de route 2019.

Conviction que besoin intégrer stratégie globale. Améliorer organisation R&D, structurer réponses Appels à projets. Développer les compétences des agents. Important pour que discussion raisonnée avec acteurs techniques...

Aujourd’hui plus d’une 30aine de personnes impliquées dans des projets IA. En interraction avec une cellule IA de 3 à 4 membres. Pilotée par un chargé de mission au sein des services...

Projets IA sont des projets standards. Soit besoins internes soit partenariat. D’abord piloté par la cellule IA. Puis phase indusrtialisation, direction qui décide et création équipe dédiée chef de projets et experts. Actuellement un seul projet a atteint cette phase : Gallica Images, indexation automatique des contenus.

Effets de modes, et cycle de vie des modèles frénétiques qui peut mettre dans l’embarras pour faire des investissements. Nombreux besoins qui impliquent de hiérarchiser les projets.

Diapositive des projets, et niveau industrialisation (très intéressante).

HTR en phase exéprimentation à la Bnf. Se confronter énorme problème de Babel, nombreuses langues et écriture. Priorité de construire des partenariats avec les chercheurs. Tester les modèle mis en place. OCR Kraken, parse Python, format pivot et phase évaluation.

Chercheurs bien plus compétents que nous pour traiter des écritures anciennes. Donc valoriser leurs productions. Dialoguer pour des formats compatibles avec nos collections numériques et les intégrer. Avoir des produits HTR de qualité. Projets hébergés au DataLab sur des fonds spécifiques.

OMR Projet CollabScore ANR, Irisa, Cnam, Iremus. Transcription de partitions. Présentation IDAR.

Autre grand projet, correction OCR avec mistral. Projet ArGiMi. Sait que grands débats. Papier école polytechnique qui dit que pas possible mais des pour. Mistral AI, Ina, Artefact, Giskard. Des pour et des contres qui montrent que espoirs fondés. https://www.artefact.com/news/le-consortium-argimi-remporte-lappel-a-projet-sur-lintelligence-artificielle-generative-lance-par-bpifrance/

Autre projet dont attend beaucoup. FINLAM, avec Olitis de Rouen et Teklia. Fondation and integrated models for archives and museums. https://projets.litislab.fr/finlam/ 2028 ouverture à Amiens du Conservatoire international de la presse. Projet de déplacement des collections physiques qui s’accompagne d’un effort important sur les collections de presse. Mise en avant de ces collections. Mais aussi un passif car en 2016 dans le cadre d’un marché public traitement sur 1,2 pages par opérateurs. Ici voir si peut espérer que des processus d’IA permettent de concurrencer un travail humain.

Projet Gallica Images 2024-20.. entre en phase d’industrialisation. Indexation automatique de plusieurs millions d’illustrations.

#### Indexer et explorer les collections du MAD Paris : exemple de la collection Jean Royère

*Marion Charpier (MAD)* Historienne de l’art, master TNAH

Plus au MAD depuis un mois. À l’EnC pour travailler sur les collections de photographies du MAD. Présenter projet mené l’année dernière sur les fonds de Jean Royère et permis de réflechir au projet actuel.

Quelles ont été les motivations initiales pour se lancer dans un projet IA. Initiative de la conservatrice des dessins. Constat pragmatique 1M objets dont 700 000 pas encore inventorié... ⅔ collection. Des enjeux majeurs : obligations réglementaires SMF et enjeux de rendre les collections accessibles au public conformément aux missions dévolues par les créateurs du musée.

Pour terminer inventaire avec les méthodes traditionnelles 643 ans ! S’est donc posé la question de tester de nouvelles innovations dont IA. Pas traiter tous les fonds de la même manière mais se concentrer sur certains fonds. Production de Jean Royère. Nombreuses sollicitations sur cette collection.

Un inventaire du travail de Royère mais dessins pas décrits. 4 grandes catégories d’objets. GRandes gouaches, petites goaches, vues ensemble et calques d’exécution.

Reconnaissance des objets. Mise en place systéme de prise en main facile pour prise en charge. Modèle supervisé. Vérités de terrain, entraînement de modèles, et phase de correction et d’annotations. Supprimé phase de test pour déployer modèle. 

Résultats limites de YOLO. Matrice de confusion qui permet de voir les classes qui sont confondues. Certains objets qui nous intéressent échappent encore à des modélisations précises.

Résultats limités avec CLIP. Besoin d’entraîner les modèles pour les appliquer aux collections de Jean Royère.

Première année qui a permis de développer une réflexion appropriée pour travailler avec des modèles itératifs (car renouvellement des modèles). Méthodes pour amener robustesse. Tester d’autres modèles pour approche par IA.

Blocage technologiques mais aussi culturels. Besoin de convaincre les équipes internes. Projet qui débute sur médiation outils IA pour s’instaurer dans les pratiques du MAD.

prpojet Tornach

#### Le projet HikarIA avec le Musée Guimet

*Solène Tarride (TEKLIA)*

Projet mené avec le Musée Guimet. Doctorat Institut des sciences appliquées de Rennes. Nouvelels écriture, etc. Teklia surtout experts en analyse de documents. Mais ici description sémantique collections photographiques arts asiatiques anciens.

Collection de photographies anciennes japonaise du 19e. 300 albums, 18 000 photographies produites par des studio photo lors de l’ouverture du Japon sur le monde. Albums touristiques souvenir.

Explorer modèles IA pour analyser automatiquement cette collection photographique. Modèles généralement pas entraînés sur ce type de corpus.

Exploré plusieurs modèles : 

- modèles de légendage ou de description comme ChatGPT. 
- détection d’objets YOLO ou SAM qui localisent les objets sur l’image
- modèles de recherche sémantiques: ou encode des images puis recherche de similarité.

Teklia, passage à l’échelle car outils spéciaux pour traiter les documents de manière massive : Arkindex et Callico qui permettent importer des documents puis entraîner les modèles pour applications larges.

Callico pour annotation.

Modèels de description. Founit une image avec instruction qui permet soit de donner du contexte soit des instructions. Génération d’une description plutôt juste. Mais verbeux.

Génération de légendes. Plus important de pouvoir générer des mots-clefs sur l’image. Ce que ces modèles sont également capables de faire. Le format de description peut être adaptée à des finds d’archivage ou d’indexation.

Trois modèles différents évalués CLIP (OpenAI), Qwen2.5 (Alibaba), ChatGPT (OpenAI payant). 

Génération de légendes évaluation

La chance de déjà disposer de descripteurs sur ces collections. Avec mots-clefs et description de types de photographies. Identification des monuments ou des lieux.

Sélection de 6 albums 275 modèles images. Le prompt continet la liste des balises possibles. Founit un jeu de tags complets 1034 tags (mots communs français). Jeu de tags réduit (les 190 tags) du sous-ensemble d’images.

Comparaison des trois modèles avec le même prompt. ChatGPT de loin bien meilleur que les modèles open source. Sur l’ensemble de tags réduits précision forte 75%. Précision chutte beaucoup lorsque modèle complet.

Comme privilégie open source. Finetuné CLIP. Arrive à se rapprocher de ChatGPT.

Essayé de comprendre pourquoi performances basses. En comparant même si précision et rappel bas. En réalité, tags générés par ChatGPT plutôt corrects. ChatGPT en oublie certains mais ajoute aussi des termes manquants.

Passé au peigne fin les prédictions de ChatGPT et intégration termes corrects. Réitération atteint précision 80% Montre bien les limites de ces évaluations et enjeux de métriques.

Les modèles de recherche sémantiques CLIP. Encode ensemble des photographies avec CLIP. Calcule représentation vectorielle et recherche images similaires. Cheval et recherche visuelle pertinente. ex. Cheval, Cérémonie du thé, Poissons (un peu moins bon), etc. 

Visualiser les vecteurs d’images. CLIP permet d’encoder des vecteurs qui peuvent être visualisés. Permet d’analyser de manière simple une grande collection d’images.

Modèles de détection d’objets. Yolo-World pour identifer les personnes. Comptage des personnages. Identification des photos de groupe, de portraits, déterminer cadrage (% bounding box). Identification des modèles récurrents dans le corpus.

Conclusion analyse des performances des modèles contemporains pour analyser photographies anciennes. Fonctionne plutôt bien pour un vocabualire contemporain et généraliste. Permet d’analyser plus facilement les collections photographiques japonaises.

Besoin que les chercheurs regardent ces photographies et nous produisent des résultats.

#### Discussions et échange avec le public

Souvent pour numériser un corpus, besoin qu’ait été inventorié préalablement. Est-ce qu’il y a des 

Projet Tornach?? idée d’inveser le processus. Créer des modèles pour accélérer le processus pour l’inventaire.

Bnf sur le catalogage plusieurs choses. Numérisation exemplaire à la Bnf nécessite que soit catalogué au préalable. Opération qui précède. Bnf 5 personnes qui travaille à temps complet pour intégration du catalogage dans la numérisation. Ce qu’essaye de développer à la Bnf, ce sont des processus d’aide au catalogage pour développer des processus qui améliore les métadonnées.

Correction OCR. Bnf vont s’en tenir OCR. Pour les transcriptions manuscrites sans doute ouvre boite de pandore. Dans le paradigme institution patrimoniale s’en tiendra sans doute aux caractéres lisibles dans le document. Fidélité aux écritures.

Grand risque lié aux corrections LLM pour éviter réécriture... Un gros écueil à éviter. Des modèles HTR entraîné. Modèles de développement d’abréviation.

### Ateliers

Dicover-demo, fonctionne en miroir avec Eikon. Plateforme développée à l’École des ponts dans le cadre de l’ERC Discovery pour proposer des démos et interface pour modèles.

https://tinyurl.com/dhnord-discover

Connexion sur la plateforme. Sélection d’un jeu de données pour les tests.

Charge les modèles et visualise résultats. Possibilité de télécharger les crop en format TIFF sur son ordinateur.

Plateforme modulaire destinée à accueillir différentes experiences sur le même dataset. Plateforme encore en développement possibilité de recommencer extraction sur même jeu de données.

Utilisation de la même API. Deux plateformes. Une en partenariat avec différents projets. Showcase censée être beaucoup plus minimale.

Plateforme pour corpus de données satellitaires et historiques. TRavail avec deux projets sur la diffusion de l’imaginaire scientifique. VHS et Eida pour voir comment les diagrammes ont pu se diffuser dans l’astronomie. Modèles inspiration ptoléméenne.

Ambition

- accessibilité
- intégration
- données : possibilité de correction es résultats

Données entraînement. Plateforme développée par Robin Champenois et [Ségolène Albouy](https://github.com/Segolene-Albouy). Étudiants École des ponts. Un projet collectif.

Articulation en deux blocs. Un front utilisant Django et une API Flasq déployée sur un GPU pour faire différents traitement. Bipartition qui permet d’être plus modulaire et éviter concurrence de processus et mettre GPU seulement sur GPU. PErmet aussi avoir un même outil pour différentes utilisations avec différents front.

Clustering (actuellement désactivé). Modèle pour extraction de watermark. Un modèle de vectorisation de diagrammes. Un modèle d’extraction et de similarité.

VHS et Eida branchés sur autres modules.

Yolo et Doc Extractor (pipeline pour générer de fausses docuemnts historiques, T. Monier) De même pour la détection de copie, entraîné sur des motifs synthétiques. Résultats intéressants pour retrouver des correspondances entre des simgaes.

Shen, Xi, Alexei A. Efros, Armand Joulin, et Mathieu Aubry. 2022. « Learning Co-Segmentation by Segment Swapping for Retrieval and Discovery ». In *2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)*, 5078‑88. New Orleans, LA, USA: IEEE. https://doi.org/10.1109/CVPRW56347.2022.00556.

Modèle développé par ?? pour détection de diagrammes. Modèles reposant sur des transformers.

Cluster repose sur méthode Deep transformation-Invariant Clustering idée de travailler sur modèles invariance aux transformations 2020. Reconnaitre une image indépendamment de la rotation. De même transformation affine, colorométrique, et reconnaissnce visuelle.

Installation du repo. Téléchargement des modèles. Tester interface graphique en local. Puis travail sur l’API.

En local possibilité d’avoir directement accès aux résultats bruts des extraction (prochainement disposnible). Bounding box calculés en valeur relative. 

Extraction de données support pour d’autres extraction de données. Donc souhaite par exemple pouvoir les utiliser pour similarité. Dans Sharedocument/extraction un fichier JSON avec extraction et crop défini par valeurs absolues, etc. Bbox un encodage hexadecimal de ces crop. Une annotation au format de base utilisée par Yolo, aevc nom images et dimensions. Ceci pour les formats bruts.

Idem pour les watermarks

Possible de travailler avec l’API REST. Un fichier JSON avec informations minimales. Possible de communiquer un manifeste Bnf et un nom de modèle. Possible de lancer la requete CURL en donnant comme référence le JSON.

API renvoie un id de l’expériment et un tracking ID qui permet d’obtenir un statut pour monitorer diverses tâches à distance.

Document journal, clef données dans mon JSON. Document qui peut être soit un Zip soit un manifeste. Actuellement travaille sur la gestion des dataset pour pouvoir importer images, ou zip d’images. Annotations et images téléchargées. Annotation avec coordonnées.

Pour les watermark idem, mais besoin chemin image. 

Aussi possible d’utiliser les modules dépourvus d’interface graphique comme la recherche de similarité. JSON qui comprend un certain nombre de document. Similarité qui se calcule par paire de documents. Recherche dans les images extraites ce qui est comparable dans autre ensemble de documents.

Matrices de similarité au format numpy, un format compressé pour des matrices. Indice de similarité cosinus. AUtres indices.

http://www2.culture.gouv.fr/documentation/archim/Batim.html

### DVT Distant-viewing toolkit

https://github.com/distant-viewing/dvt

Collection dataset et outils pour faciliter le travail sur les images mouvantes.

Second tutoriel https://github.com/distant-viewing/dvt/blob/main/tutorials/Distant_Viewing_Tutorial_2_Network_Era_Sitcoms_and_Visual_Style.ipynb

Essayé être très robuste dans le notebook. Montrer avec de pertits exemples comment travailler sur courte vidéo.

Importance des plans pour comprendre la relation entre les personnages. 45’’ que va analyser de ce point de vue.

Plusieurs formats avec lesquels possible de travailler. Enjeux échelle des corpus.

DVT avantage de travailler sur des vidéos. Faciliter la vie.

Analyse temporelle de la luminosité permet déjà d’identifier un certain nombre d’aspects.

Pour détection des plans. Segmentation en pt morceaux. Seul à travailler nativement sur fichier vidéo. Sans production images individuelles.

Produire ligne pour segmenter plan et déterminer longueur des plans pour avoir un sens d’à quelle vitesse viennent les plans.

Pour simplifier un tableau pour travailler directement.

Détection de visages. Voir qui est sur l’écran et avec qui. Gros plans, closeup, etc.

Test de similarité avec produits matriciel.

Quand travail avec grand corpus pas nécessaire de travailler sur ensemble des plans. Détection de scènes particulières. Réduire le temps de travail.

Intéressant car contredit idée que l’une des émission copie l’autre.

Beaucoup travaillé avec des photographies mais documentaires. Peu avec les images d’art. 

Photogrammar débuté 2010.  https://lyonelkaufmann.ch/histoire/2022/07/03/photogrammar-un-laboratoire-derudition-numerique-sur-la-grande-depression/

Première image sur laquelle travaillé, images art, pb identification.

Aimeraient travailler plus de formes narratives.

## DH Nord 2024

### Discours introduction : « 10 ans de DHNord ! »

*Philippe Useille (UPHF)*

Sous la direction de Martine Benoît que la MESH a lancé DHNord en 2010. Des humanités numériques, des outils, des méthodes... Les directeurs successifs de la MESH ont continuement appuyé le domaine.

Aspects méthodologiques et spécifiques au domaine. De plus en plus sujets contemporains ou réflexifs. 2016, théorie et critique. 2018 matérialité de la recherche en SHS. Collaboration entre acteurs, liens société, etc. Encourager la réflexion épistémologique et promouvoir la diffusion des connaissances et des pratiques.

Donner du temps aux intervenants. Favoriser les échanges pour mieux identifier les problèmatiques pour le Colloque DH Nord 2025.

### Search and Exploration of Documentary Photography Using Multimodal Large Language Models

*Taylor Arnold et Lauren Tilton (Université de Richmond, Virginie, États-Unis)*

Distant viewing. Photographie homme sur cheval et chien. Qu’est-ce que cette image ? que veut faire le photographie ? Quel message convoie ? Comment véhicule le message ?

Processus d’interprétation des images. Paul Valéry décrit le processus d’interprétation des images comme « looking in other world forgetting the name of the things that one sees ».

Comment ce système fonctionne-t-il ?

Challenge pour penser computer vision. Série de pixels et array de nombres. Peuvent representer le même concept.

Pourquoi si différent comme compréhension image. Exemple image de niveau de gris. Détail œil, sans contexte ?? si zoom out, contexte et comprénd image.

Computer vision basé sur la visualité humaine. Il existe d’autres manières de voir dans le monde. Manière de voir une question de 

Steve Anderson suggère de théoriser les technologies de vision de nouvelle manière. John Berger, Lisa Cartwright, Stuart Hall, Elizabeth Losh, Tara McPherson, Lev Manovitch, Marita...

Pourquoi est-ce nécessaire ? Distant viewing une théorie de l’exploration computationnelle des images à travers l’application de la vision computationnel et pourquoi est-ce nécessaire ?

- nature mimétique des images qui réclame analyse computationnelle parte de l’extraction de métadonnées sémantiques en utilisant la vision computationnelle
- processus construction annotation médiévismes computationnellemeent comme forme de viewing
- application de la vision computationnelle n’est pas un processus neutre, engage dans des manière de voir socialement médiée de voir et encoder dans algorithmes manières dont utilisées.

Rmq

Méthode distant viewing offre une approche pour spécifier ou interroger des méthodes poru l’exploration computationnelle des images à travers l’application de la vision computationnelle.

1. annoter
2. organiser
3. explorer
4. communiquer

Qui a les données les plus Messing, nous. Pour cela que IA tellement important.

Travail sur Documerica, 1972 à ...

**Trois approches « classiques »**

Trois manières passées de faire. Et présentation de la manière dont approche multimodale nous permettent aujourd’hui de travailler.

Approche utilisant les métadonnées. Pour les photographies des métadonnées consistantes. Photogrammar fondée sur les métadonnées : localisation, photographe, etc. Archive et carte interactive. Desinstaller Photogrammar 170k images collectsion FSA-OWI.

Utilisation ML supervisée. Détection objets. Exemple plusieurs manières de voir les bouteilles. Différents contextes.

Image embeddings. Utiliser DL modèle et regarder comment fait la prédiction. Jusqu’à ce qu’obtienne prédiction. Dernier layer, utilisation de ces séquences pour décrire les images. Idée que peut utiliser ces séquences pour facilement détecter des objets dans les images et donc identiifer des similarités. Résultats phénoménaux. 

Ne sait pas pourquoi similaire, à l’humain de comprendre pourquoi. Parfois saisit sur les objets, mais parfois aspects plastiques, texture ou matérialité de l’image.

Exemple, images dont légendes très différentes. Mais même type de contenus.

**Multimodal large Language Models (MLLMs)**

Explainable clusters and tags. Plus proche de la manière dont nous interprétons les images. Mécanismes du prompt qui permet également de recontextualiser les images.

#### Questions

Faisons aussi des analyses formelles. Pas présenté aujourd’hui. Notamment analyse des plans : contre-plongée, etc. Travailler sur le cadrage. Selon le background, différents éléments.

Partie théorie surtout question de la manière dont ordinateur voit les choses. Sémiotiques, plutôt un argument technique sur la manière différente dont l’ordinateur voit les choses.

### Emmanuelle Bermès

2017 Google met l’IA au cœur de son écosystème.

Certains nombre d’acteurs considère alors que les technologies sont sufisamment matures.

2019 considèrer que l’IA un sujet 

2019 AI4LAM

2022 ChatGPT

Où en est-on aujourd’hui.

Première chose que l’on observe avec ces grandes conférences, c’est un effet de balancier entre des enjeux d’expérimentations et de...

Fantastic Futures, nom de la première conférence. Ensuite organisés dans différentes régions du monde et différentes langues. 2018, mais aussi 2023, plus sensibilisation et expérimentation. Retour à l’expérimentation en 2023 car irruption de ChatGPT.

2021 et celle de Paris cette année plus du côté de l’implémentation. Comprendre comment stabiliser les experiementations faites. Démarche encore compliquée à construire.

L’an 2 après ChatGPT (pas Kraken car outil HTR dans notre domaine). Ce qui ressort aujourd’hui la maturité certain nombre de modèles utilisés par tout le monde.

- Chat GPT
- Whisper 
  Modèle de Meta pour speetch to text
- Utralytics Yolo
  Très utilisé pour la détection d’objets dans les images. Celui qui est utilisé dans le projet MAD.
- OpenAI Clip
  Beaucoup cité en 2024, un modèle multi-modal qui permet de faire de la recherche d’images via du texte. Modèle zéro shot utilisable pour indexer immédiatement un corpus d’images.
- Florence-2
  Microsoft, très performant
- Llama
- Mistral AI

Grands modèles IA génératives qui font que voit émerger la notion d’archives conversationnelles. Un des cas d’usage qui émerge est celui d’une conversation possible avec les archives.

RAG Retrieval Augmented Generation. Une méthode qui consiste à utiliser un LLM en la ciblant sur un corpus particulier. 

ex. Chat Bot mis en place par la Bibliothèque du Luxembourg l’année dernière. Mise en place d’un workflow dans lequel la requête de l’usager est confronté à la base de document sous forme d’embedding pour identifier documents pertinents. Revoyé à un LLM qui combine un élément de réponse dans un prompt en se basant sur les documents pertinents du corpus. Permet de cibler sur quoi répond, par ailleurs capable de citer ses sources. Permet aussi de converser avec un agent capable de désigner le contenu des archives.

Pose des questions de cas d’usage, mais également des questions de qualité. Pb hallucinations. Cette année Stanford a présenté lors de la conf AI4LAM un RAG concernant les archives de la Sillicon Valley avant la création d’internet. Permet de poser des questions du type pensez-vous qu’Apple aura du succès à l’avenir ! Il faudrait donc que les chercheurs se penchent sur ce genre d’outils pour savoir quoi en faire.

Autre expérimentation proposée par JStor depuis 2023. Outil Béta dans JStor qui permet lorsque consulte un article intéressant, de demander à cet agent de résumer l’article ou d’en interroger le contenu.

BookLM

Pas seulement générer du texte. Il existe également des applications d’enrichissement des méatdonnées. Possible de créer ou enrichir des métadonnées. Mais également d’organiser des données. Corriger un texte (donc un OCR). Décrire une image (et éventuellement, interroger cette description).

Pratiques arrivées dans les sujets de stage des étudiants TNAH

Ne pas vous fier aux réposnes d’une seule IA. Besoin interfaces sensibles pour les personnes qui connaissent bien les collections pour déterminer si oui ou non les réponses sont pertinentes. 

Dernier défi, intégration de ces modèles. MAD, BnfF Gallica, NFSA, TRove, National Library, British Library qui réflèchissent toutes à ces enjeux. Trove comme Gallica travaillent sur recherche d’images. Gallica moteurs analyse images pour extraires caractèristiques sémantiques ou visuelles. Trove choisit de passer par le texte. NFSA défi principal le temps de traitement. Traitement une année linéaire en 50 jours. Bristih Library OCR, HTR de langues à faibles ressources. https://www.nfsa.gov.au

## Les projets innovants du Lab des Archives nationales de France

*Florence Clavaud (Archives nationales - Centre Jean-Mabillon)*

Création sepetmebre 2021. Sur la base d’un arrêté du 9 avril 2021, dans un contexte de réorganisation des AnF. Toute petite équipe au sein d’une direction de support chargée de la régie des fonds, de leur conservation, etc.

Missions formulées dans les documents internes

- chargé de coordonner les activités de recherche et de développement numérique
- assurer un appui méthodologique et technique aux porteurs de projet
- aide à la valorisation des projets
- réalisation de projets dans ce domaine, souvent dans le cadre de partenariats

Concrètement travail coordination en concertation avec la Mission pour la prospéctive, la stratégie et les relations internationales. Animation du comité interne R&D de l’institution. Séire de webminaire et ateliers depuis printemps 2024. Via le bureau du chapitre fracophone AI4LAM. Contribution à l’animation communauté d’intérêt.

Activité significative à l’internationale sur standardisation.

être pragmatique tout en définissant et en suivant une ligne claire. 

- Mener de sprojets ou participer en tant que partenaire à des projets de recherche qui soient utiles à l’institution. En lui permettant d’explorer de nouvelles voies et solutions pour l’avenir de son SI et ses missions de médiation numériques. Faire monter des données de qualité. ...

Testaments de Poilus (2017-2025). Projet emblématique. Au départ projet de recherche de Christine Nougaret. Projet d’édition participative. Financement de la Fondation des sciences du patrimoine. Projet très documenté. Premier projet d’échantillon. Création d’une plateforme d’édition collaborative à une époque où les projets collaboratifs florissaient mais avec des objectifs moins ambitieux que ceux que les AN s’étaient fixés.

Très nombreux collaborateurs. Nouveau site web d’édition collaborative aux AN. Projet aujourd’hui terminé.

Regrets et acquis de ces projets. Aurait souhaité pouvoir étendre le périmètre du projet. Pas été non plus possible de rendre la plateforme générique. Mais fournit une méthodologie globale de crowdsourcing qui ont nourri les projets d’indexation collaborative construite depuis.

Produits corpus de fichiers TEI disponible sur GitHub et déjà réutilisée pour servir à constituer un des jeux de données d’entrainement référencés sur HTR-United.

NER4Archives 2020- ... Named Entity recognition for archives. Objectif élaborer une méthode et mettre... Mené avec l’équipe Almanach. Mise en place de solutions annoattion et de classification automatique (Lucas Terriel). 2023-2024Continué avec opérations de liage des entités pour identifier les agents nommés et classifiés dans les métadonnées. Exploite le fait qu’une partie corpus soit sémantisé pour classer candidats afin de les aligner (Cécilia Graiff).

Présentation mai 2024

Limites de la SIV pour procéder. 

Transitiond es métadonnées des AnF vers des graphes d’entités liées. Interface de travail. Limites constatées.

### L’édition savante numérique : enjeux et perspectives

*Joana Casenave (Groupe d’Études et de Recherche Interdisciplinaire en Information et COmmunication (GERiiCO) – Université de Lille)*

Définir édition critique comme la mise à disposition d’un texte à un lecteur qui, sans le traavil de l’éditeur serait ) sa soustrait à sa connaissance. Texte accompagné d’un appareil de notes. Texte présenté dans une version qui puisse faire autorité.

Peut exister d’autres éditions représentant autre discours d’autorité sur ce même texte. Peut donc exister plusieurs versions parallèles. Entend comme édition critique dans sa conception philologique, contexte de préparation et d’annotations du texte.

Comment les philologues opèrent leurs éditions mais aussi la justifient. Exploré les fondements du paratextes pour isoler trois concepts fondamentaux qui structurent la démarche philologique :

- autorité : valeur de référence et garantie scientifique
- fidélité : conformité à un modèle et fiabilité d’une méthode
- exhaustivité : gestion de la documentation et modalités de sélection

Ensemble de choix opérés en fonction de ces notions.

Plusieurs formes d’autorité dans les éditions critiques. 

- celel du ms de base
- méthode philologique (qui sont diverses)
- autorité de l’édition
- autorité de l’éditeur
- autorité de la maison d’édition ou de la collection

Formes qui posent des questions d’auctorialité mais aussi d’évolution dans la version numérique. Toujours la même question : quel ms présente meilleure version, quelle méthode mieux adaptée, dans quelle collection...

Mais on constate également des évolutions très tranchées qui sont notamment liées au fait qu’on assiste à une évolution notable du travail et du rôle des éditeurs. Les éditeurs plus les seuls auteurs. Évolution aussi des fonctionnalités et émergeance du corps auctorial composé de chercheurs, d’éditeurs, mais aussi d’infromaticiens mais également des lecteurs qui peuvent participer de manière plus ou moins prégnante à l’édition. Collaboratif, mais même dans les éditions terminées, corps auctorial fondé sur la contribution et la participation qui pose des questions d’autorité. Comment reconnaît contribution. Dissolution rôle auteur qui pose diverses questions notamment d’évaluation de l’édition critique numérique. Obtient-elle le même niveau de reconnaissance que les éditions sur papier.

Voit de nouvelles formes d’évaluation. Notamment évaluation par les pairs en amont. Évaluations classiques qui portent le plus souvent sur la forme plutôt que le fonds pour les éditions numériques. Pose la question du niveau de reconnaissance par les chercheurs.

Par ailleurs, ces évolutions sont évolutives. Or, une grande différence par rapport aux éditions papier. Question documentation des mises à jour pour citation. Exemple de l’édition de Walt Whitman et blog de mise à jour.

... enjeux primaires et secondaire dans l’édition numérique. Important de pouvoir développer documentation primaire et documentation secondaire. Remarque que deux documentations qui peuvent être mêlées.

L’exhaustivité dans l’édition numérique qui est de plus en plus présente, en essayant de rendre visible le processus d’édition et les sources primaires. De même processus d’acquisitions des connaissances ouvertes sur l’extérieur dans la publication. Liste de référencement dans l’édition numérique elle même. Enjeu de la gestion de la profusion documentaire. Comment ne pas noyer le lecteur dans une documentation trop abondante. Y répond un impératif d’organisation. On organise le matériau mais aussi le discours qui l’accompagne.

L’édition critique qui peut être considérée selon le schéma classiqeu de la communication Jacobson, etc. Texte à éditer (contexte ou référent). Site web (canal). Corps auctoriel (émetteur) Documentation critique et secondaire (message) – Lecteur (Destinataire). Norme méthodologiques, règles d’édition instituées par l’éditeur, outils et fonctionnalités, parcours de lecteur (Code).

Discours critique que l’éditeur convie au lecteur. Plusieurs étapes pour transmettre ce discours, classer la documentation et hiérarchiser l’information. Il y a donc un ordre et on construit un discours qui mobilise tous ces objets avec l’intérêt de transmettre un discours. TRansforme en didactisation, mise en place d’un parcours de lecture.

Il y a une importance particulière données à la trame narrative, à la scénarisation. Donne l’illusion au lecteur de croire qu’il est acteur. Pourtant ensemble des choix encodés en avance. Didactisation : comment mettre l’information à la portée de l’utilisateur. Voit donc une prise en compte de la réception : l’édition comme discours orienté vers le destinataire.

Conclusion

Problèmatique prope à l’édition numérique : hétérogènéité et manque de normalisâtion des plafeformes. Or, devrait pouvoir s’appuyer sur ce qui fonctionne et existe déjà. Important car les éditions critiques numériques conservent au fil des années des mêmes modes de présentation. Si on peut ajouter des chapitres ou des documents, s’aperçoit que les modes d’organisation de l’information ou les parcours proposés aux lecteurs restent fixes.

Il est donc d’autant plus important e de réfléchir de manière approfondie à la didactisation de l’information et à la structuration du contenu dans les pages web dès le début de la conception des sites. C’est à l’équipe éditoriale dans son entier, c’est au corps autorial dans son ensemble d’engager cette réflexion.

### Discussion

Comment contrôle distribution des formes. Avec IA dissolution rôle auctorial. En même temps souvent ne prend pas en compte rôle ensemble petites mains. Mais là changement radical car plus rôle contrôlé quand devient des poids dans des réseaux neuronaux. Change radicalement manière dont le savoir transmis.

Du point de vue des bibliothécaires, deux paradigmes d’usages qui ne devraient pas changer : réponses à des questions qui ne devraient pas nécessairement passer par des supports de documents. Peut simplifier en répondant directement. Autre paradigme, celui de la recherche et des savoirs, enjeux de traçabilité et de transparence de l’information. Explicabilité qui permette de déterminer comment arrive à des conclusions. Principe de la science. D’où question des RAG et de leur utilisation pour les chercheurs. Absence explicabilité problèmatique.

Moi : question individuation et fausse transparence. 

Faire plus de place dans l’enseignement et la recherche à des approches sensibles, émotionnelles, ou encore de recherche création. À cet égard ce que font les artistes dans ce domaine est très inspirant. Si tout ce qui est rationnel et calculable peut être fait par les machines. Si machine capables de produire des textes d’idée efficaces, que se passe-t-il dans nos disciplines pour l’évaluation ? Pourquoi estime-t-on qu’il est important qu’ils soient capables par eux-mêmes d’écrire un texte. En quoi cette pratique est-elle importante. Redonner du sens dans l’enseignement et la nature des exercices que l’on demande.

Patrimoine et temps long. Ce dont a parlé surtout des logiques de projets. Quelles sont les évolutions prévisibles dans ces secteurs en termes d’effectifs. Quelles évolutions pour la formation en termes de débouchés ?

### HNLab

Adam spécialité

Isidore 2020. Un cadre de travail pour adapter l’IA à nos besoins. 14 ans que ce dispositif socio-technique fonctionne. Réflexion Low tech, arrêter de mettre des CMS partout et processus réécriture. CREN Université de Montréal et CRIHN. Coproduction outils Stylo. Outil écriture appareillé pour les sciences humaines et sociales, vocation rejoindre Isidore pour faciliter écriture bibliographie, etc.

Comment ofrger des outils frugaux à l’heure des GML ? Quel modèle de fonctionnement minimal quand peu de données pour le structurer ou le mettre dans un RAG. Ensemble de réflexions que publie et dont fait des notes sur Zotero.

Stratégie de recherche qui est en train d’être formalisée. Essai de prise de recul sur les travaux actuellement menés.

RAG mise en place de hackathon. Formalisation d’un POC

4 principes

- innovation par l’usage, intégration continue des besoins des chercheurs et des communautés SHS.
- forte dimension recherche SHS & informatique : interdîsciplinarité, besoins particuliers
- Développemnt internet et expériemnation agiles : modélsiation
- industrialisation co-construite en externe : LabCom, Premat’

Rag permet de garder conrtaole LLM

conceptualiser les requêpets sur des corpus spécifqieus

Lutte contre les hallucinations 

augmente pertinence, la cohérence, l’explicabilité et surtout l’interpréation

Corntôle r

approches frugales

Problématiques : Voies de recherche ouvertes par inclusion IA. Qu’ouvre comme applications de recherche. Offre de nouvelles vues et interprétations. Comment articule à des méthodes computationnelles classiques.

RAG combine modèle de recherche information et un modèle de génération de texte.

TRois étapes fondamentales : indexation, récupération puis génération du texte.

Dans la première phase encode la requête. Projection espace sémantiques. À partir de la question, recherche des résultats pertinents dans le corpus en fonction de votre requête. Fournir le contexte. 

Corpus NIPS sur l’IA en libre accès 1984 à 2018. 7 200 documents. Est-ce qu’avec un corpus d’une telle volumétrie peut obtenir des résultast pertinents ? Peut-être avec mesure de similarité ou bien plus pertinents avec corpus stylés par des prismes d’entrée.

Détection réseau auteurs, analyses diachroniques. Premières entrées sur le corpus et sous-corpus maîtrisés et connus de l’utilisateur. Permettent une exploitabilité sur corpus plsu spécifique.

- relations entre les auteurs
- relations entre les articles (détection communautés de recherche)
- sémantique des articles
- analyse diachroniques nouveaux concept qui apparaîssent ou disparaissent
- intérêt pour la lexie

Multiplie prisme entré avant appliquer RAG. Cluster qui nous semblent pertinents.

Détection de communauté. TF-IDM et clustering.

Création sous-corpus maîtrisables connus des utilisateurs. Explicabilité des résultats grace au contexte. Forme interprétation possible plutôt que ChatGPT. Réduction aspect boite noire et frugalité des modèles.

Utilisation Llama 1b?? et 8b

Intégration presque terminée, veut expérimenter impact fineTuning sur les domaines. Utilisateur au cœur du système comment designer interface.

**Une méthode plus rapide pour segmenter des imaegs en utilisant...**

Deuxième axe. Chaîne de segmentation, idée de récupérer des images dans le domaine SHS. Segmentation, classification et identification. 

- Récupération des images dans les corpus de recherche
- Identifciation de motifs, d’images spécifiques
- Annotation et récupération de ces imaegs
- « Récupère-moi l’ensemble des représentations d’éléphants... »

Permet d’explorer des corpus d’images ou articles comprennant des images. Ensemble d’annotations effectuées à la main pour ensuite repérer un modèle IA. Ce qu’a essayé de faire, c’est accélérer ce processus. Dans le labo essaye de partir de cas de recherche. Ici en HA, repérer sur des sculptures différents motifs. 

Assez laborieux. Dans ce cas, traitement bdd, uniformisation, annotation, etc. Puis étiquetage. Ce que l’on a fait, c’est essayer de s’intéresser à du travail en IA. Intedisciplinaire, avec Léa Maronnet. Avec elle, établir une chaîne de segmentation. Utilisation de SAM, qui permet de faire beaucoup plus rapidement le repérage des motifs. Puis avec transformeur vision, rassembler les motifs.

Un autre article l’ayant fait dans un autre domaine montrant que processus 100 fois plus rapide. Offre également beaucoup plus de possibiltés en termes de segmentation. Des masques classifiés avec du clustering. Les masques ayant une similarité jugée...

Reste à généraliser sur un plus grand nombre d’images. Utiliser pré-traitement pour nettoyer. Limitation actuelle à des cas plus faile. Urbaniser chaînes de traitement pour faciliter usage.

Dissémination

RAG pour Isidore et Nakala comme epxloration interactive des bdd et constitution de corpus scientifiques. 

Chaine de segmentation comme description de bdd images

Ouverts autres collaborations

## Panel "Acteurs, projets et nouvelles perspectives de recherche"

*Modération: Nicolas Genis (Histoire, Archéologie et Littérature des Mondes Anciens (HALMA) – Université de Lille)*

### Faire collaborer les acteurs des données de la recherche : retour d’expérience de l’atelier de la donnée Lille Open Research Data LORD

*Alicia Leon y Barella (Service Commun de Documentation (SCD) - Université de Lille) et Valentin de Craene (MESHS – CNRS)*

Enjeux du travail en commun autour de cette question des données de la recherche. Thématiques transversales à DH Nord, à travers le travail quotidien des acteurs de la données. Nombre d’acteurs des données de la recherche ont pris à bras le corps cette question de la science ouverte. 13 MSH se sont dotés de services. Certains services communs de la documentation ont aussi ajouté la mention.

Analyse du travail collaboratif. Reprise de la notion de science ouverte telle qu’elle est définie par les plans nationaux. Diffusion des résultats sans entraves. Pas attendu 2018 et première plan national de la science ouverte pour être introduite dans les pratiques de recherche. Dacos dans *Des mains sur les épaules de géant* fait la filiation.

- 1991 ArXiv
- 2001 HAL
- 2002 Budapest OAI
- 2003 Déclaration Berlin
- 2016 loi pour la république numérique 
- 2018-2021, plan national science ouverte
- 2021 Recommandation de l’UNESCO sur une science ouverte

Pilotage de la recherche. Élargissement de la notion depuis la publication à politique publique des données.

- Rapport Bothorel « Pour une politique publique de la donnée », décembre 2020
- Politique des données des algorithmes et des codes sources du MESR 2021-2024
- Création de Recherche Data Gouv en 2022
  - outils techniques
  - et formes d’accompagnement des équipes de recherche, centres de références thématiques : Huma-Num et Progedo. Maillage d’accompagnement généraliste avec les Ateliers de la donnée.

« Alléger le fardeau de la donnée pour les équipes de recherche » en organisant un point d’accès unique pour les chercheurs et les jeunes chercheurs. Faire en sorte que derrière figurent tous les métiers dans une idée de mutualisation des compétences et des approches métier.

Question de l’apprentissage du travail en commun. Question qui nous précède à la MSH et dans DHNord.

Atelier de la donnée. Modération vers des entrepots de qualité.

Perspectives pour l’atelier de la donnée. Co-construire l’évolution de nos services. Création site web. Respecter les périmènes géographiques, disciplinaires et institutionnels. Organiser des rencontres communes pour faire connaitr enotre accompagnement.

### eCorpus : une solution Open Source et collaborative pour la gestion et l’éditorialisation d'objet 3D à l’usage des chercheurs et professionnels du patrimoine

*Elise Bailleul, Mathieu Beaud, Marc Gil (Institut de Recherches en Sciences HIstoriques du Septentrion (IRHiS) - Université de Lille) et Thibault Guillaumont (Holusion)*

DoMA Intégration de Données...

Projet eThesaurus CPER MALIVE 2018-2023 porté par Pierre Gilles, etc. et équipe de chercheurs universitaires. En première lieu un projet d’histoire de l’art qui prenait position dans le domaine des techniques de fabrication de l’objet orvévré dans l’Europe du Nord. Ce faisant pris position sur deux assises technologiques en particulier : 1° adapter le protocole de numérisation en l’adaptant à l’orfèvrerie : pb transparence et réflexance. Résolu avec des filtres de lumières polarisées croisées avec succès. 2° développer une solution logicielle qui puisse répondre au besoin de manipulation des modèles. Stockage au même endroit et conservation. Application eCorpus développée en OpenSource par IE puis par la société Ollusion à partir d ’un viewer de la Smithonian.

À la suite de ce projet qu’est né le projet DoMA avec un soutient CPER Enhance. Idée de pouvoir développer des outils développés pour un projet portant sur les arts monumentaux et pratique de la reconstitution par anastylose. Portée par Elise Baileul et Mathieu Beaud. Projet porté par la possibilité de sémantiser le modèle. Intéroge l’outil corpus dans sa possibilité de manipuler et visualiser le modèle 3D.

Application qui en plus d’être une bdd offre solution de manipulation et visualisation. Le modèle 3D est implanté dans une scène qui rend possible sa manipulation. Objet présenté dans un environnement 3D où possible de modifier les contexte lumineux ou spatiaux. Aussi possible d’ajouter de la documentation à plusieurs niveaux pour enrichir le modèle. Ensemble de données de la scène structurés et décrites dans un fichier JSON. .glb, . .html, .etc --> JSON

Plsueirus niveaux de description : métadonnées, annotations, articles. Enfin possible de construire une visite guidée de l’obejt en couplant annotation etc. https://ecorpus.eu traçabilité, export différents formats.

Intérêt du logiciel pour faire de la médiation. Il s’agit de le faire évoluer pour être utile au chercheur. Visualisation et décentralisation. Permet accès rapide à la visualisation des fichiers 3D et permet conservation fiable et sécurisée. Intéressés par son potentiel d’enrichissement sémantiques pour documenter les objets. Surtout appliqué jusqu’à présent orfèvrerie. Aujourd’hui diversifier les objets d’étude en passant à l’échelle monumentale. Idée de la rendre utile au travail d’anastylose monumentale où il s’agit d’assembler des vestiges mais aussi de compléter les éléments manquants.

Idée venue de la possibilité offerte pas l’application d’associer plusieurs modèles dans une même scène. Alors possible d’utiliser ces éléments dans un contexte d’anastylose numérique. Que pourrait apporter ? Travail de remontage et souvent de complétude monumental, pose souvent le problème de l’interprétation. Souvent propose une image qui pourrait paraître certaine, or réducteur par rapport à la diversité des hypothèses, etc.

On voudrait ici pouvoir ajouter des choses et tt l’intérêt. Pour le moment, ne peux pas passer étape... mais voudrait proposer environnement collaboratif et ajout de la possibilité d’annotations dans les corpus. Et scénarisation qui permettrait de pouvoir présenter de manière guidée plusieurs hypothèses envisagées et états de la restauration.

Première étape de travail déjà réalisé sur le portail démambré de l’église de Corbeil. Conservé dans plusieurs lieux. Travail avec Archéovision pour produire des images fixes et un état définitif de restitution. Actuellement travaille à décomposer les éléments et la démarches pour travailler à ces possibilités de reconstitution. Plusieurs nœuds simples à retravailler : échelle et décalage. Verra si peut arriver à une solution suffisamment conviviale pour le travail des historiens de l’art. Voir jusqu’où arrive à pousser le travail et présentation sur mesure pour ce type de travail.

Suite du projet conssitera à pouvoir s’emparer d’un objet d’étude du début à la fin : portail Ancienne abbatiale Arbous. Fonds lapidaire qui présente nbx avantage. Bien conservé, entièrement inventorié. Restaurations importantes ayant produit données d’analyses. Et déjà proposition de restitution graphique en 2D. Unité monumentale du 12e s. Bon candidat pour perfectionner l’usage. Partenariat pour mise en œuvre de tt cette chaîne opératoire en utilisant les possibilités d’eCorpus. 2025 acquisition du corpus, laserométrie et photogrammétrie. Rassemblement des données de recherche. Travail de restitution dans logiciel 3D. eCorpus ensuite utilisé comme bdd pour le stockage (documentation, gestion et partage). Puis intégration des données de recherche existantes. Enfin utilisé pour la présentation d’un rendu final qui pourrai être utilisé comme publication scientifique.

Questions de droits et de licences. Dès cette première étape confronté à ces questions à tts les étapes du projet.

2023-2024 projet expérimental avec étudiants de L3. Numérisation au musée avec [Scaniverse](https://scaniverse.com) pusi dans eCorpus. L’année prochaine avec la piscine de Roubaix, déploiement du cours pour enseignement à distance. Premier bénéfice pour HA, rendre à l’œuvre le regard long qu’elle mérite. Besoin de regarder l’œuvre et anticiper la volumétrie. Expérimenter un type de restitution de l’œuvre. Un problème ancien pour le travail de l’historien de l’art qu’il s’agisse, de gravues, de photographies, ou de modèle 3D. Plus riche mais pas l’œuvre. Autre aspect, restituer les connaissances sur l’œuvres plutôt que dans une dialectique linéaire. Difficile de penser selon plusieurs axes de lecture. D’un point de vue pédagogique, plusieurs points intéressants. Chaîne de mise en œuvre et logiciels open source. Récupération formats de fichiers récupérables, etc.

Sur la littératie numérique, travail collaboratif. Mis à plusieurs pour stimuler les projets. Ne travaillent qu’en salle.

### Projet PERARTEM : modéliser, structurer et enrichir une base de données pour la presse est-allemande avec Heurist

*Carola Hähnel-Mesnard, Gabrielle Desmet (Analyses littéraires et histoire de la langue (Alithila – Université de Lille) et Valentin de Craene (MESHS – CNRS)*

Idée de pouvoir se consacrer à Sonntag, journal culturel hebdomadaire fondé en 1946 par l’union culturelle pour le renouveau démocratique de l’Allemagne. Une mine pour les articles consacrés à la littérature, arts et théâtre. Architecture, culture au quotidien et politique culturelle évidemment. Tirage de 20 000 ex. Un format stable de 12 pages. Existé jusque dans les années 90. Refondé grâce à la fusion avec journal ouest allemand en 1990 --> Freitag.

Grand corpus. Pré-projet pour déposer un projet ANR dans le cadre projets franço-all.

Numérisation par ART Lille échantillon de 2 années, 1977 et 1989. Collaborâtion avec le Fonds Cadist RDA Nouveaux Lander.

Résultats numérisation.

Modélisation et structuration avec un modèle conceptuel pour la base avec Heurist. Efforts concentrés sur la table des articles. Table des auteurs et dates. Œuvres traitées. 63 articles pour 52 aueturs et 28 journalistes.

Question des titres constitutifs, quelles bonnes informations mettre en avant ?

Première exploitation des résultats. Question émissions radiophoniques.

Fonctionnalité de Heurist ...lookup pour bénéficier référentiels pré-enregistrés. Mais le nombre d’API accessible reste en partie limité. Pas accès DNB. Enrichissement a posteriori des informations. Utilisation API SRU permet de récupérer réponse API sérialisée en XML.

https://www.bnf.fr/fr/service-sru-catalogue-general-de-la-bnf



### Question

Comment envisagez-vous de traiter les annotations pour qu’elles puissent être inteopérables et bien documentées (utilisation référentiel, etc.). Quid IIIF et Open Web Annotation. Cf. Kompakt (choix Voyageur)

Travaillent sur plusieurs projets en même temps. Projet Voyageur impliqué sur les questions de IIIF. Normalement devraient également intégrer IIIF. Se donne la possibilité pour les scènes 3D d’utiliser d’autres outils qui ne seraient pas forcément 3D, comme Potery pour nuages de points, etc.

Collaboration avec musée d’archéologie nationale. Roadmap DPO-Voyager pour ajouter des couches représentation différentes (infra-rouge, etc.). Bénéficierait ici d’imagerie. https://smithsonian.github.io/dpo-voyager/

Résultats OCRisation très bon, pas de mélange des colonnes. Oui possible réintégrer en TEI pour édition. Utilisation Tesseract sur du contemporain.

SRU car déjà une pipeline.

PGD qui permettent déjà de faire prendre conscience d’éléments de bonnes pratiques. Important mais arrive souvent un peu tard. Souvent quand nous sollicite, le projet déjà bien lancé. Là où le plus utile pour voir la mise en conformité des projets et l’adoption de bonnes pratiques, surtout lorsque l’on nous demande des accompagnements en phase de montage de projets sur les volets sciences ouvertes. Permet de prendre en compte ces enjeux dès le début du projet et nous évite à devoir gérer un passif. 

Question situation par rapport Consortium 3D. Beaucoup apporté dans le projet eThesaurus. Quelle ariculation avec LORD ? Au sein de l’atelier pas de formation 
