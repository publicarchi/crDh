# DHNord 2024

https://journees-dhnord2024.sciencesconf.org/resource/page/id/6

## Atelier PictorIA

### Panel: Innovation, traitement et visualisation des données multimodales et médiation culturelle en SHS

*Modération: Philippe Useille (Université Polytechnique des Hauts-de-France (UPHF) - MESHS)*

#### Introduction

*Julien Schuh (Université Paris Nanterre - MSH Mondes)*

Collaboration avec DHNord qui permet à PictorIA d’organiser une journée. Remerciements des acteurs. Quelques mots sur le consortium PictorIA. Consortium Huma-Num dédié à l’analyse automatique des images par l’utilisation d’outils de traitement automatique des images.

Après période de numérisation massive des archives, face à des difficultés pour traiter humainement ces informations. Désormais des outils développés permettant d’industrialiser les processus cognitifs pour apréhender ces documents. Mais outils principalement développés dans des perspectives commerciales ou ultra-contemporaines. Or travaille sur des données anciennes, souvent déteriorées, images anciennes d’objests ayant subis différentes dégradations. Pb d’absence. Mais aussi le contenu même des contenus que nous travaillons situés dans une histoire ancienne. Et souvent modèles entraînés sur des contenus contemporains ou dans lesquelles les données anciennes perdues. Conduit à des faux positifs. 

Créer une communauté de gens intéressés sur ces questions. Mais besoin de se former ou de réentrainer les modèles pour répondre à leurs propres enjeux de recherche. Essayer de créer des standards ou des pratiques communes. Perte d’efficacité ou risque de créer des standards ne pouvant communiquer ensemble. Ex. IIIF. Sait que doit réfléchir collectivement à ce que veut faire de ces outils.

Site du consortium, cartographier ce qui existe. Sélectionner certain nombre d’outils, les mettre en avant.

https://pictoria.hypotheses.org

#### La recherche en SHS au sein de la Fédération de Recherche Sciences et Cultures du Visuel (FR-SCV)

*Yann Coello (Sciences Cognitives et Sciences Affectives (SCALab) / FR-SCV)*

https://fr-scv.fr

https://fr-scv.univ-lille.fr

>En favorisant les échanges et les interactions entre les UMR CRIStAL, IRHIS et SCAlab (CNRS/Univ Lille), la **Fédération de Recherche Sciences et Cultures du Visuel** (FR CNRS SCV 2052) coordonne un programme scientifique pluridisciplinaire visant à étudier, à l'aide des équipements numériques de pointe de la plateforme Equipex Continuum, les processus visuels et les cultures visuelles dans les sociétés passées et contemporaines. Par l'implantation de la FR SCV **au cœur du site d'innovation Plaine Images**, les chercheurs et ingénieurs développent des projets de recherche interdisciplinaires en collaboration avec les artistes et les Industries Créatives et Culturelles.

Projet né d’un 

FR CNRS 2052 Sciences & Cultures du visuel. Société Vanoutryve fermée en 1973. Métropole qui a voulu créer nouvelle dynamique autour de l’image. Autour de 2000. Inauguration Plaine Images, 2012.

Créer un lieu de rencontre interdisciplinaire qui s’appuie sur les outils numériques dans le champ des industries créatives et culturelles. Travail avec trois UMR. Laboratoire **IRHIS** (histoire et histoire de l’art, culture visuelle), Laboratoire informatique **CRIStAL** (sciences du numérique, IA et modélisation), **SCALab** Sciences cognitives et sciences affectives.

Développer un programme de recherche interdisciplinaire pour étudier les manifestations visuelles du passé et contemporaine. Installation dans les bâtiments de l’Imaginarium sur le site de Plaine Images qui accueille 150 entreprises. Développement d’une plateforme technologique labellisée équipex. En relation avec les entreprises de Plaine Images.

Labellisation 2012 Equipe, renouvellement en 2021 dans le cadre de l’équipex Continum qui constitue un réseau de plateformes de réalité virtuelle. Devenus infrastructure de recherche en 2022 pour RV. Relation avec le Fresnoy, école d’art. Artistes en résidence. Picture école modélisation 3D. Artfix, effets spéciaux.

Accueil d’entreprises en résidences, etc. Débute en 2010, en travaillant dans un RTP réseau thématique pluridisciplinaire financé par le CNRS dans la dynamique IRIS. Lauréat équipex en 2012 6M, développement projet autour des Visual studies. Puis obtention CPER 2 à 3M sur 7 à 8 ans. Permet d’animer la recherche sur du temps long avec des projets larges qui incluent de nombreux partenaires. Projets très utiles pour la structuration de la recherche.

CNRS a accepté de nous créer en tant que structure indépendante. Fédération de recherche en 2021. Nouveau projet Continum et nv CPER. Projet COMET sur le métayers ciblé à Lille sur la fédération 2023 (lancement 17 janvier 2025). Projet régional.

Projets qui permettent de travailler sous la forme d’appel à projets et de financements pour accéder aux équipements. Appels à projets, résidences d’artistes, thèses, etc. Formations déterminantes sur des thématiques concernant IA. Générer des dynamiques utiles pour associer les chercheurs et les entreprises.

Plusieurs axes

- construction historique du visuel (Elise Baillieul https://pro.univ-lille.fr/elise-baillieul/enseignements)
- perception cognition en environnement numérique
- modélisation visualisation interaction (données complexes, multimodales, environnement virtuel)
- arts sciences et technologies

100 chercheurs, 5 titulaires et 11 ingénieurs sur contrat. Pas pérenne car surtout financés sur appel à projets. 

Essaye de créer une chaîne d’ingénieurie spécialisée.

Fil rouge compétences

- historiens spécialisés dans la restitution numérique
- infographistes 2D-3D
- Modélsiateur 3D
- Animateur 3D
- Interatcion homme-machine
- Traitement du signal
- Valorisation-transfert

Occulométrie. Restitution numérique de sites anciens disparu. Exemple Camp du drap d’or.

Mise à disposition présentation visuelle utilisant les outils numériques incitant à l’interaction. 

Partie analyse du comportement. Nombreux équipements classiques en sciences cognitives permettant de projeté à haute qualité. Casques avec bonne définition visuelle, etc.

Dispositif TORE, courbe dans toutes ces dimensions. Qualité immersion forte par rapport aux faces des CAVE qui créent des disruptions visuelle. Système de doubvle point de vue. Permet étudier des situation où des personnes doivent interagir sur le même objet.

Tapis de marche pour visualiser des environnements virtuels pour se déplacer dans un site archéologique ou historique. Évite l’utilisation de manettes qui créent inconfort.

Big Blake

Well, expositions de Whistler (Isabelle Enaud-Lechien)

Recontext, restituttion site des tombes. Restitution des peintures en place. Formats très dégradés. Reconstitution du mobilier funéraire. Des hypothèses faites par les chercheurs à partir de mobilier de la même époque conservé à Lille.

Travail sur les rites funéraires.

Projet Get-in-Past. Représentation des danses anciennes à partir de documents anciens. Numérisation des documents avec Computer vision. Reconnaissance automatique puis animation en modélisation MOCAP motion capture pour faire de la médiation culturelle.

Projet qui fait travailler les trois laboratoires au sein de la fédération. 

Rencontre chercheurs et artistes autour création. Interopérabilité des systèmes comment regrouper outils visualisation : Unity, ... engine, dans outils utilisables pour les artistes. Dessin 3D dans un espace numérique. Création visuelle et sonore. Des systèmes différents associés.

#### Discussions et échange avec le public

Effet proteus concernant impact des agents virtuels.

Des projets concernant le droit du numérique avec Juliette Sénéchal. Questions des responsabilités et des accès. Responsabilités.

Pas de travail sur la génération automatique de scènes 3D à partir de scènes 2D. Question du stockage des données et de leur mise à disposition. Cherche à travailler avec Huma-Num pour la formalisation de certains standards de modélisation 3D. Veulent constituer centre d’expertise sur cette question. Pour la génération automatique, pas encore abordé. Des questions importantes car limites des ingénieurs.

Idée du dernier projet un peu cela, créer une plateforme permettant à des artistes de se connecter à n’importe quel environnement pour interagir avec cette plateforme.

Commencé à travailler avec [Houdini](https://www.sidefx.com/products/houdini/) pour certaines restitution automatique de ville. Pour pouvoir se concentrer sur les bâtiments pour lesquels dispose de sources.

Comment se passent les partenariats. Faut-il arriver avec un projet.

Laurence Parrot, coordinateur institutionnelle. Engage à la contacter pour des projets. Si sciences et culture du visuel peut accueillir. Ensuite voir ce que représente en termes d’investissement. Si projet simple sans trop de développement et surtout accès aux équipements facile. Si plus complexe doit travailler avec les ingénieurs. Projets sur appel à projet plus de chances d’être retenus.

### Panel: Vision par ordinateur

*Modération: Daniel Foliard (LARCA – Université Paris Cité)*

#### Projet ERC Discover

*Mathieu Aubry (Ecole des Ponts ParisTech (ENPC))*

https://erc-discover.github.io

https://aikon-platform.github.io

Diplômé Poly, Ingénier des Ponts et Chaussées. Chercheur au laboratoire Imagine école des ponts.

Chercheur en vision artificielle et non en histoire. Le projet sur lequel travaille le plus consiste à faire qqchose assez natruel pour les humains, regarder ensemble d’images et repérer ensemble de choses cohérentes.

Lorsque regarde images satellites, identifie rapidement des éléments récurents. Construire des algorithmes de vision artificielle pour faire ce genre de choses.

Travail débuté sur des enjeux d’histoire de l’art où besoin de détecter des choses semblables. Pas forcément des choses qui aient des noms. Avec des historiens des sciences, pouvoir trouver des copies dans des manuscrits. Ensemble de textes modifiés au cours du temps, ensemble de choses parfois modifiées ou recombinées. Analyse visuelle de texte, si exemple de différents documents formes élémentaires qui sont des lettres que pourrait vouloir comparer entre docuements.

Comment avec des outils de vision artificielle avancer en paléographie. Présentation plateforme à destination des historiens qu’est actuellement en train de construire pour intégrer différents outils d’IA pour comparaison, etc.

Pour l’analyse de texte, avoir un algorithme qui va essayer de découvrir l’alphabet, formes des lettres et reconstruire différentes formes de textes. Positionner lettre à différents endroits et donner couleurs. Apprend prototype des différentes lettres que peut ensuite comparer ou visualiser. Exemple alphabét chiffré. 

Ce type d’analyse permet de faire de la paléographie. Exemple développé dans le cadre d’une thèse. Collecte d’un ensemble de ms avec deux types d’écriture standards, Textualis du N et du S. Et comparaison avec ce qu’en disent les paléographes. Voir sur plein de ms différents alphabet.

Ensuite prototypes que peu comparer et analyses confrontables. Permet aussi de faire des analyses plus fines sur certaines lettres au niveau d’un corpus.

AIKON platform. Construite à partir de deux projets menés ces dernières années : ANR VHS et ANR EIDA. Objectif d’étendre l’utilisation de cette plateforme pour continuer à ajouter des outils dedans. Exemple détection illustrations, plateforme de similarité.

Permet d’ajouter des documents avec métadonnées, possibilité extraire illustrations contenus et de les visualiser. Exemple ms botanique. Possibilité de changer notion de similarité. Possibilité d’annotation des similarité.

Projet EIDA pour les diagrammes astronomiques. Besoin extraire les primitives géométriques de ces diagrammes. Idée de pouvoir comparer les diagrammes et de faire des éditions critiques en comparant ces diagrammes.

Plusieurs algorithmes présents dans cette plateforme. Manière dont sont conçus. Dans tous les cas, travail avec les historiens pour comprendre les besoins et formaliser la tâche qu’ils ont besoin de résoudre. Nombreuses notions de copie différente. Besoin d’aller chercher des exemples. Première chose faite. Ensuite générer des données synthètiques pour produire premiers résultats suffisamment bons pour être corrigés par les historiens par des annotations pour améliorer le traitement.

Réalisé sur 4 problématiques différentes : détectiond ’illustrations, la recherche de similarité, la vectorisation de diagramme, la reconnaissance de textes (à inclure). 

Génération de données synthétiques. Pas nécessairement besoin d’être réalistes. Possibilité d’apprendre copies et éléments entre les deux. Ensemble qui permet de générer des algorithmes fonctionnant sur différentes tâches.

Certains nombres d’algorithmes standards IA. Mais pour découverte formes identifiques dans des gd bases de données. Pas de solutions std. Nbx problèmes que HA ont qui peuvent se ramener à ça.

#### L’IA et les données de Notre-Dame de Paris: de la théorie à la pratique

*Kévin Réby et Anaïs Guillem (ERC n-Dame_Heritage, Modèles et simulations pour l'Architecture et le Patrimoine (MAP) - CNRS)*

Architecte archéologue de formation, formée sur les questions de représentation de connaissances. Termine doctorat à Munich. Données complexes, hétérogènes et intégration de données. Comment transforme de l’information et de la connaissance en utilisant des ontologies. Questions spatio-temporelles, argumentation et hypothètiques. Vocabulaires, etc. IA neuro-symbolique.

Kévin Réby informatien, spécialisé en deep learning. Dès que nb données et label peut faire plein de choses, classifications, etc. Intéret de pouvoir travailler avec des experts. Exploiter puissance Deep Learning et IA peu classique que va présenter.

Projet ERC, complexe dense avec 10aine de groupes de travail thématiques. Structure, bois, accoustique, décoration, etc. qui regroupent 200 chercheurs produisant des données hétérogènes avec des modèles différents et des problèmatiques distinctes. Gros enjeux d’intégration de données. Idée de voir comment utiliser l’IA pour intégrer tout cela.

Exemples d’interogénéité des données. Outils Aïoli basé sur la photogrammétrie. Outils qui vient être complémenté ArchéoGrid pour archivage. OpenTheso pour les vocabulaires.

Question de l’interopérabilité entre les outils mais aussi dans les workflow. En IA plusieurs courants historiques :

- GOFAI KR. (« Good old fashioned artificial intelligence ») Logique, ontologies et systèmes experts
  trouver conceptualisation partagée entre les humains pour se comprendre. Utilisation ontologies SKOS, CIDOC-CRM. Deux niveaux : ontologies et données pour travailler sur du raisonnement, des inférences, règles pour enrichir les données.
- ML et DL
  apprentissage statistique, où le but utiliser grandes quantités de données pour retrouver des pattern caché dans les données. Au lieu d’avoir systéme expert où humain définissent les règles. Mais va produire ces règles automatiquement. Effet de noir car ne va pas pouvoir expliquer comment ces catégories produites. 

Besoin des deux systèmes pour pouvoir profiter des avantages de l’un comem de l’autre. Enjeu important de la qualité des données. Mieux vaut en avoir moins de bonne qualité que de mauavises.

**IA neurosymbolique**. Autre tendance qui est en train de se renouveller ces dernieres années. Consiste à trouver une interaction entre ces deux tendances. Nouveaux journaux, etc.

Ex. Intéret LLM pour enrichir des graphes de connaissances. Friction créative enrichissante. À la fois du raisonnement ou de l’entrainement sur ces données. Tantôt faire de l’extraction que de la représentation.

Première chose faite travailler sur la segmentation sémantiques des images. Reconnaissance des éléments et associer des classes aux pixels. Des images annotées à la main et données textuelles dans OpenTheso.

Premier modèle utilisé SAM entraîné sur 100M images zéro shot learning. Capacité de généralisation et reconnaitre des objets jamais vus lors de l’entraînement. Plus possibilité d’utiliser un prompt. Dans les expériences, fonctionnait mieux avec la bonding box. Donc autre modèle pour générer bounding box, puis utilisation SAM pour reocnnaître segment. Plus CLIP pour donner label correspondants. Mais derniere étape ne fonctionnait pas car images jamais vus. Utilisation des données textuelles dans OpenTheso pour les lables produits apr les humains.

DINO Déterction objets. Knowledge distilation

Donne ensuite à SAM pour détection masques

Puis association label CLIP

Inteprétation sémantique 

- identification des phénomènes de dégradation, etc.

CLIP réutilise les données situées dans OpenTheso, outil de gestion de thesaurus. Réutlisation de ces vocabulaires contrôlés structurés en SKOS.

Utilisation LLM. Prompt pattern pour extraire connaissance.

AUtre expériemnetation Semantics of Complex Spatial Data. Interrogation de requêtes spatiales complexes. Méréologie et topologie. 

#### Discussions et échange avec le public

Évolution des pratiques des chercheurs, meilleure reconnaissance des besoins concernant les métadonnées. Automatise aussi au maximum.

Peut utiliser plateforme Jean Zay

Comment monter des outils génériques qui répondent à des tâches courantes et fréquentes. Mutualisation et calcul.

Exemples montrés pour ND, tous sans entraînement. Donc peut êrte réalisé facilement sur un ordinateur local. Maintenant fine-tuning, besoin de passer sur Jean Zay. Prend plusieurs jours.

### Panel: Circulations d'images

*Modération: Marion Charpier (Musée des Arts Décoratifs (MAD))*

#### Circulation d’images dans la presse ancienne

*Daniel Foliard (Laboratoire de recherche sur les cultures anglophones (LARCA) – Université Paris Cité), Julien Schuh (MSH Mondes, Université Paris Nanterre)*

Projet qui débute l’année prochaine. Depuis plusieurs années essaye de développer des chaînes qui intègrent des outils de reconnaissance automatique des images pour répondre aux enjeux de massification issues de la numérisation massive des documents patrimoniaux pour répondre à des questions SHS.

Archives d’objets créés au moment de la massification de la production d’images. Moment où photographie et techniques impression reconfigurent le paysage de la culture visuelle. Comment redonner vie à ces archives massives et produire des processus de remémoration actives pour que ces bases de données configurées selon des protocoles ou des configuration bibliothéconomiques ne répondent pas aux manières dont ces objets sont utilisés par des humains. Archives mortes car des formats pas directement appropriables. Comment en refaire des éléments d’analyse historique et d’appropriation. Comment recréer du lien entre ces images. Passer du désordre documentaire au domaine du vivant. Outils analyse puissants de ces fonds numérisés.

Adapter ces outils à nos propres pratiques de recherche en se demandant comment reconfigure nos pratiques de recherche et directement adossés à des corpus d’institutions patrimoniales.

Consortium. Question des agences photographiques d’images. Rejoints par l’image center de Toronto (collection Black Star). Agence Roger Viollet.

LIPAD et LIP6 deux labos IA.

Créer jeux de données de terrain. Pb similarités. Deux fonds clefs, Black Star (Live Time et ...). Fond moins connu, fonds Forbin donné au Ministère de la Défense. Agent clef dans la naissance de la culture visuelle française qui a agi comme agence image, joue le rôle de traducteur de la culture anglophone. Fond brut qui sera numérisé intégralement 60 000 images. Réécrire l’histoire de ce fonds en l’entraînant sur les fonds Roll et Roger Viollet ainsi que Library of Congress pour faire un lien entre le contenu visuel de ces images et la sémantique. Fonds sans métadonnées.

Exemple 

- Dégradation par reproduction rotogravures, sur lesquelles les systèmes ne fonctionnent pas bien. 
- Retouches par recadrage
- Tampons origines et métadonnées

Automatisâtion et enrichissement des métadonnées. Pouvoir extrapoler à autres fonds comme *Le Petit Parisien*.

Programme de recherche chargé à l’intersection Computer vision, etc. Ateliers réguliers. Premier à Toronto en mars prochain. Arriver à une plateforme qui puisse être de l’ordre de l’alphabétisation pour les historiens de la photographie et des archives.

#### Circulation d’images : Projet ANR CROBORA / Les voies des images

*Matteo Treleani et Shiming Shen (SIC.Lab - Université Cote d'Azur)*

https://crobora.hypotheses.org

Projet ANR terminé en juillet dernier. Idée du projet de pouvoir travailler sur l’image de l’Europe à travers un ensemble de reprise d’archives européennes, France et Italie.

Travailler sur l’administration des images. Transports, voies du visible. Une perspective du matérialisme numérique où regarde les logiques circulatoires du visible à travers les éléments techniques, socio-documentaires qui régissent leur fonctionnement. On pourrait donc dire que l’on considère les images comme des documents d’archives. Un prisme circulatoire pour travailler sur les images de manière opératoire.

Toutes les images sont réalisées, documentées stockées pour être retransmise. Il y a donc une logique archivistique qui gouverne le monde des médias. Et même que le monde industriel repose sur ces réemplois. Logique de réemployabilité. Mode de circulation qui en conséquence influence ce mode de circulation. Malgré UGC, répétition qui est la norme et ne fait qu’exploser avec le numérique, mais déjà le cas dans le monde audiovisuel.

Deux conséquences : interroger les images à travers la notion de reprise. Analyser tout ce qui est diffusé au moins deux fois. En deuxième lieu, fragmenter les émissions pour analyser les images qui les compose. Souvent patchwork d’archives issues de différentes sources. Passer de l’unité télévisuelle de l’émission ou du sujet du JT pour en saisir les séquences qui la compose.

Selon étude avec FigerPrint ⅔ contenus télévisuels sont des reprises. Un point de repère car plus en réalité (car différents biais, logiciel n’analyse que des séquences de 7s min). Dans le corpus entre 75 et 100% des sujets constitués de reprise. JT du soir 2000 et 2021, chaînes françaises et italienne. Contenu du dépôt légal INA.

Exemple Signature du traité de Rome. Se concentrer sur la circulation d’une image spécifique.

Trouver deux images dans le corpus. Mesure de similarité cosinus pour trouver images similaires. Seuil fixé à 0,80.

Partenariat avec l’INA pour utiliser [SNOOP](https://www.ina.fr/institut-national-audiovisuel/equipe-recherche/projet-snoop). Apprentissage par renforcement. Importe une image et recherche images similaires dans flux en ligne YouTube ou DailyMotion.

Détection de sentiments autour d’une même séquence. Évolution des tendances thématiques des reportages.

Modèles multimodaux comme CLIP. Souvent relation entre le texte et l’image très figée. étiquetage thématique très limité. D’un point de vue sémiotique, le sens en production, un processus dynamique qui dépend beaucoup du contexte. Raison pour laquelle mis en avant l’utilisation de la vision par ordinateur pour étudier la circulation du sens des images.

#### Discussions et échange avec le public

Vocabulaire colonial, s’intéresser à la question circulation image et compréhension géopolitique. Forbin progressiste qui achète certaines imaegs pour mettre en valeur des événements peu couverts. Exemple Tripolitaine.

Problèmes de reconnaissance de similarité avec les modes de reproduction. Dégradation des papiers, différents types de numérisation, et modes de reproduction. Système pas suffisamment robuste. Nous a forcé à créer des images synthétiques en imaginant des dégradations extrêmes. Procédé roto... avant le demi-ton. Pb de cache qui oblige à repenser les approches. De bons résultats. Aussi un aspect de retouches massives. Des images parfois extrêmement composites ! photomontages, etc. Pose beaucoup de questions sur l’image comme source.

Tracer les origine un travail très important. Automatisatisation du travail possible mais le faire à grande échelle compliqué. Besoin de disposer de sources importantes. Périmètre important pour chaque séquence.

Depuis les origines de la circulation de photographie de masse, question de véritée posée. Important d’avoir un discours sur ces questions. Mais que les photographies soient vraies ou pas à cette échelle pas le pb. Analyser l’image comme un processus.

### Panel: IA et institutions patrimoniales

*Modération: Jean-Christophe Carius (Institut National d’Histoire de l’Art (INHA))*

#### HTR, correction d'OCR, fouille d'images, segmentation de journaux : panorama des projets IA à la BnF

*Sébastien Cretin (Bibliothèque nationale de France (BnF))* Expert - chef de projet OCR et formats éditoriaux 
01 53 79 57 76 [sebastien.cretin@bnf.fr](mailto:sebastien.cretin@bnf.fr)

Panorama rapide des projets en IA menés à la Bnf. Premières preuves de concept qui datent de 2016 autour de la fouille d’images, rassemblement d’images par similarité. Adhésion communauté IA4LAM et conviction que nécessaire de rédiger une feuille de route 2019.

Conviction que besoin intégrer stratégie globale. Améliorer organisation R&D, structurer réponses Appels à projets. Développer les compétences des agents. Important pour que discussion raisonnée avec acteurs techniques...

Aujourd’hui plus d’une 30aine de personnes impliquées dans des projets IA. En interraction avec une cellule IA de 3 à 4 membres. Pilotée par un chargé de mission au sein des services...

Projets IA sont des projets standards. Soit besoins internes soit partenariat. D’abord piloté par la cellule IA. Puis phase indusrtialisation, direction qui décide et création équipe dédiée chef de projets et experts. Actuellement un seul projet a atteint cette phase : Gallica Images, indexation automatique des contenus.

Effets de modes, et cycle de vie des modèles frénétiques qui peut mettre dans l’embarras pour faire des investissements. Nombreux besoins qui impliquent de hiérarchiser les projets.

Diapositive des projets, et niveau industrialisation (très intéressante).

HTR en phase exéprimentation à la Bnf. Se confronter énorme problème de Babel, nombreuses langues et écriture. Priorité de construire des partenariats avec les chercheurs. Tester les modèle mis en place. OCR Kraken, parse Python, format pivot et phase évaluation.

Chercheurs bien plus compétents que nous pour traiter des écritures anciennes. Donc valoriser leurs productions. Dialoguer pour des formats compatibles avec nos collections numériques et les intégrer. Avoir des produits HTR de qualité. Projets hébergés au DataLab sur des fonds spécifiques.

OMR Projet CollabScore ANR, Irisa, Cnam, Iremus. Transcription de partitions. Présentation IDAR.

Autre grand projet, correction OCR avec mistral. Projet ArGiMi. Sait que grands débats. Papier école polytechnique qui dit que pas possible mais des pour. Mistral AI, Ina, Artefact, Giskard. Des pour et des contres qui montrent que espoirs fondés. https://www.artefact.com/news/le-consortium-argimi-remporte-lappel-a-projet-sur-lintelligence-artificielle-generative-lance-par-bpifrance/

Autre projet dont attend beaucoup. FINLAM, avec Olitis de Rouen et Teklia. Fondation and integrated models for archives and museums. https://projets.litislab.fr/finlam/ 2028 ouverture à Amiens du Conservatoire international de la presse. Projet de déplacement des collections physiques qui s’accompagne d’un effort important sur les collections de presse. Mise en avant de ces collections. Mais aussi un passif car en 2016 dans le cadre d’un marché public traitement sur 1,2 pages par opérateurs. Ici voir si peut espérer que des processus d’IA permettent de concurrencer un travail humain.

Projet Gallica Images 2024-20.. entre en phase d’industrialisation. Indexation automatique de plusieurs millions d’illustrations.

#### Indexer et explorer les collections du MAD Paris : exemple de la collection Jean Royère

*Marion Charpier (MAD)* Historienne de l’art, master TNAH

Plus au MAD depuis un mois. À l’EnC pour travailler sur les collections de photographies du MAD. Présenter projet mené l’année dernière sur les fonds de Jean Royère et permis de réflechir au projet actuel.

Quelles ont été les motivations initiales pour se lancer dans un projet IA. Initiative de la conservatrice des dessins. Constat pragmatique 1M objets dont 700 000 pas encore inventorié... ⅔ collection. Des enjeux majeurs : obligations réglementaires SMF et enjeux de rendre les collections accessibles au public conformément aux missions dévolues par les créateurs du musée.

Pour terminer inventaire avec les méthodes traditionnelles 643 ans ! S’est donc posé la question de tester de nouvelles innovations dont IA. Pas traiter tous les fonds de la même manière mais se concentrer sur certains fonds. Production de Jean Royère. Nombreuses sollicitations sur cette collection.

Un inventaire du travail de Royère mais dessins pas décrits. 4 grandes catégories d’objets. GRandes gouaches, petites goaches, vues ensemble et calques d’exécution.

Reconnaissance des objets. Mise en place systéme de prise en main facile pour prise en charge. Modèle supervisé. Vérités de terrain, entraînement de modèles, et phase de correction et d’annotations. Supprimé phase de test pour déployer modèle. 

Résultats limites de YOLO. Matrice de confusion qui permet de voir les classes qui sont confondues. Certains objets qui nous intéressent échappent encore à des modélisations précises.

Résultats limités avec CLIP. Besoin d’entraîner les modèles pour les appliquer aux collections de Jean Royère.

Première année qui a permis de développer une réflexion appropriée pour travailler avec des modèles itératifs (car renouvellement des modèles). Méthodes pour amener robustesse. Tester d’autres modèles pour approche par IA.

Blocage technologiques mais aussi culturels. Besoin de convaincre les équipes internes. Projet qui débute sur médiation outils IA pour s’instaurer dans les pratiques du MAD.

prpojet Tornach

#### Le projet HikarIA avec le Musée Guimet

*Solène Tarride (TEKLIA)*

Projet mené avec le Musée Guimet. Doctorat Institut des sciences appliquées de Rennes. Nouvelels écriture, etc. Teklia surtout experts en analyse de documents. Mais ici description sémantique collections photographiques arts asiatiques anciens.

Collection de photographies anciennes japonaise du 19e. 300 albums, 18 000 photographies produites par des studio photo lors de l’ouverture du Japon sur le monde. Albums touristiques souvenir.

Explorer modèles IA pour analyser automatiquement cette collection photographique. Modèles généralement pas entraînés sur ce type de corpus.

Exploré plusieurs modèles : 

- modèles de légendage ou de description comme ChatGPT. 
- détection d’objets YOLO ou SAM qui localisent les objets sur l’image
- modèles de recherche sémantiques: ou encode des images puis recherche de similarité.

Teklia, passage à l’échelle car outils spéciaux pour traiter les documents de manière massive : Arkindex et Callico qui permettent importer des documents puis entraîner les modèles pour applications larges.

Callico pour annotation.

Modèels de description. Founit une image avec instruction qui permet soit de donner du contexte soit des instructions. Génération d’une description plutôt juste. Mais verbeux.

Génération de légendes. Plus important de pouvoir générer des mots-clefs sur l’image. Ce que ces modèles sont également capables de faire. Le format de description peut être adaptée à des finds d’archivage ou d’indexation.

Trois modèles différents évalués CLIP (OpenAI), Qwen2.5 (Alibaba), ChatGPT (OpenAI payant). 

Génération de légendes évaluation

La chance de déjà disposer de descripteurs sur ces collections. Avec mots-clefs et description de types de photographies. Identification des monuments ou des lieux.

Sélection de 6 albums 275 modèles images. Le prompt continet la liste des balises possibles. Founit un jeu de tags complets 1034 tags (mots communs français). Jeu de tags réduit (les 190 tags) du sous-ensemble d’images.

Comparaison des trois modèles avec le même prompt. ChatGPT de loin bien meilleur que les modèles open source. Sur l’ensemble de tags réduits précision forte 75%. Précision chutte beaucoup lorsque modèle complet.

Comme privilégie open source. Finetuné CLIP. Arrive à se rapprocher de ChatGPT.

Essayé de comprendre pourquoi performances basses. En comparant même si précision et rappel bas. En réalité, tags générés par ChatGPT plutôt corrects. ChatGPT en oublie certains mais ajoute aussi des termes manquants.

Passé au peigne fin les prédictions de ChatGPT et intégration termes corrects. Réitération atteint précision 80% Montre bien les limites de ces évaluations et enjeux de métriques.

Les modèles de recherche sémantiques CLIP. Encode ensemble des photographies avec CLIP. Calcule représentation vectorielle et recherche images similaires. Cheval et recherche visuelle pertinente. ex. Cheval, Cérémonie du thé, Poissons (un peu moins bon), etc. 

Visualiser les vecteurs d’images. CLIP permet d’encoder des vecteurs qui peuvent être visualisés. Permet d’analyser de manière simple une grande collection d’images.

Modèles de détection d’objets. Yolo-World pour identifer les personnes. Comptage des personnages. Identification des photos de groupe, de portraits, déterminer cadrage (% bounding box). Identification des modèles récurrents dans le corpus.

Conclusion analyse des performances des modèles contemporains pour analyser photographies anciennes. Fonctionne plutôt bien pour un vocabualire contemporain et généraliste. Permet d’analyser plus facilement les collections photographiques japonaises.

Besoin que les chercheurs regardent ces photographies et nous produisent des résultats.

#### Discussions et échange avec le public

Souvent pour numériser un corpus, besoin qu’ait été inventorié préalablement. Est-ce qu’il y a des 

Projet Tornach?? idée d’inveser le processus. Créer des modèles pour accélérer le processus pour l’inventaire.

Bnf sur le catalogage plusieurs choses. Numérisation exemplaire à la Bnf nécessite que soit catalogué au préalable. Opération qui précède. Bnf 5 personnes qui travaille à temps complet pour intégration du catalogage dans la numérisation. Ce qu’essaye de développer à la Bnf, ce sont des processus d’aide au catalogage pour développer des processus qui améliore les métadonnées.

Correction OCR. Bnf vont s’en tenir OCR. Pour les transcriptions manuscrites sans doute ouvre boite de pandore. Dans le paradigme institution patrimoniale s’en tiendra sans doute aux caractéres lisibles dans le document. Fidélité aux écritures.

Grand risque lié aux corrections LLM pour éviter réécriture... Un gros écueil à éviter. Des modèles HTR entraîné. Modèles de développement d’abréviation.

### Ateliers

Dicover-demo, fonctionne en miroir avec Eikon. Plateforme développée à l’École des ponts dans le cadre de l’ERC Discovery pour proposer des démos et interface pour modèles.

https://tinyurl.com/dhnord-discover

Connexion sur la plateforme. Sélection d’un jeu de données pour les tests.

Charge les modèles et visualise résultats. Possibilité de télécharger les crop en format TIFF sur son ordinateur.

Plateforme modulaire destinée à accueillir différentes experiences sur le même dataset. Plateforme encore en développement possibilité de recommencer extraction sur même jeu de données.

Utilisation de la même API. Deux plateformes. Une en partenariat avec différents projets. Showcase censée être beaucoup plus minimale.

Plateforme pour corpus de données satellitaires et historiques. TRavail avec deux projets sur la diffusion de l’imaginaire scientifique. VHS et Eida pour voir comment les diagrammes ont pu se diffuser dans l’astronomie. Modèles inspiration ptoléméenne.

Ambition

- accessibilité
- intégration
- données : possibilité de correction es résultats

Données entraînement. Plateforme développée par Robin Champenois et [Ségolène Albouy](https://github.com/Segolene-Albouy). Étudiants École des ponts. Un projet collectif.

Articulation en deux blocs. Un front utilisant Django et une API Flasq déployée sur un GPU pour faire différents traitement. Bipartition qui permet d’être plus modulaire et éviter concurrence de processus et mettre GPU seulement sur GPU. PErmet aussi avoir un même outil pour différentes utilisations avec différents front.

Clustering (actuellement désactivé). Modèle pour extraction de watermark. Un modèle de vectorisation de diagrammes. Un modèle d’extraction et de similarité.

VHS et Eida branchés sur autres modules.

Yolo et Doc Extractor (pipeline pour générer de fausses docuemnts historiques, T. Monier) De même pour la détection de copie, entraîné sur des motifs synthétiques. Résultats intéressants pour retrouver des correspondances entre des simgaes.

Shen, Xi, Alexei A. Efros, Armand Joulin, et Mathieu Aubry. 2022. « Learning Co-Segmentation by Segment Swapping for Retrieval and Discovery ». In *2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)*, 5078‑88. New Orleans, LA, USA: IEEE. https://doi.org/10.1109/CVPRW56347.2022.00556.

Modèle développé par ?? pour détection de diagrammes. Modèles reposant sur des transformers.

Cluster repose sur méthode Deep transformation-Invariant Clustering idée de travailler sur modèles invariance aux transformations 2020. Reconnaitre une image indépendamment de la rotation. De même transformation affine, colorométrique, et reconnaissnce visuelle.

Installation du repo. Téléchargement des modèles. Tester interface graphique en local. Puis travail sur l’API.

En local possibilité d’avoir directement accès aux résultats bruts des extraction (prochainement disposnible). Bounding box calculés en valeur relative. 

Extraction de données support pour d’autres extraction de données. Donc souhaite par exemple pouvoir les utiliser pour similarité. Dans Sharedocument/extraction un fichier JSON avec extraction et crop défini par valeurs absolues, etc. Bbox un encodage hexadecimal de ces crop. Une annotation au format de base utilisée par Yolo, aevc nom images et dimensions. Ceci pour les formats bruts.

Idem pour les watermarks

Possible de travailler avec l’API REST. Un fichier JSON avec informations minimales. Possible de communiquer un manifeste Bnf et un nom de modèle. Possible de lancer la requete CURL en donnant comme référence le JSON.

API renvoie un id de l’expériment et un tracking ID qui permet d’obtenir un statut pour monitorer diverses tâches à distance.

Document journal, clef données dans mon JSON. Document qui peut être soit un Zip soit un manifeste. Actuellement travaille sur la gestion des dataset pour pouvoir importer images, ou zip d’images. Annotations et images téléchargées. Annotation avec coordonnées.

Pour les watermark idem, mais besoin chemin image. 

Aussi possible d’utiliser les modules dépourvus d’interface graphique comme la recherche de similarité. JSON qui comprend un certain nombre de document. Similarité qui se calcule par paire de documents. Recherche dans les images extraites ce qui est comparable dans autre ensemble de documents.

Matrices de similarité au format numpy, un format compressé pour des matrices. Indice de similarité cosinus. AUtres indices.

http://www2.culture.gouv.fr/documentation/archim/Batim.html

### DVT Distant-viewing toolkit

https://github.com/distant-viewing/dvt

Collection dataset et outils pour faciliter le travail sur les images mouvantes.

Second tutoriel https://github.com/distant-viewing/dvt/blob/main/tutorials/Distant_Viewing_Tutorial_2_Network_Era_Sitcoms_and_Visual_Style.ipynb

Essayé être très robuste dans le notebook. Montrer avec de pertits exemples comment travailler sur courte vidéo.

Importance des plans pour comprendre la relation entre les personnages. 45’’ que va analyser de ce point de vue.

Plusieurs formats avec lesquels possible de travailler. Enjeux échelle des corpus.

DVT avantage de travailler sur des vidéos. Faciliter la vie.

Analyse temporelle de la luminosité permet déjà d’identifier un certain nombre d’aspects.

Pour détection des plans. Segmentation en pt morceaux. Seul à travailler nativement sur fichier vidéo. Sans production images individuelles.

Produire ligne pour segmenter plan et déterminer longueur des plans pour avoir un sens d’à quelle vitesse viennent les plans.

Pour simplifier un tableau pour travailler directement.

Détection de visages. Voir qui est sur l’écran et avec qui. Gros plans, closeup, etc.

Test de similarité avec produits matriciel.

Quand travail avec grand corpus pas nécessaire de travailler sur ensemble des plans. Détection de scènes particulières. Réduire le temps de travail.

Intéressant car contredit idée que l’une des émission copie l’autre.

Beaucoup travaillé avec des photographies mais documentaires. Peu avec les images d’art. 

Photogrammar débuté 2010.  https://lyonelkaufmann.ch/histoire/2022/07/03/photogrammar-un-laboratoire-derudition-numerique-sur-la-grande-depression/

Première image sur laquelle travaillé, images art, pb identification.

Aimeraient travailler plus de formes narratives.

## DH Nord 2024

### Discours introduction : « 10 ans de DHNord ! »

*Philippe Useille (UPHF)*

Sous la direction de Martine Benoît que la MESH a lancé DHNord en 2010. Des humanités numériques, des outils, des méthodes... Les directeurs successifs de la MESH ont continuement appuyé le domaine.

Aspects méthodologiques et spécifiques au domaine. De plus en plus sujets contemporains ou réflexifs. 2016, théorie et critique. 2018 matérialité de la recherche en SHS. Collaboration entre acteurs, liens société, etc. Encourager la réflexion épistémologique et promouvoir la diffusion des connaissances et des pratiques.

Donner du temps aux intervenants. Favoriser les échanges pour mieux identifier les problèmatiques pour le Colloque DH Nord 2025.

### Search and Exploration of Documentary Photography Using Multimodal Large Language Models

*Taylor Arnold et Lauren Tilton (Université de Richmond, Virginie, États-Unis)*

Distant viewing. Photographie homme sur cheval et chien. Qu’est-ce que cette image ? que veut faire le photographie ? Quel message convoie ? Comment véhicule le message ?

Processus d’interprétation des images. Paul Valéry décrit le processus d’interprétation des images comme « looking in other world forgetting the name of the things that one sees ».

Comment ce système fonctionne-t-il ?

Challenge pour penser computer vision. Série de pixels et array de nombres. Peuvent representer le même concept.

Pourquoi si différent comme compréhension image. Exemple image de niveau de gris. Détail œil, sans contexte ?? si zoom out, contexte et comprénd image.

Computer vision basé sur la visualité humaine. Il existe d’autres manières de voir dans le monde. Manière de voir une question de 

Steve Anderson suggère de théoriser les technologies de vision de nouvelle manière. John Berger, Lisa Cartwright, Stuart Hall, Elizabeth Losh, Tara McPherson, Lev Manovitch, Marita...

Pourquoi est-ce nécessaire ? Distant viewing une théorie de l’exploration computationnelle des images à travers l’application de la vision computationnel et pourquoi est-ce nécessaire ?

- nature mimétique des images qui réclame analyse computationnelle parte de l’extraction de métadonnées sémantiques en utilisant la vision computationnelle
- processus construction annotation médiévismes computationnellemeent comme forme de viewing
- application de la vision computationnelle n’est pas un processus neutre, engage dans des manière de voir socialement médiée de voir et encoder dans algorithmes manières dont utilisées.

Rmq

Pas de di