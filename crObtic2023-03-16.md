# Journée d’étude Littérature et numérique, Obtic, 16 mars 2023

IEA

Voir comment l’informatique peut permettre de travailler la littérature mais aussi comment la littérature peut informer nos pratiques numériques.

GPT4 évaluation sur des examens. Mais planté en histoire et en littérature. Une résistance du littéraire ?

## TAL et analyse littéraire

### Thierry Poibeau, Par une nuit d’ivresse ? Faire style ? L’analyse automatique de textes littériaries.

Réflexion menée avec de nombreux collègues au Lattice.

Analyse de roman, pas théâtre et poésie

Approche supervisée ou non supervisée (dans la quelle ne sait pas ce que l’on cherche).

Comment rendre compte d’éléments caractéristiques du roman comme le suspense, qui sont peut traités.

Annotation supervisée, le projet BookNLP

Un projet en cours depuis 3 ans au LATTICE. Projet développé par David Bamman (Berkeley) vers 2014-2016.

But obtenir des outils adaptés à l’annotation de roamans

- personnages (pas des entités-nommées)
- coréférence
- événements
- prises de parole des personnages
- Tâches classiques, POS, Syntaxe, Métasens

Résultats

Multilingual BookNLP nouveau projet obtenu en 2020. Créer des corpus annotés avec le même schém ad’annotation.

Au LATICE idée d’annoter même type de corpus pour le français.

Pour commencer, disposer en premier lieu de corpus. Pas toujours disponibles. Le plus coûteux en terme d’annotation, la co-référence. Un projet d’un collègue pu être utilisé. Taille équivalente à la base annotée pour l’anglais (LitBank 2014, BookNLP étant les outils).

22 extraits de romans 19e et 20e siècle. Libres de droits, diffusés librement et gratuitement. 10 ou 20 000 mots.

Difffusés sur GitHub.

Campagne d’annotation 2021 (janvier à août)

- Quelques textes annotés en triple aveugle, puis discussion/adjudication
- le reste du corpus --> annotation simple avec révision rapide
- Annotation avec TXM

Corpus de 184 000 mots (peu pour l’apprentissage, mais beaucoup pour l’annotation).

Les entités sont principalement centrées sur la notion de lieu. Les catégories de Maman ont été reprises de manière directe. Queston des personnages, quid des personnages non humains ? Lieux GPE, Loc, Fac. Véhicules, indications temporelles, fêtes, etc.

Chez Bammman en plus supersense (en fait, familles sémnatiques, animaux, vêtements). Idée de retrouver dans certaines ressources des ensemble de nom qui se rattachent à une notion.

Plusieurs viewers disponibles pour le corpus annoté.

Problèmes fréquents. Personnages de différentes natures. Question des surnoms. Groupes nominaux avec des déterminants. Mystères de Paris difficile avec les analyseurs.

Co-référence, basée sur le projet antérieur Démocrate. On n’annote pas les noms abstraits. On ne retient que les chaînes correspondant à un type faisant partie du modèle BookNLP.

- problème des longues chaînes de coréférence
- problème d’annotations Democrat à corriger

Travaux en cours

Citations/niveaux de discours. Travail en collaboration avec Obtic/Scai. Reprérer les dialogues et les prises de parole. 

Tout ce qui relève de la structure du roman, pas encore dans l’annotation.

Mise au point d’annotateurs dédiés.

- apprentissage à partir d’annotation.
- Mobilisation de BERT
- Puis finetunig pour adapter à la tâche et obtenir des outils d’annotation qui correspondent à la tâche que l’on veut.

En étendant le corpus d’apprentissage, marge de progression possible.

Mesures non adaptées aux textes longs. Les résultats sont globalement bons malgré la grande variation des exemples et le volume limité. Point de départ vers d’autres études (personnages, agentivité en fonction du genre). Peu de plublication car idée de créer une base de démarrage pour d’autres études.

#### L’approche non-supervisée

Peut-on faire émerger des caractéristiques du texte sans déterminer ce que l’on cherche. Fait penser à la textométrie, une approche statistique qui s’est développée en France il y a quelques années. Mise à jour de caractéristiques du textes que révèle l’analyse de données.

Reprend idée de segemntatios répétés.

Dominique Legallois et al. 2016 proposé reprend idée de motif.

Analyse mrophosytaxique du texte

sur cette base conserve

- les formesdes unités invarianes
- les lemmes de certains verbes très fréquents
- les catagories morphologie-syntaxique

Les romans sentimentaux.

Difficile à interpréter pour la littérature générale. Mais lorsque l’applique à des romans très stéréotypés comme Harlequin. 

Marche bien mais pb d’interprétabilité. Une étape de triq ui est problématique. Sentiment que repère ce qui est bon. Mais du point de vue de l’analyse automatique, s’attend à ce que le modèle fasse émerger ce qui est saillant dans les textes. Savoir si cette étape d’interprétation est nécessaire. Et question de la diff entre l’idiolecte et le style. Est-ce que ce que l’on repère sont des traits d’évolution de la langue.

Analyse des motifs

- Legallois, Dominique. 2015. « Comment appréhender la déviance argumentale ? » *Pratiques. Linguistique, littérature, didactique*, no 167‑168 (décembre). https://doi.org/10.4000/pratiques.2651.

Pense que fort par rapport au stylisticien. Ce que trouve plus systématique mais peut-être moins stylistique.

Des outils adaptés au domaine littéraire. Mais lorsque trouve les personnages. Souvent ne veut pas les analyser. Ce que veut c’est faire autre chose. Une étape mais pas une finalité. Une complémentarité à trouver entre approche supervisée et non-supervisée.

Voir que s’intéresse à des choses que sait calculer. Pas des entités nommées. Mais quelque chose qui me travaille. 

Sans doute pas possible de faire du Genette automatisée. Le propre du roman semble être la différence entre la discription et la narration. Des collègues à Darmstadt explorent la notion de scènes. Si on pouvait disposer des caractéristiques qui sont le propre du roman, serait vraiment très intéressant.

Chemin qui est en train de se développer entre le TAL et HN

#### Discussion

Possible de travailler avec interface sur romans 400p. Au-delà, il faut du GPU et des ressources plus importantes.

### Joana Galleron

Dans un laboratoire de TAL à la fois par frustration et naïveté.

Voulait reconstituer pièces disparues. Et TAListes prétendant que repérer les personnages dans les pièces de théâtre réglé. Pas le cas.

Possibilité de rendre plus accessible ces techniques grâce à de nouveaux consortium. Exemple ARIANE (Analyses, Recherches, Intelligence Artificielle et Nouvelles Editions numériques)

L’identificationd es personnages avec BookNLP. Co-référence, ajout d’étiquettes avec TXM. Actuellement annotation automatique.

Corpus de romans du 18e siècle. Bien de disposer OCR propre et modernité. Formes du 18e intéresantes pour les 18e iste mais n’aident pas la machine pour faire de l’apprentissage automatique.

Gardé le découpage sans essayer de rééquilibrer le corpus. Des longueurs bien au-dessus de la co-référence.

CamenBERT pas de la langue 18e. Peut-être qu’avec DalemBERT va mieux marcher.

Co-occurence. Personnages de 2e niveau. Forment des paires. Un espace des personnages

Plusieurs types d’erreur. Dont les référents.

Plutôt bon mais en rate. Par contre scinde les chaînes. Pour le même personnage à l’échelle du roman.

Taux de concordance 86% marque aussi des choses qui n’en sont pas.

Caractéristique des romans du point de vue de l’utilisation des personnages selon les romans. Caractéristiqeus des auteurs ?

Conclusions : beaucoup de marge de progrès possible de BookNLP. Travailler sur la fenêtre d’attention. Car actuellement 512 tokens. Changer de modèle de langue. Etre moins ambitieux et regarder références mal choisies.

Aller au-delà dans l’annotation pour leur associer des statuts sociaux. Chaînes de co-référence, intéressant que si peut créer des chaînes de co-références, une possibilité de regarder l’imbrication des chaînes pour créer des graphes de coprésence et d’imbrication.

### Jean-Baptiste Camps, La stylométrie au service des littératures anciennes, des origines au 17e siècle

Principes et leur application des littératures anciennes.

Le style, c’est l’homme même. Buffon. 1753, discours sur le style. 

Souvent le fait pour identifier un individu à l’origine d’un texte. Sans doute un abus de langage ce que la stylométrie appelle le style, la signature d’un individu dans un texte donné. Parle de stylomme, ou d’emprunte digitale stylistique.

Marqueur signifiant identifiable. Sans doute plus un idiolecte, un des types de variation dans la langue, ici entre les individus et entre en concurrence avec d’autres types de variation dans l’espace, ou entre les niveaux de langue.

Une discipline qui émerge dans la 2e moitié du 19e siècle. Période où commence à se poser des questions sur des textes importants pour la culture occidentale. Moment positiviste où cherche des critères mesurables objectifs pour qualifier des textes.

Augustus de Morgan 1851

1861 dittenberg qualifie

1897 terme défini par Wincenty Lutoslawski. Sans un discours à l’Académie des Inscriptions et Belles-lettres. Pose idée de stylèmes unité de base qui va servir à la mesure du style. Mesure de l’affinité stylistique.

Encore sur cela que repose même si révolution technique amenée par l’ordinateur qui a permis de sortir des lents comptages manuels pour des calculs automatisés et des analyses satistique multivariées qui permettent de prendre en compte plus de dimensions des textes en un seul mouvement.

Souvent ce que cherche à détecter, pas des choses facilement modifiable par un auteur et souvent peu consciente. Classe des mots-outils souvent imposés. Les plus fréquents dans la langue même si peu nombreux. Petit nombre de classes qui forment un grand nomre d’occurences (Zipf). Indispensables dans la construction des énoncés mais pas porteurs de sens donc moins sujet aux variations selon le contenu des textes.

Mosteller et Wallace 1963, Federalist paper.

Psycholinguistique, Brocca et vie secrète des pronoms.

Au service des opprimés ou des oubliés.

Souvent pense aux grandes controverses comme celles de Shakespeare et Molière. Deux auteurs extrêmement importants pour leur contribution à la littérature et à la langue. Mais aussi des acteurs qui ont voulu leur retirer la paternité de leurs œuvres. 

Delia Bacon qui 1857 voit autre auteur, Bacon son homonyme.

1919 Pierre Louÿs importe cette controverse dans le domaine français. Molière Corneil.

Travaux stylométrie qui montre parties respectivement écrites par Fletcher et Shakespeare. Fenêtre roulante. Stylométrie en accord avec l’histoire littéraire.

Souvent privilégie approches non-supervisées pour périodes anciennes. Mais cas comme celui-ci où l’approche supervisée fait sens.

Approche non-supervisée mes travaux sur les œuvres de Molière avec Florian Cafiero. Partitionnements qui retrouvent division correcte. Stylométrie qui confirme les signatures traditionnelles de ces pièces.

De même jusqu’au détail des collaborations.

Important vérifier les choses autrement. Parfois cas étayés par la stylométrie.

Une discipline chartiste puisqu’elle sert à répondre à des questions fondamentales sur l’authenticité des documents. Questions qui se multiplient pour les périodes anciennes. Pb chansons de gestes anonymes.

Exemple pour littérature musicale, chansonniers de trouvers

## 2e session, Intertextualité

### Clovis Galdstone, Alignements de textes à l’aulne des modèles de langue

Aligner des textes c‘est compiler des passages similaires entre textes. Passages compilés en détectant des motifs récurrents entre deux textes.

Plusieurs approches.

- Réemplois : passages plus ou moins indentifiques entre deux textes 
  => alignement de séquence
- Similairité sémantique : passages qui portent sur le même thème 
  => similarité vectorielle basée sur des document-term-matrix
- Similarité portant sur les idées : passages qui expriment les mêmes idées dans des termes différents 
  => similarité vectorielle basée sur des *documents embedding*

Approche algorithmique semblable. De façon générale simialire.

- compare les doc un à un
- rprèe zones qui ont élément communs
- détermine si similarité suffisante pour constituer passage similaire
- fusionne les passages similaires selon leur proximité

Algorithmes différents mais approche la même.

Tout repose donc sur la représentation des textes. Comment va représenter ces textes par ordinateur pour retrouver les 

Réemplois : nGramm qui se chevauche. Sémantique en matrice de mots. Pour les idées Document-embedding. Graâce à des modèles de langages.

Ensemble d’approches algorithmiques qui sont implémentées dans le logiciel TextPair développé au sein de l’ARTFL project. Conçu pour détecter automatiquement réemplois dans grands corpus de texte.

#### Réemplois, alignement de séquence

Techniques généralise pour identifier des régions de similarités partagée.

Technique similaire à celle utilisée pour la détection de séquence d’ADN, ou du plagiat.

Prend un texte et le prétraite pour réduire la variation entre les mots. Réduit aussi les mots vides. Retire diacritique. Puis transfforme les textes en suite de ngrammes.

Nous utilisons par défaut les trigrammes. 

L’intuition est que les trigrammes construits de cette façon est assez rares. Donc si retrouve certain nombre de ces ngrammes alors doit les examiner de plus près.

- Génère ngrammes pour chaque documents
- puis compare les documents un à uns
- ancrage de l’alignement au ngramme commun dans chaque document
- on continue la compraison jusqu’à ce que les ngrammes ne correspodnent plus (flexibilité plus ou moins grande)
- on extrait le passage entre le premier et le dernier ngramme commun identifié

Exemples : 

- détection de réemploi avec insersion
- détection de réemploi avec suppression/insertion (révêle césure)

Un système qui fonctionne très bien et permet d’examiner les stratégies des auteurs derrière un réemploi.

#### Similairtés sémantiques dans un espace vectoriel

Dans un espace vectoriel les documents sont représentés dans des sacs de mots qui consistent à représenter les occurences de chaque mots dans un texte.

c’est la distribution des différentes fréquences de mots qui représente la singularité d‘un texte

...

Similarité sémantique : les sacs de mots. Selon cette représenttaion des documents on peut ansi mesurer la similarité entre chacuns des textes...

Un exemple probant l’alignement dans l’espace vectoriel.

Peut identifier des passages similaires qui ne sont pas des réemplois.

Exemple Rousseau et Robespierre. Passage faisant écho. Représentation sous forme de heat map des mots. Mots effacés ceux ignorés, mots similaires, et mots en communs. Permet de voir rapidement pourquoi les passages ont été considérés similaires. Paratage exemple Suisse, soldat, etc.

Autre exemple où parle de la particularité d’un état gouverné par la volonté général.

Est-ce suffisant pour dire que Rousseauiste ? En tous les cas la tonalité du discours est de type rousseauiste. Bien entendu le logiciel propose des résultats et à vous de déterminer de quelle manière sont liés.

Ici différence mandat impératif, etc. Donc bien des limites.  Dit seulement que les passages sont liés mais avec limites dans les rapprochements.

#### Similarité qui porte sur les idées

Représentation document embedding qui provient dernières avancées en TAL et en natural language understanding

word2vec ou ... ou BERT

Une représentation vectorielle qui est censée en exprimer le sens et les idées et qui est générées en utiliisant des techniques tirées du TAL.

Cette transformation peut être faite à partir

- d’un modèle vectoriel de mots word2vec on prend la moyenne de l’ensmeble des motifs constituant un document selon leur représentation vectorielle
- grand modèle de langue type BERT...

Trouver deux passages qui expriment les mêmes idées de façons complètement différentes

Repérer les paaraphrases ou allusions

avec l’avènement de grands modèles de langages multilingues §ex Labse, XML-Roberta) on peut mêm fiare des compraison entre langues

Potentiel énorme : transformation des idées, idées analogues, etc.

Similarité Rousseau et D’Holbach, reformulation d’une idée déjà présente chez Rousseau. Représentation qui a bien su capturer le sens respectif des deux passages et que proches.

Clovis Galdstone https://rll.uchicago.edu/clovis-gladstone-0

Bien sûr des différences et des nuances. Néanmoins l’algorithme nous permet de repérer des passages très proches que n’aurait peut être pas relevé avec une seule mémoire distance.

Des exemles de réussites avec ces grands modèles de langue. Nénamoins de véritables faiblesses dans ces approches. L’approche qui repose sur les vecteurs de mots ne fonctionne pas très bien ici. Mais les résultats avec les grands modèles de langues varie selon les modèles choisis... Un problème car variété des résultats et comment choisir le modèle ?

Un modèle qui n’a pas été forgé pour le langage d’époque. D’AlamBERT serait donc très utile ici. Avoir un modèle à travers les époques serait très intéressant.

Gros problème aussi que ces grands modèles de langues sont de véritables boîtes noire. De bon résultats mais pas capables de savoir quel sens a été capturé.

Prometteur.

- alignement de séquence fait ses preuves 
- alignement de similarité sémantique transparence mais progrès potentiel plus limités
- alignement par document embedding pose ccertainenement problème à l’heure actuelle

Mais peut imaginer que repérage entre langue soit bientôt plus aisé.

### Ganascia

Question sur les modèles vectoriels et les modèles de langage. Comment fait-on ? Car ne peut pas le faire sur les documents entiers. Il faut des passage. Ici travaille par phrases puis applique une fenêtre glissante. 

Seulement dans le document embedding que fait phrase par phrase. Pour Word2vec possible de prendre tout le texte.

Mais pour constituer passage, différentes techniques possible moyennes. Si des phrases similaires après essaye de regarder ce qu’il y a autour.

Pour le modèle sémantique, prend des blocs. Encore une fenêtre glissante. Même pas des phrases. Ensuite quand trouve des blocs similaires, doit regarder autour pour performer.

Prend tous les blocs de l’un et tous les blocs de l’autre. Donc combinatoire. Avec puissance des machines actuel ok. Par ailleurs réduit le vocabulaire avec les traitements.

Fonctionne seulement pour les langues qui ont de grands modèles de langue. Function transformers. Modèles spécialisés pour grands modèles de document. Si pas de modèle de langues : Alors retenir approche sémantique, moins bien mais avantage de transparence.

Comment évaluer les résultats. D’un point de vue pratique, va pouvoir évaluer la similarité selon une note. Est-ce que tous les passages sont bons ? Non ! C’est finalement aux chercheurs d’interpréter. Regarde les passages et va les évaluer.

TextPAIR (Pairwise Alignment for Intertextual Relations) https://artfl-project.uchicago.edu/text-pair

Donne tellement de pistes qu’intéressant. Mais beaucoup de travail à faire pour savoir comment évaluer (fitrer ces passages) mais aussi s’assurer que l’on n’a rien oublié d’important. Tout le problème du rappel et de la précision.

Ici utilise similarité cossinus. Pourrait imaginer un seuillage ?

Le problème c‘est de savoir ce que l’on loupe. Pour cette technique distance cosinus qui dans la littérature est recommandée. Euclidienne éventuellement.

### Glenn Rowe, Réseau de réemplois chez les Lumières

Projet ModERN

Projet ERC dans le programme consolidateur. Un projet très fédérateur en raison des corpus utilisés, les méthodes développées et aussi en termes d‘équipe.

Dario Nicolosi, postdoc. Valentina... IR

ModERN Modelling Enlightenment Reassembling Neworks of Modelling of Modernity through data-drive research

Gros travail pour filtrer les résultats, les mettre à jour ou les présenter. Une question de réseau qui sous-tend tout le projet. Métaphore institutionnelle courante depuis le télégraphe et bien sûr l’internet. Mais notion qui renvoie aussi à d’autres projets comme Reassembling the Republic of letters. Mapping the Republic of Letters. Liens lettres envoyer de quelque part à quelqu’un. Peut comparer les points d’envois, etc. Un projet intéressant mais qui a montré aussi beaucoup de bémol sur l’idée de résaeu comme lettre envoyée. Palladio qui est utilisé pour la visualisation de ce genre de réseau.

- Pays bas
- Simon Raper, graphing the history of Philosophy. Représentation de l’histoire de la phlo
- Ruth Ahnert et Sebastian Protestant letter Networks, encore une fois correspodnance A Qauntitative approach ELH 92, 2015
- The Network Turn, 2021

Dans cette voie que voulait penser le projet en termes de réseau. Mais aussi le grand privilège de discuter avec Latour à propos de Peggy. Et beaucoup apprécié idée de l’Acteur Réseau. Dit que trois pb idée de réseau, acteur et théory et même le tiret.

Mais pour nous intéressant que les actant pouvaient être n’importe quoi, acteurs, mais aussi livre et que souvent ne sait pas qui sera le plus important mais parfois les gens au milieu qui opère le transfert comme médiateurs qui sont les plus importants.

Plusieurs projets Latour 2012

Mais voulait aussi penser l’analyse des réseau sociaux assez courante en sciences sociales, moins en littérature, comme correspondance entre les textes. 

Réseau de Réemplois avec TextPair ?

Idée qu’un lien dans le réseau représente un texte ou un passage partagé entre deux nœuds et que en mettant cela en réseau pourrait comprendre le champ littéraire de manière différente.

Des énormes corpus.

CANON ARTFL-Frantexte, théâtre classique, Garnier. Effet Voltaire énorme

ARCHIVE ECCO, textes résultats de reconnaissance automatique Goldsmiths-Kress Gale, Gallica, Google Books

PAMPHLETS Newberry Library French Pamphlet Collection

LETTTERS Electronic Enlightenment

DICOS Pierre Baye, Trevoux, etc.

Voudrait trouver un millard de mots du 18e, pas encore là mais presque.

Néanmoins corpus énorme. Avec le canon seulement déjà nombreux résultats.

Attention TextPAIR marche trop bien, même trop bien !

Même avec CANON qui est le corpus le plus proche, énormément de bruit. Comment filtrer et analyser les résultats ?

Alignement du corpus CANON avec TextPAIR. 76 000 pairs de citations alignées.

Créé réseau des auteurs à la base de ces citations. Et sorti les auteurs les plus cités avec le degré de neuds. Entrants et sortants.

Corneille première place, puis Saint-Simon, etc. Questiond des marginaux. Où est Voltaire ? La Vulgate ?

Exemple des ciatiosn repéras. Probonf respect, madame, etc. Des choses inutiles pour un 18e iste.

Corpus 3 pb deux à traiter avant TextPAIR troisième après.

- Des doublons dans le coprus comme fusionné de plusieurs corpus.
- Métadonnées variées sans unification
- Citations bruitées : parapente et citations “non-informatives”

Pour nous débarasser des doublons utilisation méthode semi automatique de TextPAIR qu’a complétée. Tri des citations par longueur. Aurait pu inclure un seuil. Mais préférer faire intervenir notre expert comme des questions. Préférences entre éditions pour la constitution du coprus (textes plus complets, qualité OCR).

Combinaison de trois méthode automatique pour l’unification des métadonnées

- distance de Levenshtein
- similarité cosinus
- comparaison des mots les plus longs

Expertise des résultats par un expert

Unification des métadonnées. Notices où trois méthodes OK. Cas plus difficiles où premières méthodes réunissent les auteurs mais méthode brute distingue bien les trois auteurs.

Pour le filtrage des citations pour enlever le paratexte et des citations bruitées.

Méthode d’entraînement d‘un classifieur binaire à la base du modèle multilingue BERT for Sentence Classification (performance MCC = 95,5)

Intérêt de ce BERT spécifié pour l’analyse de séqunce que permet de traiter plus que des phrases.

Résultats 14 529 pairs de citations, retenus comme non-bruités : 19% du corpus de pairs de citations détectées.

Sans doute lié à la spécificité du réseau. Pu constituer le réseau. Voltaire bien au milieu donc bien contents !

Postdoc, reçu le tableau excel, qu’en faire ? Les 20 occurences par auteur les plus importantes selon les données de graphe. Comment utiliser nos résultats. 

Degré analyse le nombre de citations entrantes et sortantes. Se spécifie en in-degree gens cités. Et out-dégree ceux qui citent. (pour des raisons de métrique inversé) Closeness Centrality. Betweeness centrality mesure le nombre de fois qu’un nœud est présent à l’interne des chemins les plus courts qui relie les nœuds entre eux. Donc pont privilégié à travers plusieurs chemins.

Se rend compte qu’un texte intitulé *Pensée républicaine*, anonyme qui apparaît de manière élevée en betweeness. Regarder ses mesures. 45e dans le classement des auteurs. In-degree très bas, jamais cité. Mais out-degree etrès élevé car cite beaucoup pourtant Betweeness important.

Suggère que cite souvent mais que cette œuvre pas un hub qui remonte pour son importance. Donc première conclusion un texte relativement tardif. En effet républicain.

Betweeness qui s’explique par le fait que cite beaucoup. À travers proximité un hub, très important dans le réseau. En outre relie des hubs très différents. Relie des lcusters très distants.

Va alors voir le texte.

une sorte de calendrier de l’avant de maximes républicaines. 360 maximes.

Chef de bureau à la commission instruction publique.

“il m’est permis de faire l’éloge de ces pensées, car elles appartiennent aux meilleurs Moralistes anciens et moderne”

Betweeness confirmée du paratexte même. Mesures confirmées par le texte lui même.

Les sources des pensées 30/360 8% des maximes tiéres des auteurs modernes et “canoniques”.

- Présence forte d’auteurs anciens
- référence à des œuvres non)canonisées (nécessité de grands corpora)
- élaboratiosn personnelles de Poisson de la Chabeaussière

Auteur les plus cité Duclos. Tout de même Nouvelle Éloïse de Rousseau, mais pas le contrat social. Un certain éclectisme, variété d’influence qui en lui-même pourrait nous dire beaucoup avec le rapport de la Révolution avec la littérature précédente.

Cite Duclos, mais si regarde comment utilisé pas toujours très flatteur. 

Distinction Génie/Esprit

Deux autres potentialités, frontières auctoriales. Fusion vers de Corneille et Voltaire alors que présenté comme un seul auteur. Même phrase de Boileau. Distinction vraissemblable vérité qui passe du domaine de l’esthétique au domaine moral. Voit comment mot vrai et vérité change.

Outil qui nous présente des possibilités de recherche qui s’opèrent.

### Marianne Reboul

Évolution sémantique des langues anciennes indo-européennes.

Travaux antérieux, prémices sur Homère. Difficulté pour faire de l’alignement multilingue, pb surtout quand langue cible pas le même alphabet. 30aine de traductions françaises intégrales dans un sale état. Gros travail de numérisation. Problème du séquençage, de l’alignement des séquences d‘une langue à l’autre.

Pas encore de transformers comme BERT. Utilisation algorithme bioinformatique qui permet de faire de l’alignement de séquences ADN. Découpe textes en séquences, pas le même nombre de séquence. 

Détection de plagiaires lorsque ne vont pas vers la traduction la plus exploitée mais sélection texte plus rare.

Vecteurs de mots

Recommande deux outils

MUSE et Vecmap

## Cartographie et réseaux

### Vers une cartographie de l’Encyclopédie de Diderot et d’Alembert

Ludovic Moncla

Projet Geode

Discours géographique et ses évolutions dans les Encyclopédie.

Encyclopédie Diderot et d’Alembert et autres.

Premier axe de travail, voir comment les textes contrastent et les évolutions de ce discours géographique au cours du temps.

- TXM 
- Lexicoscope

Autre axe de travail, entraînement de modèles de classifications de textes supervisés pour la classification en domaine. Voir les domaines de connaissance auxquels sont rattachés les articles et déterminer si des évolutions dans le temps.

Reconnaissance d’entités nommées et repérage de routine descriptives à travers présence de segments récurents.

Troisième axe, celui de la représentation cartographique et ses évolutions.

Classification par domaine, essayer de repérer les articles en géographie qui n’étaient pas encore classés. Puis analyser l’évolution de ces domaines. Enfin Reconnaissances des entités-nommées. Identification de lieux et noms de personnes. Enfin reconnaissance des coordonnées géographiques avec l’objectif de faire un géocodage moderne pour comparer connaissances anciennes et modernes.

Classification en domaines de connaissance

Une difficulté liée au fait que liste très longue de noms de domaines. Non figée, non normalisation et classification possible en plusieurs domaines.

Une classification ARTFL produite automatiquement. Projet ENCCRE regroupement en 44 domaines.

Une des difficultés l’importance du nombre de domaine : plus de 2 600 classes exprimées chez Diderot mais pour nombre d’entre-elles un seul article. 

Corpus 12 000 articles non-classés dans ARTFL, un travail réalisé chez ENCCRE mais plus de 2000 articles non-classés. Notre objectif voir si peut les classer et l’évolution de ces domaines.

Modèle de langues de type BERT ou CamemBERT et réseau de neurones.

Méthodes classiques anciennes TFIDF 80% pas loin de BERT pour un temps de traitement plus raisonnable. Application des modèle BERT fonctionne bien même avec peu de données. Donc fonctionne mieux que embedding statique ou réseau de neurones dans ce cas.

Analyse pour voir si quantité faisait changer les résultats. Cf. une publication. Arrive à 90% en moyenne. Voit qu’une grande majorité de classes pour lesquelles cela fonctionne très bien, ou classes pour lesquelles plus ambigus ou bien que confusion. Exemple Arts et métiers. Difficulté avec classe métiers plus fournie. Classe Arts et métiers très peu prédite. Similarité sémantique entre les classes ou faible échantillon entre les classes.

S’est intéressée à voir les prédictions ou ce qui était considéré comme des erreurs comme notion de multiclassification. Forte proximité entre la géographie et l’histoire et géographie et la marine par exemple.

Construction de réseau sur les citations en fonction du degré entrant.

Extraction coordinations. Objectif de production d’un gazetier.

- Brenon, Alice, Ludovic Moncla, et Katherine McDonough. 2022. « Classifying encyclopedia articles: Comparing machine and deep learning methods and exploring their predictions ». *Data & Knowledge Engineering* 142 (novembre) : 102098. https://doi.org/10.1016/j.datak.2022.102098.
- Voir également ses travaux sur la reconnaissance d’entités-nommées

### Réseaux de personnages et romans : extraction et analyse

Vincent Labatut, Maître de conférences Avignon Université

Présentation introductive au domaine issue d’une revue de littérature.

Parle ici de graphes au sens de la théorie des graphes. Les points représentent les personnages et les liens les relations ou interactions entre les personnages.

Plusieurs types de graphes peuvent être identifiés. Quelle information a-t-on besoin d’encoder ?

Idée générale est celle de pouvoir modéliser une histoire. Modéliser de cette manière c’est dire que les personnages par leurs actions et leurs interactions qui font évoluer l’histoire. Une représentation assez naturelle. Utilisés depuis quelques temps, ex. travail de Moretti.

À quoi servent ces graphes ? Trois grands domaines d‘utilisation : en narratologie visualisation, détecter personnages principaux ou comparer des domaines littéraires. Applications dans le domaine des systèmes complexes. Regarder graphe comme un système complexe et le comparer à des systèmes fictifs ou aléatoires. Troisième champ d’application, celui de l’informatique et méthodes d’extraction des graphes. Travaux en TAL, mais aussi multimédia, films série tv jeux vidéo.

Deux applications plus marginales, dans le grand public pour visualiser notamment des séries. Ou encore en informatique pour constituer des bancs d’essai pour l’évaluation de méthodes de traitement de graphes.

Comment extraire des graphes ? Plusieurs approches génériques.

Co-occurences de personnage. Approches se concentrant sur les interactions interpersonnelles. Médias riches en conversation. Mentions explicites dans le discours. Identification d’action explicitement décrites. Affiliations.

## McDonnough, Machines Reading Maps

Allan Turing Institute

projet colloboration pour développer des outils pour travailler avec des textes sur des plans comme données.

Focalisé sur la découvrabilité.

Des partenaires de collections importantes. 

- Fire insurance map Library of Congres. 10% traité
- 19th ordnance Survey 1st edition 25’’ maps UK, National Library of Scotland 5000 feuilles sur 50k
- David Rumsey Map Collections, 57k géolocalisés

Utilisation approche manuelle hybride Recogito et méthode automatique avec MapKurator

mapKurator architecture

Métadonnées associées aux cartes fondamentales, toutes les cartes pas cataloguées. Aspect crucial pour le traitement des fodns dans le futur.

Patching, reconstriction polygones des textes et des étiquettes qui reçoivent des coordonnées spatiales donc possible de réinscrire dans espace géoréférencé.

Un module final pour les légendes qui représentent des lieux nommés qui peuvent être réconciliés selon des bases de données externes. Tous les noms ne pouvant pas nécessairement l’être.

Text Spotting Evaluation Results

Identification automatique du texte sur les plans. Techniques d’abord développées principalement pour des plans américains du début du 20e siècle (donc le meilleur scenario).

77% de score précision, 62% de rappel. F1 de 69%

Fuzzy string matching sur OpenStreetMap et que US.

TEsts sur des collections plus anciennes. Les résultats varient beaucoup sur ce genre de fonds. Faux positifs et plus problématiques que les vrais négatifs

Question de savoir si peut utiliser ces données. Est-ce que les méthdoes sont suffisantes pour la recherche. La réponse des spécialistes d’informatique et des historiens peut ici différer.

Comme historiens nous approchons ces données pas seulement comme une masse d’information. Nous voulons réellement rendre ce texte significatif. Texte qui a une fonction. Peut donner des informations sur l’échelle, la production du document, son historique de conservation.

Actuellement mauvais résulats pour les textes de plus de un mot. ex. “Département de Paris” qui doit être détecter en ensemble.

Il y a aussi une réelle intention dans l’inclusion de texte dans une carte pour les historiens. Sa signification est culturelle et peut présenter des dimensions politiques. Elle reflète aussi des priorités culturelles ou des biais, représentative également de la communauté servie par la production de la carte. Ces cartes réclament donc une approche sémio-historique.

Nous avons donc réfléchi à la manière dont on pourrait organiser le texte de ces cartes. Nous avons donc mené une revue pour déterminer gold standard de description. Différnets types de signes sur les cartes, étiquettes, symboles, etc. Le texte lui-même peut représenter différents types d’informations.

Rumsey Collection 57k plans

- V1 des donénes génère 9,3GB output
- V1 = 89 millions de labels
- V2 = 2x plus large

Exemple de ce que reconnaît. Toujours quelques erreurs sur les frontières des mots, etc.

Essaye de rendre cherchable la collection Rumsey. Pas encore disponible en ligne mais peut présenter sur son ordinateur. Présenté avec un avertissement pour dire que données IA. Possibilité de curation collaborative. Sera mis en ligne dans un mois : possibilité de chercher le texte d’un plan. Possibilité de chercher un mot ou deux mots.

Très différent de trouver par exemple Britania, là où se trouve sur un plan que dans les métadonnées.

Recogito.uksouth.cloudapp.azure.com

Tutoriel https://github.com/machines-reading-maps/Tutorial-Newsletters/wiki/Automatic-annotation-with-mapKurator

review https://observablehq.com/d/6efbc2db64e52bfc

## IA et littérature

### Benoit Sagot, Une approche computationnelle pour l’étude scriptométrique du français du XVIIe sciècle

Travail réalisé dans le cadre d‘une collaboration informelle avec Simon Gabay et Phiilppe Gambette.

Travail réalisé par Rachelle ...

Les applications du TAL pas toutes de l’innovation technologiques. Des applications en linguistique et en littérature. La linguistique devient presque un domaine d’application du TAL. Concernant le TAL appliqué, plusierus projets. Un projet ANR sur l’exploitation du dictionnaire Banage. Deux projets un terminé un en cours financés par le DataLab de la Bnf sur encodage ouvrages imprimés.

Travaux sur les modèles de langues. Constaté avec plaisir qu‘utilisés. Modèle de langue pour le français contemporain. Entraîné plus récemment des modèles de langues pour le français moderne et ancien D’AlemBERT et ...

Enjeu principal textes avrient selon nombreuses dimensions. Evolution dans le temps des pratiques graphiques une seule de ces dimesnions. D’où difficulté qui consiste à isoler cette variation graphique afin de l’étudier quantitativement. 

Des modèles de normalisation. Une des approches possibles pour s’abrastrire de la variation graphique. Une approche de suppresion pour s’abstraire. Sensibilité. Comment utiliser modèles pour étudier quantitativement cette variation.

Tâche de normalisation. Conversion en orthographe contemporaine d’un texte.

Peu de travaux sur les travaux de normalisation. Plusieurs tâches possibles : approches par règle ou approches dites orientées-données. Alors vue comme une tâche de traduction automatique en prenant la forme non normalisée comme la langue de départ et l’autre langue comme arrivée. Or, aujourd’hui ces modèles au niveau état de l’art se font par réseaux neuronaux. Mais tout de même comparé par des approches statistiques ou par règles (où doit partir de données parallèles).

La noramlisation comme une tâche de traduction. Une approximation, pas vraiment une traduction reste la transformation d’une séquence en une autre. Reste moins problématique car les deux langues sont très proches. Parfois le fait que les langues d’éntrées et de sorties soient très proches est parfois difficiles. Ex. simplification de textes. Ne rien faire une ligne de base difficile pour ne pas introduire d’ereurs.

Avons introduit des architecture de traduction automatique neuronales que nous avons entraîné sur des modèles parallèles. Collection FreEM corpus parallèles. Données d’enrtainement 265 000 tokens pas énorme mais tâche facile.

Corpus de textes brut, non alignés. FreEM max 185 M de tokens. Comparaison à des approches règles à la main ou automatique. Gambette et ...

Modèles complété par un filtrage facultatif. L‘idée est que si la sortie produite par un modèle de normalisation doit être présente dans un lexique. Si règle autorisée et que mot du lexique.

Règles de post-normalisation.

Filtrage lexical et règles de nettoyages facultatifs, dont verra l‘impact qu’ont sur le résultat.

Modèle et code source ouvert dès lors que possible.

https://github.com/FreEM-corpora

Résultats. Les sytèmes qui marchent le mieux les systèmes de traduction automatique statistiques et non pas neuronaux (97% des mots). Les architecture transformers auxquels s‘attendaient pour de meilleurs résultats un peu en deçà. Mais depuis mis à disposition autres modèles transformers sur HuggingFace qui atteingnent les performances.

Règles de nettoyage permettent gain global général mais surtout significatif pour les mots qui ne sont pas dans le corpus d’entraînement mais pas très surprenant.

Bawder et al 2022, Gabay et al 2022

Maintenant que l’on sait normaliser un corpus comment peut-on observer l’évolution graphique au cours du XVIIe. Pour cela besoin de modèle sensible à l’évolution dans le temps. Besoin de vérifier que notre modèle est sensible à l’évolution graphique dont on aimerait bien mesurer l‘évolution dans le temps. 

Va chercher à voir si notre modèle reconnaît la décennie dans laquelle un texte a été écrit. Et voir s’il lui est sensible pour les raisons qui nous intéressent.

Préfixer version contemporaine par mot spécial qui encode décennie au cours de laquelle le modèle pense que le texte a été écrit. Regarde ensuite si le moèle a réussi à prédire la bonne décennie cad que la decennie de production est sensible.

Decennie sureprésentée dans le modèle apprentissage surprédites;

Aucune idée que si pour la variation graphique ou pour d‘autres raisons. Car texte pas du même modèle, du même genre, ni même auteurs.

Expérience de contrôle. Entraîné des modèles de dénormalisation. Enrtaîné à reproduire ce qu’auarait pu être le texte origine et prédire la décennie du texte dans sa graphie contemporaine. Auquel cas peut dire que pas que la graphie qui prédit la decennie.

Ici s’aperçoit que diagonale toujours là. Cad que variation stylistique y parvient également mais moins forte que la graphie. Autrement dit nos modèles s’appuient en effet en partie sur la graphie pour prédire la décennie. Nous renseigne donc sur la capacité de ces modèles à nous fournir des informations sur la variation graphique au cours du temps.

Dénormalisation. Comparer les graphies entre décennies de textes diffférents.

Prendre des textes dans leur graphie contemporaine et demander au modèle de dénormalisation d’en produire de multiples versions pour chaque décennie. = les mêmes phrases dans des versions correspondantes à chaque decennie. Mais des données artificielles.

Phrases de gauche, modèle prédit comme graphie. Permis de compter les différentes règles de normlaisation à appliquer pour revenir au texte contemporain. Permis de documenter des évolutions mais des données sur des résultats statistiques. Cependant comparé avec d’autres données réelles et retrouve les mêmes conclusion.

Ne prétend pas aller plus loin mais illustre comment les approches que peut développer en TAL peuvent servir de méthodes et d’outils pour la scriptométrie tout en développant des recherches pour laquelle notre contribution en TAL intéressante.

Pas encore utilisé ni CamemBERT ni D’AlemBERT pour ces normalisation. Pour le moment, résultats pas très concluants. Il faudrait chercher à comprendre pourquoi.

Suite logique du travail ne pas seulement prendre en compte que l’information de décennie mais d’autres types de métadonnées qui peuvent avoir un impact sur les conventions graphiques.

#### Discussion

comparé différentes stratégies. Pas surpris par le fait que demander de la normalisation améliore la classification de la décennie. Cf. traduction en contexte.

FS grand pb pour la normalisation comment distingue quand la graphie se modifie et les erreurs de OCR ? Voir avec Simon pour ça. 

Le S long pour nous pas du tout l’objet le plus intéressant. Pas une information très fiable. Normaliser les S longs pas très dur, donc les modèles n‘apprennent rien d’intéressant sur ces bases là. Plutôt sur d’autres types de question que apprennent choses intéressantes.

Réfléchit à accumuler des données et étendre ce type de travaux.

### Emmanuelle Bermès, Les enjeux de l’intelligence artificielle dans les bibliothèques, archives et musées

Rappeler queqlues éléments historiques qui permettent de poser un certain nombre de dates clefs et de se souvenir que déjà les projets de numérisations dans les bib sont lancés au tout début des années 90 et qu’au milieu des années 90 voit émerger l’idée d’archiver le web. Ces deux dates annoncent le rêve de disposer de corpus de masse. 

Mais très coûteux donc passe à des numérisations par corpus ou par projet. Gallica, numérisation de la bibliothèque de l’honnête homme. Dans les années 2000 tout change avec l’irruption d’acteurs privés. Google mais pas le seul, mais rendent vraiment possible l’appréhension de la masse et l’idée que peut numériser des bibliothèques entières. Massification et création de portails pour mutualiser l’accès à ces corpus.

Plus tard enfin approches collaboratifs et mutualisation de ces coprus.

Plusieurs exemples isssus de la Bnf. Trois projets fondateurs de cette réflexion sur la fouille de texte et reflexion sur les corpus à la Bnf.

Premier projet 2013-2016, un projet autour des célébrations du centenaire de la Grande guerre. Objectif d’évaluer comment les numérisations effectuées par les institutions patrimoniales étaient utilisées en ligne par les amateurs. Au départ un projet plutôt sociologique, mais rapidement considéré que devaient collecter de l’information sur le web. Alors identiification utilisation des archives web collectées par la Bnf. Premier projet où des activités de fouille avec technologies de type IA pour diverses applications dont analyse de réseau.

Deuxième projet, très grande bibliothèque née à l’initiative Obvil et ARTFL. Original car première fois que nous demande objet aussi massif. Au départ directeur lab Obvil nous avait demandé une copie de Gallica. Dialogue qui a permis de comprendre que seulement le texte. Première analyse qui nous a permis de comprendre que devait entrer dans un dialogue et nouveaux modes de travail qu’a depuis institutionnalisé avec les labs.

Aujourd’hui admis que le travail sur les corpus massifs implique un dialogue pour comprendre ce qui est présent dans les corpus. Dépister les biais et dépister les pb pour lesrendre actif.

Autre projet plus expérimental. Jean-Philippe Moreux. Première tentative d‘utilisation des modèles d’images pour resémantiser corpus image. Ici POC preuve de concept. Montrer que technologies suffisamment matures pour être mises en œuvres.

Débouché sur la rédaction d’une feuille de route IA. Quand passe de la logique accompagnement à industrialisation de l’IA service accessible pour tous les usagers dans Gallica ce qui est l’objectif pour la fouille d’images. Se rend compte que la marche à franchir très haute. Un problème de masse d’hétérogénéité du corpus, mais aussi pb techniques et de logique du changement.

Objectif de cette feuille de rouet explorer tous les aspects et voir ce que voulait dire pour la bnf de devenir réellement actrice de l’IA et ce que voulait dire pour l’institution de découvrir tous ces aspects.

Un certain nombre de projets prioritaire identifiés.

Gallica image projet identifié dans le cadre du plan de relance. Objectif reprendre intégralité de Gallica et ségmenter les images. Repérer les images dans les textes, les périodiques et la presse pour les sortir et les rendre cherchables. Une avancée importante pour tous les utilisateurs. Un projet vu comme un projet de très longue haleine.

De la même manière qu’au moment du Google Books project a commencé à OCRIser les collections. Pas passé immédiatement de l’un à l’autre. Doit en effet commencer par un bout et petit à petit augmenter la mise à disposition d’une collection d’images.

GallicaPix parmi les projets fondateurs. Question de l’industrialisation clef dans le cas de Gallica. Comment passe d’un petit projet au traitement de 10M de documents de Gallica. Plusieurs étapes. Deux projets sur lesquels d’abord travaillers avec INRIA. 

Gallica Snoop, entraîner modèle. Déjà outil disponible pour les utilisateurs du catalan.

Autre objectif un projet sur la reconnaissance des images zoologiques sur un corpus d’iamegs médiévales intéressant pour comprendre ensemble de baiis possibles.

Autres projets comme ceux de l’INA très insprirants dans la problématique de l’industrialisation. Eux travaillé sur les matériaux audiovisuels. Industrialisation de l’IA dans la chaîne de description des documentalistes. Exemple découpage des JT anciennement fait manuellement. Aujourd’hui combine OCR, reconnaissance de formes, de visages combiné dans une même interface. Propositions dans une interface globale pour les opérateurs.

Autre exemple, projet de Europeana qui a essayé d’aller très finement dans l’analyse iconographique. Plus seulement segmentation des images et caractérisations. Mais plutôt voir par exemple Saint-Georges avec un dragon et non Saint-Geroges sur un vélo ! Pou ce faire travailler sur les représentations dans l’art, identification de pattern. Surtout montrés que difficiles d’amener IA à ce niveau d’interprétation.

Autres exmeples dans le domaine des GLAM. Ensemble des choses autour de la conservation des objets physiques. Projet d’AlgoCol projet de thèse financié par la fondation des sciences du patrimoine. Travail sur collections imprimés et opération de conservations à réalisées. Modèle prédictif sur communication et information acidité, etc. Parallèlement méthodes statistiques avec échantillonnage et connaissance humaine. Serait intéressant de pouvoir comparer les deux.

Deux autres exemples Rembrandt la ronde de nuit. Restrauration virtuelle. Partis œuvre en petit, et utilisation IA générative pour rétablir les portions manquantes de l’œuvre dans sa taille complète. cf. Vidéo.

Analyse de données climatiques au Musée national du Danemark. Là encore analyse de données à des fin de conservation. Une expérimentation sur la prédiction des risques sur la collection en analysant les données météo.

Collègues dans les Bibliothqèues archives et muséees innovent pour trouver solutions possibles tant pour améliorer leur découvrabilité mais aussi leur conservation ou encore leur présentation.

Présentation ne serait pas complète si n’évoquait pas projets de HTR comme Lectaurep et Humanis. Exemples multipliés. Ce que trouve intéressant par rapport aux traitements, finalement IA amène à un renversement de la notion d’images et de textes. Quand a d’abord numérisé dans les années 90 massivement transformé des millions de pages de texte en image. Aujourd’hui IA qui nous aide à faire le chemin inverse, retransformer des millions d’images en texte.

Avec parfois une ligne assez fines entre les deux. Exemple cartes. Enjeu clef de la ligne et segmentation pour pouvoir transformer image en texte. Enjeu important aujourd’hui autours des archives de l’internet et nouveau matériau qui présente des caractéristiques spécifiques. Exemple projet Néonautes. Collecte actualité, et pages de médias pour repérer néologismes apparus dans la langue française et succès de ces néologismes en travaillant sur la collecte d’actualités pour observer comment se diffuse. Trvavail du TAL sur ces collections, enlever tout ce qui n’est pas du texte. Ensemble information du boilerplate, éléments qui sont de nature textuelle et présents dans le matériau collecté et considéré non pertinent que doit éliminer.

Des éléments qui reviennent tout le temps dans le texte juridique comme les formulaires qui sont très utiles dans le décriptage en paléographie...

AI4LAM communauté toute jeune et très informelle fondée en 2018 à Oslo. Réunion à Paris en 2021. Les futurs fantastiques conférence annuelle. Prochaine en novembre-décembre 2023. Probablement à Vancouver.

#### Discussion

Corpus Oscar comment la Bnf se positionne sur ces questions en termes de droits. Sa proche approche de collections d’archives web comme réalisé dans le cadre du dépôt légal. Projet Espadon. Cadre légal pour constituer les corpus même si pas commode. Mais beaucoup de pratiques autour de Internet Archive.

EDM expérience qui a montré que quand essayait de fédérer telle quantité institution que meêm avec modèles de qualité peut donner des résultats assez réceptif. Portail lui-même résultats décevant et du mal à trouver son public. Même à un niveau plus restreint reste un outil difficle à manipuler. Passer à un mod!èle plus large alors que les problèmes précédents pas résolus. Pour elle l’apport princiapl de Europeana pas 50M objets mais plutôt d’avoir fédéré une communauté de pratique et bénéfice pour plus petites institutions. Quelque chose qui devrait se continuer dans le champ de l’IA. Intéresse beaucoup de monde mais ne sait pas forcément par où le prnedre.

### Jean-Gabriel Ganascia, IA et les servitudes virtuelles, Hallucinations littéraires

Conclure mais vraiment spécialiste IA même si littérature m’intéresse et que travaillé DH. Ces dernières années beaucoup travaillé sur les questions d’éthique du numérique. Et ressenti une certaine exaspération à la lecture des multiples chartes éthiques rédigées. 320 chartes éthiques publiées depuis 6 ans et 521 recommandations...

Des documents qui partent de bons principes mais souvent contradictoires et surtout figent un peu l’avenir. IA act indique qu’il y a des risques et que ne peut pas prédire l‘avenir. Dans l’ordre de la technologie tout change et pas capable d’anticiper.

Mon dernier livre part d’une critique du parallèle qui est fait entre éthique médicale et technologies numériques.

Propose d’examiner exemple d’actualité. Hallucination trouble de la perception. Hofman, inventeur du LSD. Mort à 102 ans ! bon pour lui. Descriptions littéraires des hallucinations qui ont été faites. Paradis artificiels de Baudelaire. Benjamin sur le haschich. Huxley, Timothy Leary où décrit en détail les hallucinations. S’agit-il de la même chose que les illuminations ?

Rimbaud, “le pavillon en viande saignante sur al soie des mers et des fleurs arctiques ; ...”

Autre question liée au fait que sort de la norme rationnelle. Écriture automatique, mode d’écriture dans lequel n‘entre pas la conscience. Au départ des spiritistes qui l‘utilisent pour faire advenir des esprits. Beaucoup pratiqué par les surréalistes soit pour faire parler l’inconscient. Ou encore comme règles collectives.

S’approche là de l’écriture automatique. Avoir une machine qui écrit. 

SHRDLU fréquence des lettres. 2e colonne des linotypes. Titre d’un roman de fiction, linotype qui écrit seule. Ce que découvre avec IA de la littérature. L’un des premiers programmes de compréhension du langage naturel s’appelait justement SHRDLU ! Ce qu’il faisait des volumes qui permettait d’interpréter des phrases et prendre un bloc.

Une tradition littéraire qui imagine des machines capable d‘écrire des livres est continue. Ada d’Antoine Bello une IA qui écrit. Maiis tout cela restait de l’ordre de la fiction.

Modèle de langues qualifiés dans un article de Perroquets stochastiques

Commence relativement récemment avec les premiers modèles transformers. BERT c. 2016. Puis GPT 2020. 

Ce qui est ici intéressant, c’est l’évolution du nombre de paramètre et la taille des ensembles textuels sur lesquels c’est entraîné. 78GB. Un livre 1M de char un livre. Ici donc des centaines de millier d’ouvrages. 500 000 ouvrages.

Des modèles de langage qui peuvent servir à beaucoup de choses. Pas seulement de la génération automatique de textes. Mais aussi de la paraphrase, du dialogue. Entraîné avec des réseaux de neurones. Nombre de connexion. 1,5 10^12. Pour GPT4 on dit que 100 000 000 milliards de connexion. Dans notre cerveau un peu moins de 100 milliards de neurones...

De l’apprentissage. Des réseaux de neurones formels enrtaînés par auto-encodage. Non supervisés même si des techniques d’apprentissage supervisés utilisés au service de modèles non supervisés.

Generative Pre-trained Transformers. Ensuite utilise ces modèles pour de multiples tâches du traitement automatique du langage naturel. Un certain nombre d’applications possibles.

En travaillant sur les questions éthiques, un rapport du CoP recommandations modèles langage offre aux scientfiiques de publiers des arcticles de manière automatique. Met les journaux scientfiiques dans une situation délicate car nombreux articles à lire sans originalité. Nombreux papiers qui paraissent de ce genre.

Des systèmes de dialogue. En juin dernier un ingénieur de chez Google qui s‘appelait Black Lemoine qui expliquait que la machine avait une âme. Certains articles disant qu’un prêtre. Google l’a imédiatement renvoyé et décidé arreter de travailler sur le système de dialogue Lambda. Repris par GPT en comprenant que danger dérive car modèles que ne contrôlent pas. Système où génération de modèle puis renforcement. Crowdsourcing où demande de noter les textes pour filtrer les textes à la sortie.

Technique apprentissage par renforcement développé très tôt en IA et informatique notamment avec le modèle de la souris. Stirner ? Levier pour nourritur. Apprentissage positif ou négatif. Fait la même chose avec les hommes. LRHF Reinformance learning with Human Feedback

Modèle des hallucinations de GPT et Bard. Soit les fantaisies ou les erreurs.

Exemple oreillers en plume de stylo ou en plume d’oie. Les œufs de bœufs comparés aux œufs de poule.

IAWIT gros pavé, 3000 amendements. Un commentaire sur les générateurs automatiques de texte qui sans doute n‘existait pas il y a quelques mois.

Quelque chose que voulait dire à propose des servitudes virtuelles.

Machines célibataires, livre écrit par M. Carouges. Un auteur qui dans les années 50 s’est intéressé aux machines littéraires. Parmi elles évoque la colonie pénitentiaire de Kafka. Le Surmâle de Jarry, le Chateau des Carpates de Verne. Le puits et le pendule de Poë. A-t-on avec l’IA aussi affaire à des machines célibataires.

La mariée mise à nu par ses célibataires mêmes. Broyeuse de chocolat. Pôle emploi utilise nombreuses applications IA. Un comité d’éthique. Machine qui lit les courriers, fait de la thématisation et prépare une réponse au demandeur d’emploi... Essayé de leur dire que faire attention. Un exemple de machine célibataire.

Articles scientfiiques. Possible d’extraire de l’information pour nourrir des bases de données scientifiques. Mais que nous apprennent ces modèles sur notre capacité à apprendre, au rôle du langage. Car toute la rationnalité est absente de ces modèles actuellement.

Testé cet été GPT, doit dire que époustouflé. Écrit une chronique pour La Recherche qu’a fait avec GPT. Comme graine, génération automatique de texte, plagiat d’idées, etc., etc. A produit près de la moitié de la crhonique. Assez incroyable car se tient et se termine sur avertissement. Pas confronté plagiat d’idée mais considéré que du plagiat.

Travail sur l’intextualité, Phoebus, techniques de déterction plagiat mais assoupli pour détecter autre chose. Est-ce que c’est du plagiat. Non pas vraiment car les mots de tout le monde. Est-ce que du réemploi ? Oui une question. Est-ce que de la réutilisation ? Peut-être pourrions-nous nous-même nous poser la question de savoir de quoi s’agit-il. Ne pourrait-on pas au sein de l’Obtic reprendre ces textes avec les travaux que l’on a fait pour être capable de voir si une suspition de réemploi.

Projet ITEM IMEC LIP6 Derida Forensics. Exploiter les écrivains nativement numérique. Items qui au départ travaillait sur la génèse textuelle. Travaillaient sur les brouillons. Derrida très tôt utilisé un ordinateur. A ses disques durs. Voir si peut utiliser les techniques qu’a développé pour explorer ce genre de travaux.

### Discussion

loi que ne devrait ignorer or régulation pris une telle taille que ne peut la comprendre. Par ailleurs la technologie a la caractéristique de nous surprendre. Il faut donc trouver d’autres méthodes que simplement édicter des chartes précise. Doit être capable de regarder les innovations technologiques au moment où elles se font et ensuite voir ce qui est acceptable ou non.

Comités éthiques en amont, au cours et après. Mais règles générales trop nombreuses et démenties par la réalité. L’éthique c’est être ouvert à ce qui vient (Derida). Prendre conscience que la technologie c’est de l’ordre de l’imprévisible et se préparer à cela.

Ce qui est troublant, c’est que les phrases sont bien construites. Du point de vue logique très mal articulé. Plus tard peut être sera capable d’avoir un module d’évaluation de la véracité de ce qui est avancé et de la qualité de l’argumentation.

Dit souvent que ChatGPT n’a aucune créativité. Mais en réalité, il a celle de l’humain qui est en train de l’utiliser. Possibilité de réduire écart entre les natifs et non natifs pour l’usage de l’anglais. Question du plagiat. Est-ce plagier que d’utilser ce que ChatGPT produit, dépend des cas. Dans certains cas produit du texte identifique à ses données d’entraînement mais parfois aussi capable de restitution d’une information au lieu de nous dire où chercher l’information. Actuellement pas très bien mais bientôt sans doute très bien. Sans doute un outil d’information pour aller plus loin que les bibliothèques.

Affabulation extraordinaire qui nous surprend.

Données entraînement énormes mais quand même nos données. Turing à la question de savoir si machine capable d’écrire un poème répond que ne le comprendrait pas, mais seule les machines.

En IA travaillé sur un modèle de créativité en musique. Simule l’imagination cad combinaison d’éléments de mémoire. Le faisait à l’époque de manière symbolique. Fasciné car voit les insuffisanes et les limites mais ambivalents.









# Rmq

En approche non-supervisée faire analyse phénotypique par rapporteur, par type d’affaire pour déterminer ce qui contraste ?







