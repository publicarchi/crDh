Cr séminaire culture ouverte, 2014-01-27
==============

------
Intro 2014-01-27, Camille Domange
------

Partenariat avec INRIA
Engagements Aurélie Filipetti
4 piliers d'une politique des usages numériques
Repositionner la culture comme une filière d'avenir.
Dans ce nouvel environnement la données est devenue une ressource. Aussi important que le ministère qui dispose longue tradition de production de référentielles s'impose.
Production de véritables biens communs de la connaissance
Si interconnectés nouvelle valeur
Socle innervant dev eco
Dimension territoriale

Open data / LOD sujets prioritaires pour le ministère
D'où organisation de ces réunions sur comment lier les données. Essor de ce mouvement qui est en train de transformer le web va petit à petit se constituer en base de données ouverte et distribuée.

Potentialité du web sémantique considérables
Par exemple pouvoir exprimer de manière formelle que telle œuvre celle de tel architecte, visualisation sur une carte, etc.
Inscription dans un nouveau paradigme culturel et cognitif, logique du rebonds, dans lequel un écosystème culturel vivant où les données sont interconnectées entre elles.
Ce que devons co-construire aujourd'hui.

Une économie numérique qui est une économie du possible et du présent. Celle dont devons nous emparer.





------
Alexandre Monin
------

Ravi d'ouvrir cette journée qui sonne un peu comme un bilan des diverses initiatives prises par le MCC.
Cas particulier dans notre pays, car ministère à été un acteur innovant dans le domaine du LOD.
Prendre donc le temps de faire un bilan, les examiner ensemble et imaginer l'avenir. Le sens de ce cycle qui associe MCC et INRIA qui fait sens pour imaginer l'avenir du LOD.

Reviendra sur projets de la BNF, CGP, Cité de la musique, HADOC sur Interoperabilité, et questions intégration technique, BBC, Joconde Lab.



------
Gildas Illien, des catalogues de bibliothèques dans LOD
------

data.bnf.fr
Parmi les personnes présentes dans la salle, seulement 4 qui déclarent bien connaître les données de bibliothèques

Mentionne ses collaborateurs :
Caroline qui est en première ligne pour partage
Agnela Angeli sur les référentiels
Agnès Simon chef du projet Data.Bnf.fr

### Rapide historique des données de la Bnf

Bibliothèque royale plusieurs siècles
Des première métadonnées

Production de la bibliographie nationale française, dans le cadre du dépôt légal. À partir de cette époque que se construisent les deux types de référentiels.

Deux types de données, les données bibliographiques, et d'autorité.
Concentration sur des règles pour qualifier l'information de manière régulière, explique que dispose d'une masse considérable d'informations structurées.

Dans les années 80s à choisi de coder ces données. Mise au point d'un format à même de traduire la structure de ces informations. Le format MARC, investissement important pour entrer dans cette logique nécessaire. Une des raisons pour lesquelles, les données produites par les bibliothèques jusqu'à présent surtout employées par... Les bibliothécaires.

Faire en sorte que d'avantage de personnes puissent les réutiliser et pas uniquement les bibliothécaires : faire la preuve de l'utilité d'un service social de la métadonnées. Raison pour laquelle s'est engagé dans une démarche de LOD.

Attention tout n'est pas libre et ouvert.
15 M de notices et des autorités, thesaurus de sujet RAMEAU organisé, encyclopédique.
Pour les personnes un fichier d'autorité qui récence près d'un million d'entité publiques. Autorité personnes et organisations.
Depuis l'année dernière adoption d'un système d'identifiants ISNI dont deviendra opérateur. Très utile pour le web de donnes.

Données d'autorité sujet dont géographique, établies par le département des estampes.
Actuellement en train d'opérer une transformation de nos métadonnées pour prendre en compte la notion d'œuvre. Initialement partait du principe que le lecteur cherchait un doucement, or en réalité cherche plus généralement une information, part d'un concept. Une FRBRisation de nos catalogues, chantier monstrueux de plus de 10 ans, mais pour que prouve légitimités de ce travail à besoin d'utilisateurs qui nous réutilisent.

### Plusieurs protocoles

Du Z3940
Du Dublin Core avec OAI-PMH, fonctionne bien notamment pour les documents qui sont déjà numérisés et présents dans Gallica. Mais une des limites de l'OAI sa simplicité, or veut valoriser l'information très riche. Notre avenir est donc le RDF, et ce qu'avons mis en œuvre avec Data.Bnf.fr. Quand dit RDF, rien dit, tout dépend du modèle qui est derrière.

Aujourd'hui voudrait affiner le service de Dump, actuellement charge masse de données, et trop gros. Besoin de construire un SPARQL end point et segmenter en fonction des usages.

2011 réalise une ouverture technique des données. Mais pas encore ouverture juridique. À pub faire voter en 2012 avec le soutien du MCC une ouverture de nos métadonnées en CC0. Tous les produits par défauts sont gratuits, par contre si nous demandez un travail à façon, facturé à prix coûtant.

Utilisation des données du web sémantique permet meilleur visibilité de nos données et réutilisation dans d'autres communautés. Possibilité d'interoperabilité non seulement à l'externe mais aussi en interne car des données issues époques différentes que ne pouvait faire communiquer sans ces technologies.

### L'avenir

Une fois ces données ouvertes, comment tracer les réutilisations. Qui dit ouvert, dit libre d'usage
Travail sur une piste premium avec un identifiant. 

Licence Étalab
Crainte possible que nous revende notre données. Piste de marquage de provenance pour éviter cela.

Le problème c'est qu'aura de plus en plus de citations en cascade et qu.est ce qui reste de la donnée initiale. Comment se projette dans l'avenir par rapport à ça.

Nos données des jeux de données complexes, en réalité aura réutilisation à niveaux de granularité plus fins, comment cite la provenance à ces niveaux plus fins.

Des données non soumises à droit car auteurs morts et anciens, mais peut avoir auteurs vivants. En exposant données peut avoir problème car ne voudrait pas que puisse retracer son parcours politique, connaître sa date de naissance. Alors peut ère proposer des services de gestion de l'ereputation en partenariat avec les auteurs.

Les rêves. Question des lieux historiques, dans le domaine du tourisme culturel, créer des applications permettant de retrouver historique d'un lieu, sans doute très porteur.

Actuellement travail avec comédie fr.
Description instruments de musique plus précise.

Bientôt intégrera dans data.bnf.fr tout le référence ment des journaux et de la presse autour duquel peut imaginer également de nouveaux services.


### Rmq perso
À peine ouvert, parlent déjà de refermer en créant des enclouures avec des services ?
Le projet dont rêve pour geolocalisation historique : les guides de paris.





------
Claire Galibert, centre George Pompidou au prisme du web sémantique
------

CPV rien d'autre que le site du musée.
projet initié par Alain Seban le psdt du CGP en 2007 dans une direction qui associe ensemble des contenus conservés, et plus tourné vers l'utilisateur.

Milliers de notices bibliographiques BK
Notices œuvres, événements
plus de 8 sources de données ou 12 bases de données différentes qui ne partageaient aucun référentiel ni format.

Les technologies du web sémantique qui nous ont permis de produire des liens entre ces données et ces documents. Production d'une ontologie. Technologie avait l'avantage d'être très souple et de se plier à nos données correctement.

Objectif de créer du lien entre ces données
Au printemps dernier a entrepris un projet de réécriture de ce modèle sous la direction d'Emmanuelle Bermes et de SWOrd notre prestataire.

C2if

Plusieurs objectifs : avait besoin d'intégrer un nouveau genre de données comme des données archivistiques traitées en EAD, d'autre part améliorer les résultats des recherche pour les utilisateurs.
Sans remettre en cause ensemble du modèle, le rendre conforme aux standards du web sémantique et prendre en compte les évolutions.

### quatre genre d'évolution

Attribution d'URI stable car jusqu.a présent établi à partir de la génération des pages. Or si momentanément manquante ou pb dans la génération alors changement ou nouvelle URI.
S'efforcera générer URI à partir clef de nos bases, par ailleurs mise en place d'un dispositif de redirection.

Graphes nommés pour historicistes les modifications intervenues sur une données. Permettra meilleur suivi, interogation sources particulières ou de défusionner.

Typage des données, pour le moment que des littéraux. Plus typera les données, plus les machines pourront les employer. Possibilité de tri par date, etc.

Enfin réutilisation de vocabulaires existants. Dans la première ontologie, les noms, empruntes aux modèles sources. Essaye maintenant de réutiliser des vocabulaires existants des standards du web sémantiques FOF, etc. Conservera domaine de nom CGV seulement lorsque rien de disponible. Pour les mots clefs utilisera SKOS, permettra de renseigner terme préféré, etc. Gain sémantique, possibilité accroître visibilité sur le web, et participer enrichissement du LOD.

Dernière évolution, celle qui consiste à relier nos données à d'autres données exposées par d'autres institutions culturelles dans une dynamique de co-construction des savoirs.

### Discussion

Monin: comment mis en place graph nommés, comment implémenté ?
R: une question technique mise en œuvre par notre prestataire



------
Rodolphe Bailly, Nouvelle interface et web sémantique
------

Musique2701

Projet européen pour lequel la cité de la musique s'est chargé du développement technique. Présentation sur la manière dont utilise le web de données dans ce projet.

Un projet déposé dans le cadre de e-content+, financement à 50%. Conduit jusqu'en 2011.
Institutions dans 7 pays en Europe, à elles toutes 40% du patrimoine du domaine conservé en Europe.

Problème d'harmonisation et d'homogénéisation en général. Question des dénominations dans les différentes langues. Enjeux pour la recherche de l'utilisateur dans Europeana. La variété des sources de données génère des problèmes d'indexation, et des problèmes d'interface.

Eu le solution harmonisation des données. Non pas prendre le plus petit dénominateur commun, mais produire des enrichissements en mettant au point un index commun sur lequel aligne ces différentes terminologies.

Production d'un thesaurus d'instruments de musique, localisation des lieux de production avec Geonames enfin liste des facteurs d'instruments.

### Discussion

Anne Faure Musée du quai Branly
Actuellement travail pour intégrer leurs thesaurus dans rameau, voudrait les rencontrer





------
Katell Briatte, repenser la production des données culturelles
------

HTTP://www.lite3.framapad.org/LOD2014
Twitter #LOD

Direction générale des patrimoines
Revenir sur la question de la provenance des données aujourd'hui mise à dispo par MCC sur ensemble de ses sites

Originaires de processus métiers qui embarquent un certain nombre de description des objets décrits.
Or historiquement ces processus sont cloisonnes, tant en terme de processus que technique.

Passé au filtre ces différents processus information caractérisée par la redondance, et génère des erreurs, ou incertitudes pour des données du ministère constituant normalement des données de référence.

Besoin harmonisation de ces processus ne serait-ce que pour assoir l'action des services.

Hétérogénéité souvent justifiée dans chacun des métiers, mais différences généralement implicites. Modèles générés et mis au point dans le temps de manière différente. Lorsque mis à plat, pas toujours possible de voir que l.information est prise en compte de manière différente. 

Or cette donnée que mettons à disposition des publiques aujourd'hui.hui confronté à des besoins nouveaux. Besoin d'une donnée unifiée, mise à disposition en s.affranchissement total des logiques de production. L'utilisateur souhaite naviguer dans l'ensemble des corpus en s'affranchissant des silos ou des logiques de roi d'action.

Pour répondre à ce problème, le ministère de la culture à mis au oint moteur collection. Pallier différence aussi bien dans la structure que le contenu. Un immense effort de consolidation pour les terminologies.

Cet effort de consolidation n'est pas rétroactif. Un peu sale. En outre, il fait exploser, voir met en évidence toutes les incohérences de ces données.

Bien de permettre un rêvassante plus vaste des données, mais ne pourrait-on pas faire beaucoup mieux en intervenant des la phase de production

### Ici qu'intervient le programme HADOC

Un projet lancé en ??? Pour travailler sur l'harmonsisation des données, la mise en œuvre de référentiels partagés. Pour objet de produire une sorte de cadre normatif pour ces ressources métiers, s.appuyant sur des référentiels, des standards afin d'harmoniser la carte d'identité des biens culturels afin d'assoir les processus métiers sur des données de référence. À terme servir de à se pour construire des nouveaux outils de production dont la

Consolider un certain nombre de données qui deviennent des données de référence, accessible par un processus métier.

HADOC utilisé pour MUCEM, transformation de Merimée en premier.
Modèle exprimé en UML car pour échanger sur ce modèle mais également permettre de produire des applications.

Alors dirait que loin du web sémantique. En fait pas si sur car s'est beaucoup inspiré de choses existantes dans le domaine du web sémantique.

Un modèle de production. Mais entièrement aligné sur CIDOC-CRM et FRBR00
Un modèle de production mais inspiré de modèle ou d'ontologie centré sur les technologies sémantiques.

### Les référentiels

Première brique logicielle dans ce processus, développement d'une application GINKO qui est totalement normé avec ISO ??? 2011 et 2013. Développée en open source, disponible et ouverte en production pour la première version au ministère. Nous permet de produire les vocabulaires dans les langages qui vont bien dans le web sémantique.

Plateforme de publication avec les AN
Des concepts identifiés au moyen d'identifiants uniques type ARK
Des relations
Des alignements vers des ressources

Exemple de VLD montre que tt intérêt de travailler à plusieurs pour construire des parcours qui soient utiles pour les utilisateurs.

Verrière de Paul Bony??? Décrit dans le modèle HADOC actuel en UML. Une information granulaire très très fine, une description assise sur des vocabulaires très précis, qui sont tous explicitements décrits par des concrets et des identifiants. Avec cette granularité et ces identifiants, arrivent à produire pratiquement à sans s.en apercevoir des triplets RDF.

On a le sentiment qu.avec le web sémantique les besoins qui étaient mis en avant lorsque développait...
Voit que rejoignent ceux du web sémantique sur la pérennité, citabilité.

Les enjeux de la publication rejoignent aujourd'hui.hui de plus en plus ceux de la diffusion. Donc travailler ensemble le plus en amont possible.

Nouveaux standards sur la provenance

### Rmq perso
Conclusion importante et politique 







------
DSI web sémantique
------

Ne se voyait pas naturellement devant cette audience.
En interne essaye de pousser tt ce qui est sémantique en me disant que virage à ne pas rater.

Comme audience acquise, changer de discours.
D'abord des changements de technologie ont en à déjà eu de nombreux. À toujours des vieux clous qui trouvent. Quand DSI faire en sorte que fonctionne.

Chacune de ces révolutions technologiques devaient révolutionner l'informatique, solution à tous les problèmes. À eu le SOA, le cloud, le sémantique.

Un exemple que vous aurez tous connus, celui de XML. Vous avez tous déjà vécu le XML, avait un vrai pb, n'arrivait pas à partager les données, ni les lire. Alors XML allait tout résoudre. SDX gd système dans lequel allait mettre.
Un système de description pour l'échange.
Quand commencé à faire des bases de données XML à capoté. D'une part beaucoup d'avance sur les systèmes relationnels. Passé d'optimisation et d'efficacité qui fait que doit aussi s.appuyer sur les technologies antérieures compte-tenu des investissements déjà réalisés.

Ainsi quand nouvelles technologies peut-être pas tout révolutionner. Relativiser la nouveauté pour savoir tirer parti de ce qui existe déjà.

Cauchemard d'un DSI innovation etc.
Car ne trouve pas d'argent. Ensuite des hackathons super, plait au ministre. Le mettre en place automatiquement.

Des façons d'aborder les chose sa plusieurs niveaux selon différentes problématiques.
Système courant
Système RetD
Système de gestion à Long terme

Innovation et pb de maintenance à limiter pour gestion à Long terme car sécurité priorité absolue.
intermédiaire un endroit où prend le risque avec contrainte moins forte.
Ensuite innovation, la fait n'importe quoi l'idée de développer, faire un pas sans contrainte pour développer de nouveaux concepts. Alors héberger dans la structure de recherche pour éviter contamination.

Mais être clair entre nous avec ces trois niveaux, ne va pas passer d'un niveau à l'autre sans changement. Obligation pour ce faire de prendre en compte des aspects métiers, qu'il faut nécessairement prendre en compte. (Langages, machines, ouvertures problématiques)

Méthodes de développement agile pas non plus dans la tradition française des DSI. Ne travaille pas par équilibre du consensus mais par l'équilibre des oppositions. Avec des tensions certes. Mais la culture française.

Méthodologie agile intéressant, résultat plus satisfaisant pour tout le monde. Mais en productivité ou délai pas forcément gain. Dans l'itératif donc intéressant, mais sur ensemble du cycle pas vraiment.

### Plusieurs âges de l'informatique.

Période où IBM dominant
X86 normalisée dans les serveurs donc fini

Âge du logiciel MISO Microsoft SAP Oracle
Mythe tombé grâce à la normalisation d'Internet et logiciel libre.

Troisième âge la donnée. Monde dominé par Google, Facebook. Commencé à poser problème car plus l'abstraction monte plus se rapproche de l'humain.
Comment s'en sortir. Collectivement par la mutualisation.

DPS7 vous avez aussi des bases dans des formats pas possibles. Donc comment fait avec ce stock. Bien sur ultra urgent de réfléchir sur le flux pour arrêter de produire n'importe comment. Mais un stock 4 millions de notices. Inimaginable de les reprendre à la main.
Solution en commun, peut-être faire appel à la foule. Certes de l'information experte, mais êtes vous sur que votre information est sûre ?

Le prochain stade sans doute l'incertitude. Pour le moment fait des assertions comme paris est un capitale. Sauf que des gens qui font des assertions. Ici qu'entre en jeu le big data. Peut être aussi la solution que l'on aura pour traiter notre stock de données. Il va falloir intégrer cette relation d'incertitude. Plus se rapproche de la connaissance humaine, moins sera dans le domaine de la certitude.

Dans la période d'attrition actuelle peut-être pas penser la totalité, etc. Affronter cette incertitude peut-être la solution. Pour le moment pas une solution intégrée techniquement. Prendre en compte l'incertitude, c'est aussi prendre en compte la relativité.
Par ailleurs penser que derrière vous d'autres petits jeunes qui viendront casser le modèle avec la solution qui résoudra tous les problèmes...

### Discussion

Humilité par rapport dimension métier

Vincent IRI
Une dimension de l'ordre du jugement, ce qu'appelle la controverse qui fait la science. Intégrer une normalisation qui permettrait d'intégrer dans les modèles ce genre de chose. Des modèles d'herméneutique numérique.

Monin
Fiabilité différent de la confiance.
Vrai que quelques travaux dans le domaine. Du mal à faire avancer ensemble web de données et théories des controverses. Gens qui n.utilisent pas forcément les mêmes technologies, ou qui ne s'apprécient pas vraiment. Le temps qu'arrive sur des standards encore loin.

Une initiative pour déjà permettre tracer provenance. Heuristique appliquée à un modèle de graph.

Bernard Farjus
Il y a bien les données culturelles, mais aussi une culture de la donnée qui se profile.
!!





------
Olivier Thereaux, Péripéties de la BBC a dans le monde des LOD
------

Il était une fois dans un royaume pas si lointain

Historique ancien de la BBC
Télédiffuseur depuis les années 30 
Sur internet des les années 1994

Découverte par les ingénieurs et équipes de développement en 2004 web domain driven design ???
Chaque chose une URI, une URI par choses
Alors peut avoir des vues de données de type RDF/XML

Mais tout n'était pas rose dans ce monde
Ouverture de toutes les données dans des vocabulaires utilisables par tous. Alors google va prendre nos données mais eux des milliards pour les arranger de manière pertinente. Risque de rendre nos données irelevant.
Peur de la perte de contrôle qui a constitué un gros frein à nos ardeurs d'ouverture de données.

Beaucoup eu d'expérimentation, mais peu d'innovation. Car nombreuses de données dans nos placards pas libre de droits. Agréments avec agences météos, sports, etc. Souvent peu clairs pour l'ouverture des données. S'est donc dit qu'aller être flou en matière de licence. Des expérimentations, mais quand nécessite évolution avec investissement et startup, plus personnes.

Est donc retourné vers nos principes
Le Web est notre CMS, chaque URI une chose, etc.
Qu'en faire.

Un des succès pragmatique dont parlait peu. BBC avait fait des choses à partir de données ouvertes dont disposait et qui marchait très bien. Des données sur qui passé à la radio et quand, etc. Mais pas de connaissance nécessairement fine sur ces personnes. Pouvait pour ça faire référence à d'autres données ouvertes telles que Wikipedia.

Deux avantages à cela. Utiliser des données ouverte permet de disposer d'identifiants. Mais également des environnements et nous permet de nous intégrer à tout cela. Peut participer à la base Wikipedia. 
En tant qu'utilisateur de LOD cela a plutôt bien fonctionné.

Depuis 2009 beaucoup aussi utilisé le LOD en interne. Linked data plateform pour construire des sites web. Nous a permis de passer d'un système ou chacun so. Truc dans son coin à mise en commun efficace sans avoir à tout refaire depuis le début. Se contenter ajouter petits tags, pour permettre ensuite de récupérer ensemble sans avoir à changer la plateforme de publication. Aujourd'hui en train de le faire  de manière pilote sur des informations de lieux pour produire de l'information locale à bas coût. Mais aussi des stories au sens de développement narratif des histoires. Interressant pour nous que l'utilisation assez simple de LOD permet de passer d'une information très répétitive et pauvre en elle-même à une information qui s'intègre dans une trame narrative, à faire du sens.

Travail avec le Gardian pour développer une ontologie pour voir comment cette série d'événements peuvent faire une histoire, faire l'Histoire avec un grand H.

BBC world service
Venus nous voir il y a deux ou trois ans avec quelques téra octets de diffusion. Trois ans d'écoute ! Une belle archive, mais les métadonnées horribles.

Dans ces cas là que faire ?
Une solution qui marche les stagiaires !
Mais si faisait quelque chose de plus flexible et réutilisable que le stagiaire. Démultiplier le stagiaire : un algorithme ! Qui allait probablement faire  mieux qu'un stagiaire... Utilisation d.un logiciel de reconnaissance vocale. = transcription de programmes plus ou moins utilisable. Ne dit pas que compréhensible, mais des mots, et d'après la fréquence des termes, possibilité d'extraire des éléments d'indexation avec une certitude plus ou moins grande. 

Revient alors à l'humain qui va maintenant nous aider à vérifier. Ouverture de cette archive au l'onde en permettant de contribuer. D'abord à ouvert à des fans un outil pour localiser les plages d'écoutes par speakers. Plusieurs sujets extraits. Demande aux auditeurs de nous confirmer cette extraction de sujets.
Idéalement se retrouve avec un cercle vertueux. Auditeurs nous aide et peut faire en sorte que nos algorithme apprennent de cette correction. Et peut maintenant le faire et l'utiliser pour nos programmes en live, à la volée.

Une extraction de sujets peu coûteuse, mais surtout la possibilité de la mettre en relation avec notre archive et l'histoire en donnant à l'auditeur du contexte.
Utiliser le passé pour expliquer  le présent.

Ces technologies de web sémantique ne demandent pas nécessairement de tout reprendre à zéro. Au contraire ajoute successivement des couches de compréhension, d'identification et de sémantique. Et petit à petit va pouvoir reconstituer et pouvoir offrir à nos auditeurs des informations de contexte.

Europeana, donc pas tous seuls

Finir avec Marshall McLuhan
Partis avec beaucoup enthousiasme. Fait qu'ait eut un coup de frein 
Nous façonnons nos outils et nos outils nous façonnent. Amené progressivement des outils qui changent notre manière de faire ou de penser les choses. Ensemble de petites choses beaucoup plus disruptives qu'il n'y paraît. Nous amène petit à petit par des chemins détournés au monde que pensait créer il y a dix ans.


### Discussion

Monin
Sur les petits pas, sans doute le cas général pour le web de données.
Ainsi les CC du RDF et certainement pas les scénarios envisagés par les chercheurs.
De même les id.

Vincent IRI
Cas particulier car à la fils une culture de l'archive et de l'audiovisuelle. Différent en France où séparé. Une culture de l'auteur. Part d'editorialisation des données coûteuse.

R
Ouverture à l'idée d'utiliser les archives, je pense que cela va venir pour tout le monde. Pour le moment chez nous en cours. Mais une véritable richesse, et la possibilité que l'on va avoir pour puiser dans ces archives et chercher du contexte, ne va pas forcément changer la culture du maintenant, maintenant, mais tout de même.

Bien sûr une culture du rédacteur. Mais aborde cela avec humilité, carra sait comment lecteur va scanner la page, etc. Ce qu'essaye de faire pas remplacer l'éditorial, mais leur fournir des outils qui vont simplifier leur travail. Automatisation qui permet d'identifier David Cameron alors pas de problème. En revanche quand la machine raconte une histoire alors plus conflictuel. Humilité, humanité.







------
Joconde Lab.
------

Sous-Directeur des collections, directeur
Joconde Lab, projet mèné depuis 9 mois. Projet qui fait suite au partenariat stratégique avec Wikipedia France et sémantique média et INRIA dans l'idée d'une politique culturelle de l'accès.

Une politique qui remonte à André Maleaux, ne peut se contenter d'être fournisseur d'accès, il faut cultiver l'accès.

Délégation à la langue française. Multilinguisme. Les œuvres qui portent les langues et non pas les langues qui portent les œuvres. Chacun peut leur donner un sens, ouvrent toutes fenêtre sur l'universel. Il importe donc de faire rayonner les œuvres de l'esprit et les œuvres culturelles. Au nom même du pluralisme culturel que défendons la langue française. Quoi de mieux pour promouvoir cette diversité culturelle que de diffuser des œuvres...

Plateforme en 14 langues, ouverte à tous les locuteurs. La première fois que l'administration offre une telle diversité linguistique sur la toile. Ouverture à des langues plus éloignées de nous, chinois, pays émergea tes, etc.
Proposons également de naviguer en quatre langues régionales.

Termes de la base Joconde alignés avec la base Wikipedia à partir de DBpedia. Réutiliser des contenus textuels et multimédias. Des lors que le travail d'alignement, de liage à été fait. Des lors plus nécessaire d'avoir recours à la traduction pour offrir un accès multilingue au contenu. Seuls les éléments de l'interface sont à traduire.

Facteurs humains. Ce travail n'aurait pas été possibles sans la mobilisation de différents services du MCC DLF, direction des musées de France. Sous direction des systèmes d'information qui a su proposer un cadre souple. Le département des services numériques qui a su transmettre expérience HDAlab.

Une expérimentation qui n'a aucunement vocation à. Remplacer la base Joconde mais démontre à quel point les technologies du web sémantique peuvent être utiles pour la mise à disposition du patrimoine en ligne notamment du oint de vue du plurilinguisme. Espérons que puisse servir d'exemple à titre méthodologique, technologique, etc.

Service musées de France
Ne remplace pas base des musées de France.
Des peintures conservées dans les musées de France Élargissement champ à ensemble des collections 
Pas seulement 500 000 notices dont 300 000 illustrées, mais aussi pleinement devenue un outil de diffusion culturel à l'intention du grand public.

52 millions d'interrogation
Majorité des requêtes issues de pays francophone. La langue constitue donc bien un frein à la consultation des collections. Mais assurer la traduction en plusieurs langues d'une base de données en constante évolution pas les moyens. Ici tester l'intérêt d'une traduction dynamique.

Objets des collections publiques qui témoignent de l'évolution universelle. Renforcer synergie avec Wikipedia


### IRI 

Travail sur la capacité à caractériser les contenus des amateurs. Convergence entre cette capacité propre au ministère de la culture et de la confronter à celle des utilisateurs. Discussion catégorielle qui constitue un des programmes de recherche de l'IRI autour des Digital Studies. Opiniâtreté de Bertrand Sajus et Alexandre Monin à démontrer que le moment était venu.

Colloque 6 et 7 février résultat ANR
Enjeux de valeurs sur les contenus

Travail sur les catégories de Wikipedia pour les faire remonter dans l'interface et fournir des facettes.
Une chronologie, interface temporelle = manière très intuitive de naviguer dans la base. Aspect de serendipité que cherche à mettre en place. Geotagging des œuvres. Rapidité du développement car les données déjà targuées.

Important de voir la manière dont les données agrégées, en fait parti de la Bretagne, et grâce à Wikipedia que détermine la période chronologique. Ou dynastie Tang...

Prototype qui tire parti de Wikipedia pour traduire toutes les entrées quand disponibles dans Wikipedia. Permet de se balader dans toutes les langues : à partir d'une donnée française à pu aller chercher les données dans toutes les langues dès lors qu'étaient disponibles.

Exemple : Saint-Jean-pied de porc

Un premier pas vers quelque chose de plus technique à l'avenir. Notamment si veut offrir un accès par login pour constituer des dossiers personnels.

Intéressant y de voir que contributeurs peuvent ajouter des mots clefs qui n'existent pas dans le référentiel : exemple der des ders pour la 1ère guerre.

Propose aussi un tri aléatoire, en proposant aux gens de targuer les contenus. Proposer des chantiers aux utilisateurs et profiter de ces événements pour éditorialiser la collection.

Une interface développée en multi-terminal, une exigence du ministère pour les utilisateurs de tablettes.


### Point de vue des soutiens

Gros travail de liage, chaque terme vérifié pour s'assurer qu'il s'agissait bien de la même signification.

Sur la base Joconde à mis en avant des parcours.
Parti pris différent pour Joconde Lab qui consiste à proposer d'entrer directement par les images. Ne signifie pas les artistes les plus connus mais ceux pour lesquels dispose le plus d'oeuvres.
Avant des expositions sur des contenus. Ici serendipité choix d'une image, rebond sur définition de Wikipedia, et rebond pour avoir tous les objets similaires dans la base.

On utilise à la fois les contenus de Wikipedia et ceux des langages documentaires. Rebonds entre les notices Wikipedia, etc. Une approche basée sur le rebond et la découverte.

Dans Joconde une structure hiérarchisée forte
Dans le temps imparti pour développer joconde la à pris parti différent et pas hiérarchique. À nous de mesurer l'avantage ou l'inconvénient d'un tel choix.

Utilisation thesaurus Garnier pour la représentation des sujets.
Wikipedia qui donne un environnement contextuel qui n'est pas forcément celui qu.avait choisi Garnier.

Si tape Bretagne certain nb réponse. Ici approche plus intuitive.
Frise chronologique plus grand public.

Liage 84000 termes
IRI proposait des liens vers Wikipedia. Désambigüiser les homonymes. Possibilité de qualifier chaque lien : équivalence exacte, générique ou spécifique.
N'ont pris pour la traduction que les termes en équivalence exacte pour éviter les effets de bords.

37 779 termes au total
Une époque où critiquait beaucoup les langages structures. Surprise car plus de 80% des termes trouvaient leur équivalent dans Wikipedia
978 termes sans équivalents 

Scène utilisé 52000 fois dans Joconde, sans équivalent
De même pas transport par eau dans Wikipedia qualifie plus précisément soit transport fluvial soit maritime.
Louis d'Orléans terme générique. Parfois imprécision volontaire.

Deux grosses surprises
Croisement possible car Wikipedia riche d'une information que l'institution n.avait pas elle-même. Donc dans un enrichissement mutuel.
BBC avec Your paintings proposition de termes, mais ensuite déterminer l'information adaptée. Ne peut rejeter le terme parceque utilisé seulement une fois. Si terme de spécialiste. Ici intervention humaine nécessaire. Ce sur quoi devra travailler à l'avenir.

Projet qui s'inscrit dans un programme de trois ans qui s'appelle semantisation. Petite enveloppe mais grande autonomie.
Site web proprement dit 5 mois, ce qui est très court. 50 000 euros pour le site

Pas fait appel à un prestataire mais à un partenariat. Ici avec l'IRI et apport mutuel et résultat très fructueux. Un projet qui est une expérimentation sur le liage de données, le multilinguisme.


Maîtrise d'ouvrage, pas souvent donné de travailler aussi beau projet, et collaborer autant d'acteurs différents experts dans des domaines différents.

Gobelins l'école de l'image partenaire du projet
Un partenariat pédagogique, pédagogie par le projet. Associe graphistes et développeurs. 20 graphistes et 20 développeurs.
Très intéressés par partenariat culturels.

### discussion

Le but était d'exploiter les données indexées. Moteur full text pas prioritaire 

Peut-on envisager que le contenu soit mis à disposition et réutilisable à la communauté.
Cecil

Codes IRI sur mercurial (lien difficilement trouvable)

