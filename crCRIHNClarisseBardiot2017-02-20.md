---
date: 2017-02-20
tags: cr, conférence, crihn, visualisation, culturonomics, Clarisse Bardiot
---

# Conf Clarisse Bardiot, 20 février 2017

UdeM 26 personnes

Arts de la scène et Culture Analytics.

Un travail en cours et directement lié à l’expérience vécue à UCLA dans le cadre du programme Touch analytics. 

Nicolas Schöffer, CYSP 1, 1956, un robot présenté à la cité radieuse, interagit aux danseurs. Débuts de la performance digitale, 50 ans plus tard, secteur qui continue d’explorer les technologies numériques de manière diverse.

50 ans plus tard, pas intégré, DH Demeure un continent inexploré en études théâtrales. Se demander si pas l’étendard prometteur que sont pour d’autres disciplines.

Quelques initiatives individuelles ou isolées depuis 2000, certains chercheurs en art de la scène. Plupart qui concerne art du théâtre et littérature. 

Premier THAT Camp dédié en 2013 à NY pour arriver à l’organisation prix commun en 2016. Peu de publications également. Trois grandes références, Paul Spence, Debra Caplan, et n° Theatre Journal, en décembre 2016.

Plusieurs initiatives francophones éparses, en filigrane d’autres manifestations.

Registres de la Comédie Française, un des projets les plus importants, conduits en partenariat avec le MIT. Journées d‘études, et Humanistica, réseau sur les arts en général et les DH.

Plupart des initiatives qui reposent sur la première vague des DH qui consistent en la réalisation de base de données documentaires avec numérisation des documents. Parfois TEI pour édition de textes littéraires. Une première vague consacrée à la numérisation et la constitution d’infrastructures. Plupart des autres disciplines en sciences humaines fin 90, début 2000. Dans les arts de la scène autour de 2008-2009. Plusieurs initiatives, numérisation spectacle vivant, centres de création chorégraphiques nationaux, ou portail des arts de la marionnette. Archives théâtre irlandais et grands fonds d’archives. ECLAP bibliothèque en ligne des arts de la scène dans un portrait commun sur Europeana. Artistes archivistes : Merci Cunningham ou Robert Wilson qui engagent des archivistes dans leur compagnie. Pina Bauch 2010, etc.

Retard des arts de la scène que l’on peut en partie expliquer par une réticence des universitaires en études théâtrales mais aussi par la complexité des archives qui sont en jeu. Archives, maquettes, costumes, etc. qui sont compliqués à numériser et à mettre en valeur dans des interfaces en ligne. En fait, la plupart des opérations de numérisation réalisées, conduite pour protéger les fonds fragiles et assurer leur conservation.

Savoir dans quelle mesure modifie la pratique des chercheurs. Plutôt un changement de support qu’un changement radical de méthodologie. 

À l’orée d’une seconde vague des humanités numériques (Todd Presner), tournant 2010. Avec cette seconde vague apparaît seconde approche qui est celle des Cultural analytics. Cette approche, fondée sur les données, n’est possible qu’à partir de la constitution d’une première vague de numérisation.

Analyse de la culture basées sur les données. Un champ qui est né dans le sillage des recherches de Lev Manivich. Culture analytics plutôt que Cultural analytics. Considérer la culture au sens large du terme : autant interactions sociales que les œuvres elles-mêmes. Données qui tiennent donc compte à la fois des œuvres numérisées mais des échanges autour d’elles.

Culture analytics, 7 mars au 10 juin 2016, UCLA. 3 mois pour travailler à la définition d’un nouveau champ de recherche à la croisée des recherches informatiques et humanités. Nombreux workshop, à la fin du programme rédaction du livre blanc des culture analytics pour définir le champ et ses enjeux.

Pour sa part contribué au chapitre des collaborations disciplinaires. Caractérisées par deux phénomènes principaux.

- Premier phéno : utilisation d’algorithmes pour fouiller les données et les analyser
- deuxième phénomène : le recours à la visualisation de données pour comprendre ces données.

Recours à la visualisation de données et à la visualisation qui découle de la masse des données qui est de plus en plus considérable. Chercheurs qui travaillent sur des données vastes, qui explique que le chercheur ne puisse plus opérer par seulement une lecture rapprochée. Comment analyser des milliers de documents, comment analyser un réseau. Cf. comptes twitter d’un théâtre, etc.

Une approche qui en utilisant des algorithmes va permettre d’identifier des motifs récurrents ou des phénomènes particuliers qu’il s’agira d’analyser en revenant à la lecture de près. Il ne s’agit donc pas de sacrifier les approches classiques sur l’autel de la modernité informatique. Croisement entre approche qualitative et approche quantitative.

Découvre-t-on de nouvelles choses avec les Big data. Savoir si apportent des connaissances nouvelles, au-delà de la séduction des images, ce type d’approche va permettre la production d’un savoir que l’on aurait pu constituer autrement.

**Comme algorithmes pas toujours fiables, cherche à évaluer que algorithme est pertinent car valide phénomène que l’on connaît.** voir txt original

Peut distinguer plusieurs approches et terrains de recherche. Découpage en trois champ

- histoire du théâtre
- textes littéraires
- études de ses représentations

Derek Miller Visualizing Broadway

Debra Caplan, autour de la troupe Vilna, un corpus plus restreint, à partir des archives de la troupe.

Kate Elswit, American Ballet Caravan. Diverses échelles possible

Autres outils que la TEI pour édition numérique

réédition de Shakespeare chez Oxford qui au moyen d’utilisation de divers algorithmes de text mining d’extraire du corpus un certain nombre de pièces pour déterminer que ces pièces sont écrites en collaboration. Outils qui permettent donc de réévaluer l’auctorialité. Identifier des motifs récurrents, des signatures stylistiques propres à chaque auteur.

Une approche pas possible avec la TEI. Topi Modeling. 

Consiste à avoir une méthode pour identifier les termes récurrents dans un corpus. Très employée pour analyser l’évolution d’un sujet dans un journal.

Travaille sur la revue Leonardo, arts sciences et technologies. Utilisation de Mallet. Espère que sorte relation art/science.

Plusieurs paquets de mots. Premier paquet qui peut être considéré comme art et sciences, deuxième qui renvoie plutôt à l’art classique. Finalement une relation entre art et technologies, et arts traditionnels.

Tableau de proportion art et science dans chaque article. Comme difficile à interpréter, passe à la visualisation de données. Bleu arts traditionnels, et rouge art et science. Dans un premier temps, une revue qui traitait d’art traditionnel, puis proportion qui s’inverse avec des moments de rupture au premier tiers 80s.

Intéressant car oblige à se replonger dans les premiers articles, regarder les articles de rupture. En close reading pour aller voir d’autres types de question.

visualisation de 70 sujets qui permet d’identifier certain nombre d’autres sujets. Art spatial, etc. dont évolution fluctue dans le temps.

Christof Schöch qui lui utilise cela pour caractériser des genre dans 750 œuvres de théâtre français. Lui permet d’identifier des thématiques propres à la comédie ou la tragédie sur ensemble du corpus.

Question de l’analyse de spectacle, sans doute la plus épineuse. Sur quelles données s’appuyer pour transformer représentation en données. Question de la capture et de la saisie qui est une question épineuse, sans doute la plus difficile qui soit posée en études théâtrales.

Sait traiter des textes, voir des images. Mais pour les textes des technologies mûres pour le faire. Comment transformer en données tangibles et quantifiables des représentation éphémères. Images et captations vidéo. Captation de mouvements à même le corps des interprète. Et enfin, l’ensemble des traces documentaires issues des œuvres et des travaux de création.

Annotation graphique d’une image vidéo de danse, analyse algorithmique en utilisant outils de géographie. Processus qui va permettre de dénoter des aspects singuliers qui sans ça sont invisibles et donner représentation autre. Comment comprendre le mouvement en dehors du corps même. 

One Flat Thing Reproduced, pour Forthythe ne s‘épuise pas par la visualisation. Devient un projet artistique lui-même. Pour être réintégré dans d’autres œuvres.

Rekall consiste à mettre dans un espace multi-modal, les fichiers les sons, etc. en extraire les métadonnées et en produire une visualisation qui permettrait de comprendre un processus de création en jouant sur la partie qui a trait à la visualisation des données. Utiliser des outils d’analyse pour repérer des comportements ou des usages.

Plusieurs filtres pour opérer diverses analyse en X et en Y. Permet d’identifier comment une idée a circulé d’une personne à une autre dans une équipe. Ensemble des collaborateurs sont-ils présents à toutes les étapes de création, ou bien interviennent-ils de manière plus ponctuelle, quels sont les documents les plus importants dans une logique de préservation des œuvres.

MemoRekall, une webapp disponible sur le net. Ici du close-reading, permet d’agrafer les documents sur la captation vidéo. comme annotation. Permet ainsi d’organiser les documents entre eux autour de l’épine dorsale qui est la captation vidéo.

Theatre analytics. À travers ces trois exemples empruntés aux études théâtrales permettent identifier nouvelles questions de recherche, mais aussi nouveaux savoirs.

Theatre analytics, comme culture analytics, question des données fondamentale. La question de la collecte et du traitement. Mais certain nombre de données déjà structurées et disponibles en particulier avec première vague. Bien comprendre qu’il n’y a pas de neutralité des données et que leur construction, leur structuration en base de données pas neutres. Il n’y a pas de transparence.

Quelles sont les données des théâters analytics. Compte twitter, données disponibles databnf, etc. et fonds spécifiques.

Quelques pistes. Textes littéraires de plus en plus disponibles, y compris au format TEI mais question épineuse du droit auteur. Explique que textes anciens privilégiés dans ces approches. Question de l’accessibilité des données.

Billeteries des salles de spectacles, info socio-éco pour l’étude des publics, possibilité de croiser ces informations avec celles des politiques culturelles. Art Council financement depuis 2016 si capable récolter certain nb info. Une entreprise un marché. Adaptation des publicités, du prix des billets en fonction du goût des consommateurs.

Ici utilisation pour optimisation, remplissage de salles, au pire profit. Menaces sur programmations arts et essai. Données et leur analyse jamais neutres. Mais peut utiliser pour comprendre comment survie compagnie dans un environnement public, et besoins d’accompagnements.

Archives visuelles, affiches, programmes. Nbx collaboration à envisager avec études théâtrales.

Medium data plus que big data. Comment la gérer. David Believes sur le Workflow, comment manier les données, en saisir les grandes lignes, etc. Identifier nouvelles questions.

Knowledge			Data

​		|			|

Make assumption		Discover patters 		Predict and explore

​											|

​		(revise)						Criticize model

En réalité une boucle, chaque interprétation pouvant entraîner changement mécanisme.

Nouvelle façon de naviguer dans le corpus, entre micro et macro. Spirale pour faire progresser l’analyse et les résultats. Bien faire de la recherche en théâtre.

## Discussison

Algorithme ne trouve que ce qu’a mis dans l’algo. Que les présupposés qu’y a mis trop fort. Donc manque de digital litteracie des chercheurs, et que pas suffisamment conscient des enjeux et idéologies à la base de ces algo.

Apprend-on quelque chose de ce que les informaticiens ont mis dedans ? Car codés par gens qui ont des questions différentes des sciences humaines.

Vraie vertue à collaborer avec les informaticiens. Reposent complètement les présupposés de la manière dont envisage les technologies. La difficulté dans ce dialogue là de tenir au centre les questions de recherche. En même temps, allés dans une orientation que n’avait pas du tout au début, devenu un outil de visualisation de données. Pas prévu, mais ce qu’a tenu documentation de la recherche.

Topic Modeling, 4 ou 5 algo qui sortent à peu près tous les mêmes résultats. Considère que stable du point de vue technologique. Possible de les mettre dans les mains des chercheurs sans qu’en comprennent tous les attendus épistémologiques.

Souvent des questions de recherche

Question posée par Marcello qui s’applique à toute la production des données en général, par exemple choix des mots-clefs, etc. dans la définition réponse que va se poser. Bien sûr que pas tout réglé avec ça mais merci information.

Des fonds complexes d’un point de vue archivistique, mais aussi une résistance des chercheurs. Pas lié au mythe de la présence qui est une question esthétique. Mais habitus d’un champ qui n’énonce pas clairement ses méthodologies de travail. Souvent production essais littéraires ou impression. Réflexion sur les données et les méthodologies très peu menée.

Plus de dpt arts de la scène au CNRS, en partie lié au refus réflexion.

Des images qui ont différents statuts selon les chercheurs. Pour certains, la fin en soi de la recherche me semble particulièrement problématique. à partir de ces images là que va continuer à poser des questions de recherche. Donc un statut heuristique pour essayer de reformuler des questions de recherche mais pas le résultat de la recherche. Donc important de ne pas trop se laisser séduire.

Des instruments pour la recherche et pour l’analyse.

Lui qui a vraiment voulu circonscrire ce champ en 2005, à lui donner et un nom et surtout travailler sur un corpus d’images sur lequel les gens ne travaillaient pas. Sans doute un travail novateur. Bien sûr des enjeux de territoire que connaît bien dans le domaine de la recherche. Il a été très généreux au cours des trois mois. Tinguety ?? qui a surtout été la cheville ouvrière.

Intéressant le glissement de cultural analytics, à culture analytics. Une volonté d’ouvrir le programme à des questions au-delà des artefacts culturels et des images que ne l’avait fait Manovich pour prendre en compte dimension anthropologique.



