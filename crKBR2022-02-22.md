# # Digital Heritage Seminar: The Visual Digital Turn – Computer Vision and the Humanities

## Digital Heritage Seminar: I**mage Processing**

Sebastien De Valeriola (ULB)

4e série, après avoir envisager méthodes pour les données textuelles et géographiques ou relationnelles et analyse de réseau. 4e série focalisée sur l’analyse des images. 

Un part considérable de notre patrimoine est aujourd’hui disponible sous forme d’images que les chercheurs ne peuvent ignorer. Nous montrerons que les méthodes computationnelles offrent des possibilités nouvelles pour les exploiter.

Isabelle Gribomont Louvain

Julie Birkholz



KBR invites you to attend a scholarly series on digital cultural  heritage: the KBR Digital Heritage Seminar, in cooperation with  ULB-UGent-VUB-UCL.

In this series from February to June 2022 we will virtually host  three academic scholars in presenting their work on cultural heritage  and specifically on **image processing**.

“The devil is in the details!” When it comes to digital cultural  heritage, this is as true as “The devil is in the images!” Great efforts have been devoted to the digitization of original collections in the  cultural heritage. On the one hand, this helps greatly in promoting the  collections and in allowing the general public to have much easier  access to the collections (e.g. by publishing the images on websites  like our digital library [Belgica](https://belgica.kbr.be/)). On the other hand, technologies still need to be advanced in order to  fully exploit the information (e.g. texts) that are still locked behind  the digitized images.

In this series, we are very honored to have three **researchers who have rich experiences in image analysis** and especially for **extracting information from digitized collections**.

### Programme

**Thomas Smits,** University of Antwerp

#### “The Visual Digital Turn: Computer Vision and the humanities”

Digital humanities research has  focused primarily on the analysis of texts. However, digital and  digitized sources also contain large numbers of images. Using several  research projects as examples, I’ll discuss how scholars in the  humanities can apply computer vision techniques in their research. Among other things, these new visual AI methods allow researchers to analyze  patterns of (re)circulation of images, analyze patterns of media (use),  analyze patterns in visual content at scale, analyze patterns of  representations (gender/social class), analyze patterns in visual scenes and analyze patterns of visual style. In short, I’ll show how these  techniques have opened up the visual side of the digital turn.

### Beyond Text Visual and multimodal digital humanities

Travail sur machine multimodale.

Historien des médias du 19e et 20e, sépacialisé en histoire visuelle. Travail focalisé sur la recherche, essaye d’appliquer des techniques computationnelles sur des matériaux historiques. Adopte une approche hypothèses et expérience. Distant reaading. CV et multimodal ML pour débloquer la partie visuelle des archives.

DH est depuis longtemps très focalisée sur le texte. Voir comment utiliser l’ordinateur pour étudier les archives.

Pourquoi les DH sont principalement orientées sur le texte ? Cela s’explique d’abord par la large disponibilité du texte (Guthenberg, OCR dans les années 2000).

Disponibilité des techniques de NLP : LDA/Topic modeling permettant étudier

Nouvelles approches comme Distant Reading de Moretti.

« Practical revolution » (Nicholson) où au lieu de partir du haut de l’archive, met en avant un accès bottom up directement depuis le token de la collection numérisée.

Toutefois les médias modernes sont très largement orientés sur les images. Aussi les DH manquent largement le domaine de la culture visuelle. Vie moderne de plus en plus saturée par les images que nous devons être en mesure d’intégrer dans nos pratiques. Nous avons donc besoin de devenir des lookers et ne pas être seulement des lecteurs.

Forme des collections numériques, exemple où seulement les blocs de textes de pages de journaux sont identifiées alors qu’un grand nombre d’images peuvent être extraites. Avec des techniques automatisées, possible d’extraitre des millions d’images.

Ici les approches de vision computationnelle pour l’analyse des images sont venues à notre secours. Ces approches consistent à considérer les images comme des données. Un peu comme l’OCR pour le texte, offre un accès bottom-up aux images. Comme NLP CV methods peuvent être utilisées pour trouver des pattern. ...

Un champ de l’informatique qui cherche à obtenir une compréhension de haut niveau du domaine de l’image.

Computer Vision

Gain a high level of understanding of images using computational means

Reconnaissance objet, classification d’image ou thématiques de classification.

Cela peut consister en un programme qui trace des boîtes autour des choses pour les classifier. Cela peut paraître très décevant, mais pendant longtemps tâche considérée irésoluble. Mais l’introduction de nouvelles techniques computationnelles comme les CNN Convolutional Neural Network d’une part et la disponiblité de nombreuses images sur le web pour entraîner ces réseaux artificiels qui a permis une percée considérable dans le domaine.

Il est important de bien combrendre que l’ordinateur ne voit pas des images mais voit des nombres. Une image pixellisée qui est mesurée sous la forme de degrès de luminosité. Finalement l’image une collection de nombre.

Convolutional Networks réduisent les images en une forme qui est facilement traitable par ordinateur, sans perdre les aspects (visual signals) qui sont nécessaires pour prévenir les classes étudiées.

Convolution un petit carré qui parcours une image et qui change au niveau de l’environnement du pixel. Permet de considérer des signaux faibles autour d’un pixel.

Trouver le setting parfait des dials (covolution) pour visualiser l’image.

Mais comment ces techniques peuvent-elles nous permettre de débloquer l’accès aux images des collections numérisées ?

- Les tâches majeurs de CV peuvent automatiquement décrire (ajouter des métadonnées) aux images
- cela rend les images découvrables pour les utilisateurs et analysables pour les chercheurs.
- Les métadonnées peuvent aussi être utilisées pour décrire des collections entières. Pour déterminer des tendances, outliers, et des silences visuels, etc.

Image Classification : CHRONIC, projet lorsque research fellow à la Deuth Library. 

https://lab.kb.nl/dataset/chronic

313 images de journaux

classifiées en 9 catégories : 

- construction
- images humoristiques
- chess
- crowds
- logos
- maps
- schemas
- partition de musique
- rapport météo

Il est également possible d’utiliser ces classifications pour décrire ce que représentent les images. Par exemple pour étudier tournant entre illustration et la photographie dans les journaux.

Exemple avec Leo Impett. Énorme acroissement de l’utilisation des images dans les journaux neerlandais.

Aussi possible d’utiliser classification de manière très binaire.

Par exemple Hesseini au Turing Institute. Division du plan en petite section et analyse pour identifier présence d’infrastructure ferrovière.

Https://academic.oup.com...

CHRONReader : Query Classified Historical Newspaper

Connecter nos images classifiées au texte qui acompagne les images. Nouvelles manières de parcourir la collection qui permet de disposer de portraits, etc.

Une application pour parcourir des journaux numérisés américains à la bibliothèque du congrès

https://news-navigation.labs.loc.gov

Object Détection. Advances in Digital Music Iconography. 

Https://zenodo.org/record/3859953#.YH_OzWhcJpQ

Facial Recognition

Étudier la représentation au cours du temps. Réentrainer les models pour tester Goffman’s gender displays. 1M pubs NRC 1955-1995.

Dans NRC dans les 60, plus de femmes que d’hommes, puis présence masculine devient prédominance. Montre choses relatives à l’augmentation de la publicité sur des enjeux financiers.

Un outil potentiellement très puissant pour étdier grand groupe d’îmage.

GAN et archetypical representation.

Travail plus expérimental. Besoin d’avoir une idée plus ou moins consistante de ce que recherche. Mais aussi possible d’avoir une approche dans laquelle va créer des images alternatives pour signaler ce que veut chercher.

Le modèle est entrainté pour reconnaître les visages.



Une fois qu’a acquis ces données, possible de représenter les images sur une carte en fonction de leur similarité. Cf. PixPlot Yale. 

Très bon exemple de la manière dont on peut appliquer ces techniques.

### Forme des collections numériques

Toutes ces images dans leur sources originales sont en réalité connectées à leur texte environnant. Donc situées dans un contexte multimodal.

Théorie de la multimodalité des média moderne.

Idée que le plus souvent communication multimodale.

Commen aborder cette question computationnellement. Car un problème complexe : meaning multiplication. Une image dans un contexte distinct ne signifie pas nécessairement la même chose.

Comment aboder connexion texte et images.

Distant reading 940 000 online circulations of 26 iconic photographs

Application Topic Model en conjonction de l’image. Observe que signification reconfigurée au cours du temps par différents types de textes.

Smits, Thomas, et Ruben Ros. 2021. « Distant reading 940,000 online circulations of 26 iconic photographs ». *New Media & Society*, octobre. https://doi.org/10.1177/14614448211049459.

Voit comment différents textes donnent signification différente à des images.

Multimodal Machine Learning 

CLIP early 2021

https://openai.com/blog/clip/

Similaire aux techniques de computer vision. Mais entraîné sur 400M image-text combinaison. Mais pas comme tâche de prédire classification image mais quel texte apariés dans un jeu de données.

Apprendre des concepts visuels depuis le langage. Possibilité de connecter des concepts linguistiques à des concepts visusl.

Peut entraîner des choses pour lequelles pas pré-entraîné.

Peut constituer une nouvelle révolution pratique pour les collections patrimoniales. Car possible de décrire automatiquement ou ajouter des métadonnées sans pré-entrainement spécifique à la tâche, sans besoin de données annotées.

Par exemple utilisée pour prédir scènes internes ou externes dans collections de vues pour lanterne magique. A montré que plus efficace.

Aussi effcicace pour des techniques hautement complexes.

- beaucoup de concepts visuels pas purement visuels (ex. famille où ramène famille humaine mais aussi animale, erreurs mais qui dénotent des concepts importants pour l’expression visuelle du concept de famille)

CLIPScores.ipynb

Colas.research.google.com/drive/12MgTRJ7

---

Leonardo récemment reçu un important financement pour explorer les biais de CLIP.

Pense que plus sensible grande variété de médias visuels. Pas besoin de réentraîner le modèle lui-même.