---
date: 2014-04-10
tags: cr, lod, web sémantique, ModRef
---

Cr 4ème atelier du Labex, Journée ModRef, 10 avril 2014
===========

Introduction Ghislaine Glasson-Deschaumes
------------

Nouveaux venus au sein du Labex : 8 nouveaux projets et 7 projets de préfiguration pour leur donner le temps de mûrir.

Atelier conçu comme un séminaire général, temps de réflexion et de travail collectif. Car Labex conçu non pas comme une agence de moyens mais comme un projet de recherche collectif alliant des acteurs très différents issus de métiers participants de manière égale à la construction des questions de recherches du Labex. Il n'y a pas de projet de recherche collectif sans ouverture à de nouvelles propositions, dès lors que celles-ci viennent s'intégrer aux questions du Labex.

Remercie l'équipe Modyco et le travail du groupe de travail Modyco.

Rendre compte d'une étape de travail du groupe ModRef qui fédère douze des projets du Labex qui sont en prises avec le numérique.
Deux axes dans le Labex :
- connaissance active du passé, plusieurs fonds faisant l'objet de campagnes de numérisation - et réflexion sur les usages de ces fonds et les pratiques et usages de ces projets.
Inclure les nouveaux projets à forte dimension numérique nouvellement entrés : image dialectique, musée virtuel et imaginaire, odysseo.

Avec cette journée, porter la réflexion sur le numérique à un niveau de généralité plus important qui engage chacun de nous en tant que chercheur, documentaliste, ou de conservateur, mais aussi en tant que citoyens. Les questions posées sont d'abord des questions épistémologiques, et scientifiques. La question de l'organisation des savoirs à l'ère de la numérisation et de la mondialisation avec les enjeux de la standardisation, posent des problèmes importants pour l'avenir des disciplines. La question de l'accès des sources de l'histoire et du passé, soulève des questions importantes car elle transforme nos relations au passé. Aussi, l'objectif de cet atelier consiste à réduire une fracture constatée entre les chercheurs en sciences humaines et sociales et les ingénieurs ou documentalistes déjà très avancés sur l'appropriation du numérique. Cet atelier est donc destinés à fonder une culture commune au sein du Labex et que ne dise plus que ces questions sont des que des questions techniques.

Programme conçu avec des intervenants engagés dans des projets du Labex et des personnes externes. Idée de confrontation de points de vue sur la manière de s'approprier le web sémantique et les enjeux du Linked data.


Ancrer les projets numériques dans le Linked open data
-----------
Antoine Courtin et Jean-Luc Minel

Faire le Bilan des projets au sein du Labex.
Faire une analyse de l'existant, en dégager des choix et des enjeux. Bilan de ce travail qui nous a conduits à proposer la réalisation d'un "proove of concept" sur ces projets là.

Travail issu d'un projet du Labex sur la Modélisation. Référentiels et culture numérique. Un projet fédérateur qui a regroupé de juin 2012 à aujourd'hui les douze projets au sein du Labex.

Deux objectifs :
- Analyse de l'existant et inventaire des projets au sein du Labex en caractérisant leurs finalités et leurs contraintes. En évitant que ces projets se développent en parallèle sans mutualisation, tant en terme d'approche que d'objectifs.
- Deuxième axe portant sur la culture numérique. Il s'agissait d'aborder les conséquences de l'utilisation des référentiels sur le savoir et les appropriations du savoir.

Diversité des projets qui regroupent aussi bien des projets qui numérisent du texte, de la vidéo, etc.

Documents produits à partir de données réunies sur les projets. "en fait de calcul et de proportion, le plus sûr moyen de parler à l'esprit, c'est de parler aux yeux". Acquisition des données grâce à des interviews et des sondages. Alimentation d'un fichier CSV et réalisation de graphs en JavaScript.

### Analyse de l'existant

Cinq dimensions d'analyse :
- dimension organisationnelle, nature des institutions, partenariats
- dimension technologique
- dimension conceptuelle, modèles conceptuels qui sous-tendent les modèles métiers
- une dimension juridique
- enfin, une dimension relative aux publics et aux usages qui en découlent

On verra que chacune de ces dimensions influent sur les aires. Par exemple le choix d'une licence interfère avec la possibilité de réaliser des mashups.

Douze variables :
- Disciplines engagées
- dimensions modale objectifs final, cible
- nature des équipes et des partenaires
- ...

#### La complexite organisationnelle

La composante organisationnelle du Labex et des projets rend extrêmement difficile la conception du système cible que l'on se propose de construire.
Douze projets, les institutions qui pilotent les projets, celles dont relèvent les institutions. Enfin présence au sein du Labex ou non.

Si les choses étaient simples, aurait seulement des lignes droites. Une chaîne décisionnelle simple. En fait, ne va pas se passer comme cela car douze institutions, et nombreux services qui vont interférer dans la décision.

Ce poulpe montre que la dimension organisationnelle est très importante et qu'il ne s'agit pas seulement de questions techniques.

#### Dimension temporelle

Dimension temporelle également complexe, choix qui n'interviendront pas au même moment selon les projets. Dates de production des premières anotations, numérisation, etc.

Certains disposent déjà des métadonnées et besoin de réaliser la numérisation, d'autres l'inverse.

#### Complexité conceptuelle

Plusieurs modèles possibles pour un même projet
Modèles métiers

#### Complexité technologique

Plusieurs plateforme, certaines propriétaires, certaines libres et développements propres.

La sphère ModRef
Insertion dans le LOD
Flèches unidirectionnelles doubles pour savoir si souhaite récupérer contenus
Interpperabilité entre les contenus.
Standards communs employés.

Publics, par diagrammes contrastifs, identifiés selon deux axes


### Choix et enjeux

Cinq projets parmi les douze
Exposition oai-pmh, api, sparql-endpoint

modes d'exposition des données
Question des licences
Zoom pour médias numérisées et métadonnées

Nombreux modèles, donc un choix à faire
Modèles qui fige un domaine de connaissance
Mais langages que peut articuler

**Importance des URIs :**

Deux politiques actuellement soit chaque partenaire ou institution décide de ses URIs, soit decide d'avoir ses URIs en local, soit décide de s'aligner avec d'autres institutions.

Des lors que veut participer au LOD peut sembler pertinent de lier ses données à des URI extérieures. Mais un enjeu important lorsque l'on choisit d'utiliser des URIs extérieures, on délègue la gestion de son autorité à quelqu'un d'autre.

Moteurs qui risquent d'intégrer des URIs dans leurs algorithmes. Getty : Un acteur crucial qui vient de décider de placer ses quartées vocabulaires dans le LOD en juillet 2013.

Est-ce que cela relève du scientifique ?
D'un point de vue linguistique, qui dispose du langage dispose de la pensée. Manière de normaliser.
Expérience à l'ISO que le choix de la terminologie est très important.


### Objectifs et étapes

Identification
Des jeux de données
Conversion des données, alignement et publication en vue de la réutilisation.
Plusieurs outils que va tester pour preuve de concept.

Datalift
Karma
Pour les outils open source


Isidore, Présentation de Stéphane Pouyllau
---------------

Nombreux travaux à mener sur distinction Linked open data et ?

Montrer que quand on utilise les techniques du web sémantique et du web de données, quand on s'inscrit un projet dans le Linked open data, on est amené à prendre des décisions qui peuvent être lourdes de conséquences tant en termes scientifiques qu'en termes organisationnels. Dès lors que l'on formalise numériquement les questions, on ouvre une cocotte minute que l'on n'est pas tous à même d'aborder de la même façon.

Le projet Isidore est issu du basculement de la recherche en SHS dans le monde numérique. De 2000 à nos jours, une grande époque où l'on a fabriqué des plateformes numériques, développé des archives ouvertes et des plateformes pour publier sur le web un ensemble de documents plus ou moins structurés et répondant à des modèles plus ou moins différents. Dans toutes ces année, force est de constater que n'a fait que multiplier les plateformes sans se poser vraiment la question de savoir s'il ne fallait pas faire l'effort de plus structurer nos publications en allant vers des objets nouveaux, beaucoup plus hybrides. Objets nouveaux dont ne s'est pas non plus suffisamment demandé comment pourrait les conserver et les pérenniser. À tel point qu'a pu arriver à une overdose de plateformes numériques : un projet, un chercheur, une plateforme...

La plupart des scientifiques se positionnent non pas en fonction de la nature des données que vont produire que de fonctionnalités qu'une plateforme va produire.
Se positionnent beaucoup moins en termes de nature des données que va produire, de durabilité, etc. par ex. Archéologues et Logiciels de gestion chantier de fouilles se posent plus la question de la publication des données, plutôt que de la représentation et modélisation stratigraphique.

On peut dire aujourd'hui que l'on a passé plus de temps sur la publication que sur la structuration de ces données. Une fracture entre les ingénieurs et les chercheurs, avec désintérêt de ces aspects technologiques chez les chercheurs. Quand les ingénieurs sont bons et font les bons choix ça va, mais parfois peut arriver à des problèmes. Ce que je voudrais aborder aujourd'hui.

Le rôle des métiers qui sont très importants, monde de la recherche, monde d'accompagnement de la recherche, bibliothécaires et conservateurs. Métiers qui sont au cœur du mouvement des humanités numériques et de cette hybridation. Le projet Isidore n'aurait sans doute jamais vu le jour si n'avait pas passé le temps nécessaire à mettre ensemble des gens issus de métiers différents.

Avec le projet Isidore, à essayé de décaler les choses par rapport à cette logique de plateformes. Qu'est-ce qu'il y a finalement dans ces plateformes ? il y à des données et on a voulu nous y intéresser plutôt qu'aux modalités d'interogation. Isidore est un Une plateforme de moissonnage, de collecte et d'enrichissement des données. une histoire longue d'abord conçu comme meta-portail en SHS. Puis passé à un bus de services, etc. Mais le chercheur en sciences humaines et sociales ne fonctionne pas tout à fait comme dans d'autres disciplines en terme de maîtrise de la technique. Beaucoup de discussions sur ce qu'il était interressant de signaler, etc.

Est-ce que fabriquer un meta-portail c'est aussi faire un réseau social en SHS ? Sans doute content que n'aient pas choisi cette voix là.

### Enjeux

Faciliter le signalement, l'accès et la recherche
Dépasser la classification.
Proposer un espace de navigation qui relie les documents numériques. Un dispositif qui va moissonner des documents dans des entrepôts différents et proposer des liens sémantiques sur des documents stockés à des endroits différents.

Ont voulu mettre en avant la valorisation de la stucturation de l'information produite par les laboratoires. Quand produit cela, nous répond forcément qu'il existe déjà Google. Donc s'appuyer sur le travail fait, et faire le choix d'un moissonnage ciblé. Pas un projet qui moissonne des pages web. Pour être présent, il faut en faire la demande, c'est-à-dire être prêt à faire un travail de valorisation, de structuration et de décloisonnement.

### Trois modes d'accès

Recherche Isidore un moteur de recherche pour les humains.
Mais aussi mettre en œuvre une API.
Et dépasser la notion de web de documents pour donner accès aux informations à l'intérieur des documents.

Schéma classique
Mais ont fondé les entrées sur des protocoles ouverts et normalisés utilisés par les projets des humanités devenues numériques. Pour entrer dans Isidore on doit donc adhérer à des protocoles normalisés ouverts utilisés par les communautés SHS à travers le monde : OAI-PMH, sitemaps RDFa, flux RSS, et non pas des interfaces propriétaires.

Pourrait moissonner par les pages web, mais ici idée de dire à Isidore ce qui est pertinent. On renverse la méthodologie classique des moteurs de recherche. **La valorisation et le signalement, finalement avant tout de la responsabilité des scientifiques. Important car permet de faire progresser les communautés sur l'appropriation de ces fonctionnalités.**

API REST
Et triple-store avec SPARQL-endpoint pour accéder à des données structurées.

Dans tout le dispositif essaye de mettre en valeur les techniques du web sémantique. Le format pivot exprimé en RDF, et triplestore qui expose les données en format RDF. Important car permet à la communauté de récupérer des données en RDF.

En fait pas seulement un moteur de recherche, mais une chaîne d'enrichissement des données qui permet la réutilisation de données normalisées en sortie.

### Pourquoi le web sémantique

On a voulu dépasser la logique d'un web de document pour casser logique de cloisonnement documentaire et cette logique de plateforme. Va même plus loin que OAI-PMH, proposer une solution technique et industrielle qui aille au-delà de cela.

Trois niveaux du web
Web de document, web de socialisation, web de données où utilise les protocoles du web comme une grande base de données en utilisant ces standards. Pour s'affranchir des problèmes posés par les API. En fondant les API sur des protocoles ouverts, etc. rend application tierces moins dépendantes qu'avec une API propriétaire.

Participer au web de données ce n'est pas que webifier les données, mais également se poser la question des modèles documentaires. Possibilités de réutilisations de vocabulaires de pratiquer des rebonds pour de l'enrichissement. C'est tout cela que veut dire passer à l'échelle en passant au web sémantique.

Participer au web de données, inscrire ses données dans le web sémantique signifie tout cela. Mais c'est aussi une responsabilité quant à la qualité de l'information que met à disposition, car c'est cette information qui va être réutilisée par d'autres. À partir du moment où l'on décloisonne les données, une responsabilité non pas seulement éditoriale mais concernant la qualité. C'est également une responsabilité technique en terme de maintenance des URIs de la mise à disposition. Une réflexion que voit trop peu aujourd'hui dans les humanités numériques. Se positionner sur le Linked open data c'est intéressant, choix des modèles, etc. Mais aussi se poser la question de savoir de quelle infrastructure on se dote pour que continue de rendre  disponible ses données et de maintenir ses dispositifs dans le temps car d'autres vont réutiliser ces données.


Anne-violaine Szabados
-----------

Fortunes d'un objet antique très célèbre, Centaure du Louvre.
Site du Louvre, informations variées, parfois très précises.
Succès de l'objet et de son schéma iconographique qui le rendent susceptible de beaucoup se promener sur le web.

Centaure qui est à la fois source d'information mais également placé au sein d'un réseau d'information.

CIDOC-CRM Modèle conceptuel de référence
EDM

CIDOC qui offre énormément de possibilités pour modéliser l'information

LIDO un modèle plutôt destiné à l'interoperabilité des données de collections

HADOC citation avant-propos Caylus

Discussion
-------------

Q : Incantation qui consiste à expliquer que n'était pas dans le technique mais dans l' épistémologique. Important de nourrir cette question.

Minnel pourtant anne-violaine à bien instancié cela
Si décide d'une URI pour le centaure, suppose qu'adhére à la catégorisation du Getty par exemple. Or, une certaine représentation de l'organisation du monde. Sinon se poser la question de l'alignement, or c'est une question compliquée : comment repère ces différentes URI et comment on les aligne. Si cela n'est pas possible humainement, implique de passer par des outils automatiques, et ici une difficulté. autre solution éventuelle celle du crowdsourcing.

SP Comme a l'avantage de s'installer dans un contexte normalisé, reste cependant possible de typer la relation. Donne la possibilité au chercheur de qualifier l'information avec plusieurs éléments, donc de donner au chercheur plusieurs choix et d'en débattre dans sa communauté.
Ne pourrait-on pas débattre dans chaque discipline des grandes représentations à l'œuvre dans notre discipline et les formaliser ? Finalement plutôt cela qui est interressant avec le LOD, beaucoup plus que la technologie. Des questions que l'on avait abandonnées avec les moteurs de recherche : replacer dans le débat scientifique des systèmes de classification, et les terminologies.

Sarah : plutôt l'impression d'avoir compris ce que vous avez expliqué. Me fait plutôt peur, notamment tous les enjeux de sociabilisation du pouvoir, par exemple avec le Getty. Impression que dans un premier temps devrait travailler sur des enjeux de classification et de production d'URI.
Question du pouvoir et des instances. Quel type de hiérarchies est-ce que cela implique ? Il y a-t-il au ministère de la culture quelqu'un qui fait la même chose ?

SP Il est clair qu'au ministère de la Culture des gens qui ont très bien compris ces enjeux. Quand la Bnf pose un URI dit qu'elle est la BNF et qu'elle sait faire ça. Question de savoir à qui reviendra le soin de mettre des URIs. Aujourdh'hui le far ouest, des bonnes pratiques, mais le premier qui arrive qui plante sa tente.

Aurait pu proposer avec Isidore un système qui attribue les URIs, qui prenne le pouvoir finalement. Jean-Luc voulait cela, SP n'a pas voulu. Lorsque ce choix qui a été exposé au comité scientifique, celui-ci a choisi de donner des URIs à tout le monde mais que l'on permettrait à ceux qui en disposaient déjà de les passer afin de les ré-exposer.

JM : Celui qui attribue l'URI s'engage pour l'avenir. Une suite de symboles de caractères. Certaines institutions qui choisissent algorithme aléatoire pour que n'ait pas de sens.
Dans le choix d'attribuer un URI aux choses, il y a bien choses à faire.

GGD voit qu'une simplification. Il y a-t-il une ambition encyclopédique explicite ?  Que signifie aujourd'hui faire une encyclopédie à partir d'un vocabulaire ? Mais aussi savoir ce que l'on abandonne et ce que l'on laisse lorsque l'on fait un choix de vocabulaire.

SP choix qu'a résolu au départ, idée pas de faire un outil de republication plus exhaustif. S'est contenté de dire que connaît accès et faire de la signalisation. Liens entre les données que publie pour lesquels a fait des choix que l'on assume, concerne les enrichissements placés par dessus. Modèle que publie également pour le rendre disponible.

Minel un élément de confusion entre modèle, vocabulaire et ontologies.
Modèle privilégie l'objet, l'œuvre où l'événement qui affecte une œuvre. Par exemple le CIDOC est centré sur une certaine représentation. EDM met en avant le document.
La représentation, là tout les modèles ont choisi RDF. Donc pas forcément de perte si une équipe fait l'effort ajouter certains éléments de vocabulaires pour enrichir les choses du départ.
Par contre si au départ on n'a pas prévu de traiter les événements qui affectent un objet et que le modèle ne le permet pas, alors l'aura perdu.

La question à laquelle je ne sais pas répondre, est-ce qu'il y a des modèles culturels dans les vocabulaires. Par exemple FOAF friend of à friend, sur les relations sociales, savoir si ce vocabulaire est porteur d'un modèle culturel.

Certains vocabulaires ne sont pas uniquement des vocabulaires mais aussi des classifications. Par exemple avec ATT, on voit bien que ce thesaurus est porteur d'une représentation du monde. Mais parceque certains vocabulaires portent en eux une ambiguïté sémantique des problèmes. Par exemple DC, il y a  plusieurs manières de le traiter, visiblement chacun est capable de trouver une logique qui lui est propre.

Katell Au contraire pas d'appauvrissement, avec modèles très riches pas d'appauvrissement au contraire. Complément d'information sur la politique du ministère de la culture : Le ministère s'empare actuellement de la question web sémantique. Groupe de travail l'année dernière pour définir les grandes actions pour structurer présence sur le web semantique. Parmi ces actions enjeux des identifiants pérennes qui consiste à mettre en place identifiants pérennes. Plus enjeux opérationnels stratégiques et politiques que technique. Autre stratégie possible qui consiste à pouvoir être porteur d'une politique institutionnelle, par exemple avec la production d'identifiants ISNI.

BDIC propre de ce Labex associer bibliothèques et musées. Propre de ce projet ModRef, de converger vers des standards descriptifs communs. Importance de passer au web de données. Des niveaux inégaux, tendre vers un socle commun.

Unification
Distribué

# Rmq perso

question du passage à l'échelle qui rend la question nécessaire pour mutualiser l'information. Jusqu'à présent, bases de données relationnelles qui pouvaient en partie reposer sur des implicites.

Logique distribuée du web qui pose problème pour être transposée au web sémantique. URI pas tres difficile à produire en fait, plus difficile à maintenir.
Infrastructure nécessaire.


Symogih et le web de données, Francesco Beretta (LHARA)
-----------

Intervient en tant que chercheur qui a partagé il y'a quelques années l'idée d'une base de données collaborative plutôt que chacun développe son projet dans son coin.
Présentation d'un projet du pôle d'histoire numérique du LHARA, au départ pôle méthodes. Une équipe de compétences diverses en SIG, encodage XML, bases de données. Ensemble de technologie qu'essaye de mettre au service de l'histoire autour d'un modèle.

Outre ce modèle, propose une plateforme. Système modulaire de gestion de l'information historique. Partis d'un double questionnement, comment amener les historiens à utiliser des outils numériques. Et comment permettre au chercheurs de connecter leurs données avec celles produites par d'autres chercheurs ou les institutions patrimoniales.

Exposé qui s'articulera en trois point
- Présentation de la plateforme
- Insistance sur le problème du modèle
- Enfin question de l'interconnexion de nos données avec celles du web de données.

### La plateforme

Une plateforme utilisant diverses technologies
Hébergement auprès des différentes structures
Sauvegarde données à la grille de service HumaNum, serveurs à la MSH.

Actuellement trois sites web
Données sur l'histoire du patronnat ANR. Bon exemple de prolongation des données à partir d'un projet d'ANR qui permet la réutilisation des données dans d'autres contextes.

Un système de gestion de description de ressources historiques géographiques, que l'on gère dans un gazetier avec un atlas historique.

Enfin un site exposant les données que les chercheurs ont décidé de rendre disponibles. Cet outil d'abord destiné à faire de la recherche individuelle. Travail en SQL. Possibilité de travailler la chronologie, la correspondance et des travaux classiques en histoire. Volonté de démontrer possibilité de ces approches avec cet outil.

Possibilité de mettre des données d'entretien pour extraction de réseaux de personnes.

Outre la recherche individuelle, également de la recherche académique. Exemple de site web qui compprte 2 000 notices sur l'histoire économique. Scholasticon, l'auteur ne connaît pas la population. Décomposition sur certains axes. Peut donc analyser ce sous-effectif. Permet également d'identifier des populations. Permet déjà de voir la période de naissance d'une partie de la population, en croisant avec des données spaciales possibilité d'approches de visualisation des données.

### Le modèle de données

Tout ceci est très classique certes, mais ici un système collaboratif auquel contribuent des chercheurs collaborativement. Suppose d'emblée d'avoir posé la question du modèle. Un modèle suffisamment générique pour être déconnecté des projets. En même temps garantir la traçabilité de l'information historique et de l'incertitude dans le temps et dans l'espace.

S'est d'abord dit qu'il fallait partir de connaissances atomisées.
Un auteur nous dit telle ou telle chose, un autre telle ou telle.
Première opération que fait tous, et qui a été formalisée,d ans ce texte on reconnaît des objets que l'on a identifié, puis que l'on a classé en définissant des classes d'objets.

Enfin des événements, des dates, des sources
En somme la fiche Bristol en histoire, simplement l'information est atomisée et le modèle à permis la généricisation.
Ce modèle générique est ensuite instancié
La lettre de type lettre
Les objets qui interviennent vont se voir attribuer un rôle
Ensuite important de pouvoir disposer d'un système complexe de datation et de sourçage. Enfin une interface web pour éditorialiser la source.

Pour le moment traiter une partie du domaine de connaissance. Sur le site web des descriptifs de chaque instance du modèle historique. Par exemple comment a traité le fait d'enseigner.

Modèle essentiel, ne dit pas comment faire mais décrit la production des données. Il permet donc la réutilisation des données en permettant de comprendre comment les données ont été produites. Permet donc de formuler des requête, d'obtenir des résultats.

On a donc un modèle générique qui est instancié par des modèles dédiés à chaque type d'information.

### La question de l'interconnexion

Ceci faisait, possible de travailler en commun. Possible de publier les donnes mais aussi de les croiser et de les réutiliser dans différents contextes.
Maintenant aimerait pouvoir passer au web de données. Avoir un entrepôt ne sert à rien. Mais pose beaucoup de questions. Aimerait pouvoir lier les données à des données externes, pour enrichir notre base de  données. Cela pose deux questions importantes, d'une part quel modèle utiliser pour publier les données de la plateforme, et d'autre part sous quelle licence publier ces données.

Pour le moment à créé une URI pour chaque instance. Possibilité de derenfencer pour le moment pour l'humain. Cela la condition pour faire du codage sémantique dans la TEI. Pour utilise ref et correspond doit pouvoir disposer d'URI publiques.

Possible d'alimenter la base avec des liens vers des referentiels.
Principe fondamental du système, de permettre au chercheur de publier ce qu'il souhaite. La question est maintenant de savoir si veut passer à autre chose en mettant en place un entrepôt SPARQL sur nos données.

Par exemple DBpedia qui permet d.exposer données et d'y accéder par interface de requête et de réutiliser ces données. Peut utiliser ces données pour la recherche. Par exemple un travail sur le territoire italien georeferencé. S'est donc demandé s'il pouvait y avoir des donnes disponibles sur le web que pourrait projeter sur cette carte par exemple pour faire des analyses spaciales.

Par exemple données des publications de B3.. Allemand, pour identifier des phénomènes intéressants. Bien sûr représente la documentation mais montre que des possibilités de réutilisations. Ainsi voulons-nous faire ce genre de chose ?

La solution technologique est en place depuis le mois de mai de l'année dernière. Il est globalement facile de produire un SPARQL-endpoint mais la question est de savoir quel modèle utiliser et celle des droits.

Par exemple avoir le concept de cardinal plutôt que lettres permettrait de naviguer. Système qui est entièrement prêt pour définir un graphe où chacun aurait son rôle. Actuellement ce que veut faire c'est établir un modèle qui nous permet de faire ce que veut faire. Commencé à travailler avec CIDOC CRM mais trop spécialisé. Puis BIO pas mal. L plus proche Simple évent role, mais centré sur la notion d'evenement. Puis travaillé avec factoïd qui est interressant

Choisi développer ontologie maison. Date rôles, sourçage de l'information.
Quel modèle choisir pour l'Interoperabilité des sources historiques pour pouvoir tout exprimer sans perte de richesse d'expression ? Soit quel modèle pour exprimer le travail de l'historien. Quelle licence ? veut-on permette à un autre chercheur de produire de la connaissance à partir des données. Quelle licence doit-elle autoriser les usages commerciaux par exemple ?


Brigitte Juanals
-------------

Analyser les données dans une perspective politique. De ce point de vie envisager les musées comme des espaces de territorialisations.
Un contexte instable, finalité de cette communication qui consiste à analyser les conditions de communications et de circulation des données dansants des environnements techniques. Mais envisager ces aspects numériques comme des espaces de renégociations. Ensuite articulation domaine culturel. Puis intermédiation qui réside dans l'introduction de nouveaux acteurs dans le rôle que jouent dans la diffusion de la connaissance, et dans la dimension d'autorialité. Recomposition des rapports de pouvoirs. Souligne rapports dimensions matérielles introduit par la technique, et rapports entre les différents acteurs.

Mission de diffusion des musées.
Mises en forme de la connaissance au travers d'actions de publicisation. Médiation culturelle qui s'est développée dans les années 80 qui présente aussi une dimension politique notamment pour démocratisation de la culture. Numérique qui depuis les années 90 déstabilisé les cades de diffusion. Dans ce contexte les musées portent une position sous-jascente. Pose hypothèse que enjeux redéfinition entre science culture et société qui en déplaçant les lieux de parole porte une redéfinition territorialisation.

Actualisation singulière de cette publicisation.
Méthodologie qui analyse publication pro et politique. Deux corpus constitués afin d'evaluer les orientations majeures des musées. Premier corpus des acteurs. Ensuite un deuxième corpus constitué de la production éditoriale numérique de plusieurs institutions. Travail mené concomitamment à des entretiens.

Étude qui a débuté en décembre 2012
Présence affichée d'une politique de développement numérique innovant retenue comme critère. Quai Branly, Getty, Denver, moma, san Francisco muséum

Entretiens qui font apparaître que motivations des musées s'inscrivent dans une adaptation aux techniques de publications mais aussi d'usage de leur public. S'inscrivent donc dans dimension marketting.
Constat généralisé application pour mobiles. Usage de la réalité augmente et de données ouvertes encore essentiellement américaines, sinon prévu à l'horizon de deux années.

Adaptation aux nouvelles formes conçues en rapprort dispo de com tablettes, etc. vision hypertextuelle
Environnement immersif.
Sortir d'une conception de la communication unidirectionnelle qui permet de sortir de la seule logique de diffusion.

Utilisation croissante d'outils de communication numérique
Déstabilisé modes de communication
Rôle croissant joué par les industriels de la communcation et des acteurs

Institutions qui s'appuient sur un écosystème numérique qui se construit par l'intégration successive de contenus et d'outils.
Constitution qui restent centralisée. Les formes de la médiation numérique reconduisent un contrôle qui leur était antérieur.
Site web qui constitue généralement l'axe central de la diffusion. Présentation de la collection et de l'institution.
Des logiciels interactifs et des environnements immersifs utilisés à plusieurs fins. Blogs vocation initier le public aux métiers du musées et des compétences. Partage de l'espace institutionnel avec le public qui révèle des clivage. Une tradition médiation à l'attention des publics scolaires et jeunes. Médiation scientifique valorisation de ressources.
Pratiques editoroiales facilités mais non induites.
Adaptation aux publics. Musée de Denver qui va régulièrement inviter population ne participer aux activités au musée.
Usage social des terminaux mobiles qui a provoqué des changements pour utilisation de ressources. Par leur intermédiaire à vu arriver de nouvelles formes éditoriales et de nouvelles technologies qui se sont adaptées au contente d'utilisation mobile. généralement gratuite.

Public jeune utilise mobile
Audio guide pour public plus âge. Condition contractuelles d'utilisation. Introduction de technologies sans contact. Acteurs industriels qui ménent opérations de communication et de test. Ex cité architecture pour NFC.
Musées qui restent partagés dans l'utilisation de ces technologies. QR code parfois pour plus d'indépendance.

Environnement qui implique distribution par les plateforme de téléchargement commerciale des marques. Par contre conservé contrôle des podcasts.
Enfin pour les publications scientifiques situation hétérogène pour la publication en ligne. Accès parfois payant et plus ou moins numérique.

Nouvelles catégories d'acteur. Généralement externe au musées. Engagés dans la production hors du contrôle des institutions. Réseaux sociaux. Google qui s'appuie sur notoriété et solutions innovante pour s'imposer comme acteur de diffusion. Wikipedia. Nouveaux acteurs extérieurs engagés dans la production de contenu en rapport direct avec les collections.

Réseaux sociaux qui consistent à entretenir activité soutenue. Notoriété qui ne suffit pas, cf exemple communauté du Louvre.
Critère de performance qui n'ont pas vraiment de signification sur la nature des publics et de significations. Les préoccupations marketting bien que pas généralement explicités néanmoins impliquées car conséquence sur la perception du caractère innovant des institutions. Problème que peut poser celui d'un risque de censure idéologique. Récemment suspension du compte d'un musée pour avoir présenter poitrine dénudée. Autocensure.
Tous préconisent diversification des lieux de presence pour garrantir autonomie. PRatiques de liens. Utilisation principalement à fins de marketting et redirection lecteurs sur les sites institutionnels.

Idem pour Google art
Accepté généralement présence modérée du fait de la notoriété de Google. Améliorer notoriété et visibilité en ligne, et rediriger les lecteurs vers les espaces numériques du musée. De même art Babel.

Wikipedia suscite des réactions différentes
Projet capitolin différemment perçu même si tous vus pratiques accès à Wikipedia lors des visites. Ignore la nature des contributeurs et présence dans le personnel. Réactions différentes, parfois refus comme au Getty du fait anonymat et consensus. Toutefois apport qui peut être également evalué de manière positive notamment pour un besoin d'actualisation des données sur des acteurs contemporain.
Bien sur politique du projet Wikipedia qui a évolué et ordonnait les initiatives GLAM wiki avecnpartenariats avec diverses institutions.
Question des reproduction des œuvres. Ex Wikipedia et national galery
À l'exception du sfoma qui considère que la propriété est un non sens tous les acteurs en faveur de la propriété des œuvres.

Analyse qui fait aoparaitre évolution de ces modes d'appropriation des connaissance. Porteur de permanences dans les formes d'appropriation culturelle t numérique. Intervention de nouveaux acteurs qui induit déstabilisation. Suscite redistribution partielle des modèles de diffusion. Ré configuration des modes de diffusion, ou entremêlement plusieurs logiques, diffusion public, modèle industriel, etc.


L'exemple du Musée du Quai Branly, Anne Faure
----------

Quelle diffusion patrimoniale et culturelle oury un établissement culturel museal européen à l'ere du web de données.

Au milieu et au cœur d'injonctions contradictoires toutes évoquées.
Injonction marketting, questions technologiques, et questions de choix et de formation.

Double tutelle dimension de recherche
De même publics, centre de recherche
300 000 objets
400 000 photos
350 000 ouvrages

Ensemble des collections gérées dans des bases de gestion des collections
Toutes diffusées en ligne
services de réseaux sociaux, etc.

Bases de production qui sont en lien avec d'autres opérateurs nationaux comme le Sudoc, Gallica, data.fr et les archives nationales
Enfin Europeana et worldcat

Conséquence aujourd'hui.hui deux mondes
Ce qui est diffusé pour le moment dans une logique de silos avec des interfaces propres de diffusion de nos données sur le web. Et partie relationnelle du CMS sans lien avec ces types de données. Données encapsulées dans le site qui pour le moment ne communiquent pas avec nos autres données.

Ensemble de la documentation qui dispose de métadonnées. Langages maison et vocabulaires contrôlés maisons. Indexation en partie avec RAMEAU.
Mais généralement des données fortement structurées mais avec des langages maison.
Dispositifs capables actuellement exposer en DC et webservices.

Pour les archives Évolution du système avec possibilité de gain en terme de souplesse. Langages indexation maison pas forcément reliés avec autres. Mais aujourd'hui EAD accessibles avec OAI-PMH.
Pour le son langage d'indexation formalisé avec RAMEAU.

L'environnement légal
Quel est le statut légal de ces donnes. Savoir que pour le moment des données enfermées, donc pas vraiment de statut. Elles sont très peu disponibles sur le web et échange de données souvent très conrtactualisé.
Les donnes du catalogue de bibliothèque seulement un statut car dans le SUDOC donc licence Étalab.

Pour les photos Plusieurs cas. Soit libre, soit sous droits, soit sous droits avec ayants droits que ne connaît pas. Dans tous les cas réutilisation qui passe par une agence tarifée de gestion des droits. Pour les archives sonores et multimédia, statut un peu le même. Divers selon les cas.

### Vers quelle stratégie de diffusion de données ?

Ici que se rejoingnent plusieurs contraintes. Un musée qui est un établissement public et première demande tutelle plaire au public visibilité sur le web et améliorer présence, tout en continuant missions traditionnelles.

Mais petite structure, trois au service informatique
Donc choix informatique qui doivent être urbanisés dans nos systèmes, que doit pouvoir maintenir technologiquement compétences.

Demande de réutilisation très forte et dimension de restitution.

Demande forte open data par ministère et établissements de recherche qui demande ouverture des données.

Comment répondre à tout cela ?
Occasion de refonte site web et reconfiguration de l'ensemble des systèmes.
Savoir si choix open data ou partiel. Selon choix plusieurs chantiers à conduire, pas les plus aisés à conduire en termes de ressources humaines.

Alors choisir de faire les choses progressivement.
Mieux répondre aux besoins en décloisonnant les données et sortant de la logique de silos. Depuis fin mars, nouvelle interface qui nous permet Interoperabilité entre les quatre grands corpus de données objets, bibliothèques et photos.
Enfin disposiTif de cartographie. Système de facettes et nuages de tags, réseaux sociaux tout en conservant des possibilités d'usages pour les chercheurs avec constitution d'albums personnalisa les.

Pour le moment cela en utilisant les données et catalogues actes les en utilisant les flux.
Comment ça marche ? En production, toujours nos silos ce qui nous permet de ne pas toucher à la production de nos données et qui font l'objet d'un enrichissement continuel. Pour le moment pas touché la question des modèles et des référentiels.

Tout fonctionne avec un indexeur
Ensuite par les entrepôts et api de nos bases que va chercher les autres données.
Pas encore travaillé sur la question du sémantique. Mais arrive déjà à favoriser accès et navigation dans les données avec les technologies dont disposait.

### Pourquoi la question du sémantique se pose-t-elle aujourd'hui ?

Parce que besoin de faire des liens plus profonds dans nos données. Permettre access direct sur nos ressources et liens entre elles que veut créer automatiquement par exemple lors exposition. Pour le moment pas possible. Actuellement exposition sur des pages web séparées. Voudrait réunir tout cela. Des informations pratiques évidemment. Mais également un autre public qui lui entrera avec d'autrtes modalités. Par exemple chercheur et historien qui devraient pouvoir accéder avec d.autres interfaces et modes accès qui ne doivent pas être concurrents mais complémentaires.

Notre problématique, un existant et situation sédimentaire. Ne peut pas se lancer dans l'ouverture des données si bp de licences avec centaines de milliers de notices.
Identifie bien problèmes résolus et posés avec le centre Georges Pompidou virtuel. Doit les anticiper.

Schéma technique sur lequel part
Toujours production de donneess mais ajoute autres fichiers pour la production éditoriale
Dans cette partie de l'application souhaite faire de l'alignement de données, c'est-a-dire faire converger nos vocabulaires et envisager une publication en RDF et une politique de LOD.

Ici signifie travailler sur nos modèles et nos vocabulaires. Signifie aussi que va se donner un peu de temps pour réfléchir sur les outils et modèles auxquels le plus interressant de se rattacher.

Dans les mois qui viennent d'abord travailler sur nos données pour les faire converger.
Acquis un topic manager de mondeca dont attend beaucoup.
Ensuite va essayer de faire évoluer nos modèles vers des standards présentés et tester ce qui sera le mieux pour nous car ne sait pas.
Enfin publier nos données et éventuellement un modèle ou une ontologie réutilisable dans d'autres institutions anthropologiques.

Exemple indien plaine
Notice épaves descriptif
Référence ouvrage dans la bibl
Et référence à la programmation culturelle
Car aujourd'hui séparé. créé automatiquement des liens

Autre possibilité récupérer données externes. Et enrichissement de nos propres données.
Pourquoi nous intéresse car pu déjà enrichir rameau avec nos vocabulaires. Dès lors que pu faire ça alors nous semble logique ensuite de pouvoir travailler avec quelque chose comme Data.Bnf.fr


Sophie Derrot, remanescence du passé numérique...
----------

Trois sites au contenu numérique pur
N'existe plus sur le web
Exemple typique de contenus nés numérique présents en ligne qui ont une existence éphémère sur laquelle une institution patrimoniale et culturelle doit concentrer son attention en vue de  la conservation.

Dépôt légal de l'internet qui se base d'abord sur une obligation légale. 1537 François premier. Temps long mais adaptation constante pour s'adapter au support de présentation.
Jusqu'a 2006, loi DAVSI étendue à internet
Décret application en 2011

Important car loi qui cadre nos activités
Institue deux institutions légales pour le dépôt légal Bnf ina
Périmètres propres ina 10 000 sites
Bnf tout le reste

Objet signés signaux transmission ou message de toute nature faisant l'objet d'une communication au public par voie électronique

Dépôt légal de nature différente. Pour internet, l'institution dépositaire qui va capturer le dépôt en ligne.
Changement de définition de paramètres géographiques.
Ancien dépôt légal tout ce qui était importé. Techniquement pas possible. Mise en place d'une étrange définition de l 'internet français. Contenu produit ou enregistré en France ou édité par un producteur résidant en France.
Logique d'exhaustivité remplacée par une logique de représentativité.

Expérimentation
Travaille avec associations, chercheurs et laboratoires
Et consortium qui regroupe 50 institutions internationales intéressées à l'archivage du web. Permet bonne vision des pratiques et des collections.
1996-2005 achat collections françaises.
Travail entièrement en interne depuis 2010
Collecte quotidienne janvier 2014 470 to de donnnees. Collection les plus importantes dans le consortium.
Pb manipulation des données sur les supports en maintenant cohérence des données et de la collection.
21,2 milliards de fichiers

Cycle d'archivage du web désormais complet depuis 2013 avec brique préservation SPAR OAIS
Utilise robot heritrix
Index
Versement sur des supports d'accès
Utilise waybackmachine

Robot URI, poids et date exacte de collecte par timestamp
Deux filière pour les urls collecte large au moins une fois par an 2013 56 to, plusieurs millions de noms domaines fournie par afnic. 13 semaines
Des collectes ciblées plus régulières selon ressources ciblées
Conserver cohérence avec collection, et s'intéresser au spécificités du média numérique
Articulation avec politique documentaire ex site avec Roger Planchon et photo arts et spectacle
Exemple spécifique au médias, gif animés symptomatique du média.
Sites politiques, actualités et pure players
Collectes électorales
Collecte thématique débat manifeste pour tous
Échos en ligne révolution tunisienne
Collecte à la demande d'une institution.
Corpus et édition en ligne

Droit de tout collecter et possibilités demande lever bloquage
Mais loi qui restreint la consultation des contenus à l'accréditation et enregistrement
Possibilité étendre consultation aux partenaires.

Recherche par URL
Pas encore de recherche plein texte

Beaucoup de travail sur interface de consultation
Défis techniques important pour l'affichage de contenu multimédias. De même les réseaux sociaux.
Un système de per malien qui permet de citer explicitement des articles tels que consultés dans l'archive. Permet citation pérenne de la donnnee.
Travail sur les corpus avec les chercheurs comme tiers de confiance.
Collecte ponctuelle. Encore à inventer leurs propres outils pour visualisation.

Valorisation dans le contexte de l'indisponibilité.
Parcours guidés
En ligne essayé de donner visibilité aux collections sur certains contenus.
Vont être de plus en plus présents dans Data.Bnf.fr
Travail avec data.gouv sur exposition des donnnees notamment web électoral


Questions juridiques, Lionel Maurel
-------------
[nota : Lionel a en partie basés sa réflexion à partir de l'exemple des guides de Paris au sujet duquel nous avions échangé]

Juriste qui travaille à la BDIC

On a déjà bien vu que les questions liées au web de données pouvaient présenter des enjeux liés au web de données. Une question fondamentale dans certains cas tout autant que les questions techniques.

Exemple sur un projet fictif
Des choix qui se présentent et qui ont des répercussions ensuite sur les possibilités de mediation par la suite.

Choix d'un projet fictif (en fait inspiré discussion sur les guides de Paris)
Prenons le cas d'un projet de numérisation d'un corpus de livres anciens dont les auteurs morts depuis plus de 70 ans donc dans le domaine public.

Numérisation en mode image, ocr puis correction manuelle, texte encodé en TEI, indexé. Enfin valorisé de manière numérique avec un dispositif numerique.

Assez représentatif des dimensions que l'on trouve dans nombreux projets. Et qui posent la question de leur statut. Verra que des objets de nature différente qui a chaque fois posent des questions particulières.

Scan image, OCR et tanscription et encodage TEI.
Très souvent doit se poser la question de savoir si ces objets sont saisissables par le droit d'auteur et susceptibles de protection.

Scans ne généré pas une œuvre nouvelle protégeable par le droit d'auteur. Ne fait pas acte d'originalité quand bien même des opérations techniques particulières.

De même texte océrisé pas protégeable par le droit d'auteur même si investissement important et mise en œuvre d'une competençe technique.

Quant à l'encodage, mise en œuvre compétence technique mais pas constitutif de la production d'une œuvre. Quand produit des notices, le décrit selon des champs indexation, même si fait des choix, pas des choix qui relèvent de la personnalité et donc susceptible de la protection du droit d.auteur.

Ne veut pas dire que ne peut pas les protéger par d'autres droit car sont des données qui peuvent être saisis par d'autres fondements juridiques ou terrains juridiques.
Fondement qui sont le droit des bases de donnes et le droit de réutilisation des donnes publiques.
Droits des bases de données qui est un droit européen, lorsque investissement substantiel, peut se voir reconnaître droit de protection pour la structure de la base et empêché extraction complète de la base.

Droit accès données publiques. Droit européen. Droit reconnu aux citoyens et que l'administration peut conditionner à une redevance si réutilise dans certains contexte.
Ces deux droits qui s'appliquent donc à la réutilisation.

Dans les projets de ce type encore valorisation éditoriales et rédaction d'articles pour un site. Ici les juges reconnaissent facilement expression d'une personnalité et reconnaître l'attribution d'un droit d'auteur.

Pour résumer une couche de données
Une couche de métadonnées toutes deux de même nature et relevant du droit des bases de données. Et pour editorialisation droit auteur.

Ici un schéma un peu brutal
Car quand prend connaissance des choses disponibles, exemple Joconde, un petit texte dans une notice qui peut provoquer une appropriation par le droit d'auteur. Difficile de savoir à partir de quel niveau un texte bascule dans le droit d'auteur.

Question de savoir qui est titutaire
Pour droit auteur la personne, mais droit des bases de données l'institution qui fait l'investissement (parfois difficile à savoir). De même pour acces données publiques.

Agent publics réputées céder leur droit à la tutelle sauf si enseignant chercheur, alors conservent leurs droits. Si agent public, cèdent leur droit.

Voici le panorama
Ceci dit quand projet, se pose la question du choix d'une licence et permettre la réutilisation ou pas. Le choix fondamental lorsqu.égagé dans les projets.

Si ne voulez pas permettre réutilisation alors va devoir l'exprimer en faisant appel aux différents droits qui encadrent ces contenus. Cf. Louvre conditionne réutilisation à une demande préalable.

Peut choisir d'ouvrir. Savoir que la fermeture se fait de manière systématique. Si ne fait rien, votre base est protégée. Si vous voulez permettre la réutilisation, vous allez devoir l'exprimer par une licence. Cette license peut tout de même poser un certain nombre de conditions. En fait un contrat qui lie la personne qui va réutiliser les éléments.

Plusieurs licences applicables mais pas toutes au même niveau
Pour les Scans et OCR, peut utiliser une public Domain mark pour dire que l'œuvre est dans le domaine public.
CC0 qui dit que peut avoir droit sur cet objet mais qu.y renonce volontairement.

Licence ouverte d'étatlab pour réutilisation donnnes public, ici  à n'importe quelle fin.

Pour les métadonnées un peu pareil
ODBL qui fonctionne comme licence logiciel libre, si réutilise les contenus en les mélangeant à d'autres alors mettre à disposition même cadre
Cc0 et public Domain mark

Les autres cas ne fonctionnent pas car ces licences alors sans fondement.

Peut donner des cas complexes.
Cas tablettes rennaises qui montre que peut conduire cas complexes.
Public Domain mark autorisé réutilisation commerciale
Base de données en ODBL oblige si remise libérer
On tenus éditoriaux en CC by
Voit ici que complique un peu les choses car plusieurs licences et certaines moins connues

Quand on est dans un contexte universitaire un choix de décider ou non d'ouvrir ses contenus. Mais un choix qui est une exception car depuis 2011 loi sur open data qui oblige à rendre licence ouverte. En 2011 principe exception pour mettre redevance sur certaines réutilisation.

2013 rapport Trojette qui a fait analyse de ces redevances, et montré que retours pas profitables par rapport à abandon licence. Administration centrale aujourd'hui interdiction appliquer licence.
S'applique établissement publics admi sous tutelle de l.admi

Mais pour la recherche et la culture un régime spécifique
Dans la loi réutilisation des info publiques article 11 dérogation établissement publics et de recherche et culturels qui dit que peuvent fixer leur propres règles.
Pendant longtemps pas su ce que signifiait. Procès archives. Jusqu'à jurisprudence favorable redevances, puis 2013 rapport ministère de la culture guide qui indiquait que article 11 pas contradictoire. Fin 2012 nouveau rapport et feuille de route numérique. Puis automne numérique.
Décembre 2013 nouveau rapport équivalent rapport Trojette même conclusion soit un signal très fort aux établissements. Cependant, ne peut pas l'ordonner. Les institutions culturelles toujours à l'heure du choix.

Exemple d'institution qui ont déjà fait le choix de libérer. Exemple de la Bnf. Autres établissements politiques particulières, exemple centre George Pompidou virtuel fait effort passage au Linked data mais pas open data. Ce qui a pu interpeller car bénéfice maximal du LOD lorsque ouverture.

Pour l'enseignement et la recherche, arrive dans une phase intéressante. Pas de formalisation de ce niveau de la part de la tutelle. Pas certain que le ministère puisse formaliser une politique aussi claire car autonomie université et CNRS.
Ministère en tant que tel obligé aller sur open data, mais contribue qu'avec sept jeux de données.

Problème de la nature des données.
Des données de recherche
Données des chercheurs
Les données pour la recherche un Labex comme le notre qui doit se pistionner.

Un événement qui pourrait changer la donne, beaucoup de bouleversement europent. Directive sur ouverture données qui vient du droit européen or cette directive à évolué et France qui va devoir transposer en droit français. Suppression exception pour la culture, mais conservé pour la recherche.

Choix mais choix de moins en moins libre car positionnement des institutions. Question de savoir si veut lier les données dans le Linked open data. Obligation de les ouvrir. Un accord de consortium en cours, mais non imposable. Nous aussi à l'heure des choix.


Le programme HADOC, Katell Briatte
---------------

Chef de projet de maîtrise d'ouvrage
Programme HADOC

D'où viennent données du ministère de la culture, données historiques car produites depuis l'epoque du Minitel.
En fait viennent de processus métiers. Qu.est-ce que c'est. Où l'a fabriqué, etc.
Généralement métiers qui mettent œuvre ces processus sont cloisonnées et des problématiques particulieres: diffusion large au public, signalement, etc.
Des préoccupations particulières fréquentes mais tout autant légitimes.
À la limite do qui ne semblent pas parler du même objet.

Pourtant tout intérêt à se concentrer sur mutualisations afin de se recentrer sur son cœur de métier.
Éliminer resaisie, améliorer gouvernance, écologiste son système.
Parle de bus informationnel
Objectifs de production qui peuvent rencontrer d'autres contraintes portées par d'autres interlocuteurs DSI, etc.

Diversité des pratiques qui se traduit par des données qui portent la marque des implicites métiers.
Modèles à plat qui rendent aussi mal compte de la complexité de nos objets. Exemple  manuscrit. Provoque interrogations des utilisateurs.

Besoin accès unifié par portail ou metamoteur
Navigation indifferentiée aux logiques de production.

Une réponse possible, essayer d'unifier l'accès aux ressources.
Exemple moteur collection mis en place par le ministère. Avantage d'abolir les silos. Mais aussi mis encore plus en évidence les défauts et les imperfection de la production en faisant exploser la redondance. Nombreuses notices références même objet, parfois œuvre, reproduction. Mise en évidence des erreurs. Et decontextualisation qui font que ne peut plus comprendre le implicites métiers qui soustendent la production.

En production un énorme effort de consolidation des données. Pour mutualiser. Vocabulaires, etc. Mais aucun effet en retour sur lanproduction.
Projet HADOC qui consiste à dire que si déporté l'effort en amont de la production, ne pourrait-on pas améliorer et la production et la diffusion.

Programme envisagé des 2005, lancé en 2008 harmonisation des données.
programme préconisation normes, bonnes pratiques, remplacement des outils de la chaîne de production qui est parfois obsolète.
Appuyer la production sur des normes.
faire évoluer les applications métiers pour que se branchent sur des services qui permettent d'acceder aux vocabulaires et aux référentiels.

Partager au maximum les structures de données
Normaliser les dates
Partager des nomenclatures simples
Avoir des formats de stockage fins qui permettent de multiples restitutions, et non pas penser le stockage en fonction de la restitution.

Harmoniser les contenus après avoir partagé les structures, c.est harmoniser les notions. Partager les vocabulaires scientifiques et techniques pour clarifier les notions et concepts utilisés par les uns et les autres. Exprimer par une sémantique commune, des réalités communes. Trouver des formalismes qui permettent de représenter cette notion d'événement qui est ici sous-jascente et de clarifier ce jeu de lien entre les dates et les auteurs.

Enfin identifier
Différentes formes de noms qui ne permettent ni à un automate ni à un humain de voir que la même notice. Ce qui génère de faux biens culturels. Parfois des données non fiables. Donc nécessaire d'identifier les choses. De même pour les auteurs afin de fédérer les différer les modèles de noms.

Dans le programme HADOC, le modèle de données HADOC élaboré par le groupe de travail qui a permi publication 2013 de ce premier modèle. opérationnel car utilisé pour exemple avec Marianne et Utilisé pour le hub informationnel du MUCEM.

En passe de convertir la base Merimée 150 000 objets
Modèle élaboré en UML car avant tout un modèle de gestion qui doit être implémenté en production. Dans toutes des applications va être exprimé en web sémantique car des le début fortement inspiré par les ontologies. Alignable sur cidoc-crm et frbroo de manière systématique.
Donc un modèle de production qui peut amener à une diffusion sur le web de données.

### les référentiels

Ontoterminologiques
Vocabulaires métiers beaucoup plus stricts comme autorités auteur

À considéré que constituait base de nos systèmes
Conçu un système
Webservice
Respectueux des standards et du w3c SKOS et isotest
Code ouvert
Pour la partie production
Un outil de gestion à côté duquel un outil de diffusion. Lui appuyé sur les technos du web sémantique. Triplestore. Sparql-endpoint que va déposer. Une chaîne de production.

Deuxième référentiel celui des acteurs
Un énorme pb
Incapables de naviguer dans les bases par la facette acteurs. Dommage car biens culturels important
Sur cela aidons-nous les uns les aures.
Une complémentarité évidente des données avec inha, et ailleurs. Avantage de parcours également pour le public.

Perspectives ouvertes par le web sémantiques
Possibilités ouvertes et possibilité de pousser les données dont dispose
Tout intérêt enrichir dépôts existants
Fait que dans un écosystème fait que ce type de projet devient réaliste et réalisable.

Est-il psosible de réconcilier les besoins de la production et de la diffusion. Résultats qui montre qu.un objectif atteignable
Possibilité de faciliter la production
Mettre en place services qui vont bien
Mais aussi améliorer la diffusion car granularité plus fine. Des modèles riches et explicites qui permettent maintenant un enrichissement en explicitant les relations et les associations. Dit ce que date, comment etc. De même quand localise ou pour les sources.

Des modèle beaucoup plus explicites et ontologisables. Possibilité de passer au web sémantique. Et mise en place politique d'identification.
À terme idée d'aller plus loin. Aller vers un référentiel des biens culturels.
Traduction sous forme de triplets RDF


Discussion
--------------

Question sur collaboration recherche et ministère de la culture

Francesco
Information historique nouvelle connaissance quel droit sur nouvelles connaissances qui peuvent être extraites.
Si s'oriente vers open data et gratuité de nos donner comment nous autofinancer.

Sur le premier cas d'élection information. Ne pense pas que soit protégeable par le droit auteur. Mois dernier décision tribunal instance sur édition manuscrit à partir de plusieurs sources, voit bien que travail de sélection et de choix et que plusieurs personnes différentes arriveraient à résultat différent, donc pas protégeable par le droit auteur. Si raisonne par analogie idem pour cas que vous évoquez idem. Si production de faits importants alors droit des bases de données.

Jurisprudence opposant Droz pour reproduction de manuscrits dans cd-rom.

Nombreux auteurs etc présents dans référentiels du ministère pas ailleurs

Michel
Question juridique. Si ppublications de donnnees sans restriction. Peut-on reconnaître plagiat si reprise ?

En fait peut renoncer tous les droits, mais en France ne peut pas abandonner son droit moral.
question déontologique différente du droit d'auteur

Francesco sur identification des acteurs, initialement s'était demandé si n'etait pas possible de collaborer avec les institutions qui produisent ces données, avaient vous envisagé d'impliquer les acteurs universitaires, pour penser ces référentiels sur un mode contributif.
En effet une des idées que l'on a d'entrer sur un mode collaboratif pour la production des données, pour que chacun apporte et puisse récupérer en retour une donnée correctement structurée, une maintenance, un identifiant.

Contribution à rameau qui se fait dans le cadre normal de la participation au Sudoc. Mais ce dont parlait un cas particulier où un référentiel précis et contribution.

