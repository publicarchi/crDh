# DH2024, 7 août 2024

## Tackling Misinformation: The Confluence of Platform Integrity & Data Journalism (Keynote)

Linda Ngari

Histoire du sport et son intersection avec la question des droits. Importance de pouvoir accéder aux données des grandes entreprises, nombreux échanges sur RSN.

Travail sur l’écosystème information, questionnant désinformation et misinformation ou malinformation. Nombreuses personnes impliquées dans ces processus parfois sans le savoir. Peuvent être circulées par des personnes qui ont envie de causer du mal mais pas seulement.

Intersection des platerformes et du journalisme très importante. Important que les grandes entreprises ouvrent leur données pour comprendre ce qui se passe sur ces plateformes. Causes potentielles de domage, implicatons en santé, mobilisation ou implications financières.

Présentation de discours de haine au Kenya dans le contecte des élections. // avec campagne américaine.

Professionnalisation de la désinformation. Développement rapide de cette professionnalisation. UD 60M dépensé par des acteurs étatiques. Nombreux pays où preuves de manipulation.

Mobilisation d’acteurs à travers des plateformes numériques (cross-platforme) pour se coordonner. 15 comptes postant sur le même sujet pendant 2h.

Usage malicieux de l’IA. Principalement utilisé pour impersonnification (journalistes, ou figures fictives). Utilisation point de vue autoritaire pour communiquer point de vus pro-hamas. Production de contenus de masse. Nombreux sites qui prétendent présenter informations normales, mais contiennent aussi misinformations.

Question de savoir qui doit formuler ce mandat.

## Unpacking the Power of Language: From Science and History to Ethics and Culture

### Tracing the Genealogies of Darwinian Ideas with LLM embeddings

Lucian Li

*I propose a method to detect similar ideas across a large text corpus using embeddings to capture semantic meaning and argumentative structure. I create a corpus of 100,000 nonfiction academic books from the 19th century and trace genealogies of ideas found in Darwin's publications.*

Travail sur le texte et standards de citation. 19e std moins précis et rigoureux. Souvent solutions que seuls les experts peuvent résoudre. Influence croisée selon les domaines culturels.

Exemple référence Darwinienne. Auetur qui débouche sur même interprétation. Nombreux exemples restent encore inconnus ou non étudiés.

Plusieurs approches : Topic Model, Word embedding, Text reuse focus sur discours précis mais pb avec OCR. Pb des arguments indirects.

Objectif repérer influence intellectuelle sans métadonnées bibliométriques. Comment obtenir ce type de travail sur OCR.

Sources de données NER pour extraction auteurs journaux et coprus revues sociétés savantes 1800-1900 Internet archive. Communautés disciplinaires larges.

19th century non fiction. 300 000 personnes repérées.

GTE Embedding, BERT based model, entrainé avec contrastive learning on entailment, web datasets, question answerring.

Generally ouperfomr BERT, BPT embedding...

Création représentation verctoriennes.

Recherche efficace pairs of similair statement utilisant veector Indexing FAISS.

Use cas Darwin pour définir métho

Peut envisager résultat comme édition contextualisée : peut repérer intertextualisé, et réemplois. Paires de travaux publiés avant et plus tard. Voir comment arguments de Darwin reservis ou diffèrent.

Chaque claim situé dans une chrontologie. Se souvenir que ne peut pas avoir vue complète. Dépend corpus et pas possible de déterminer exactement quand idée introduite.

Pre/post publication similarity trends.

Tjrs shift majeur après publication.

% livres publiés après ... niveaux de match. Plus de similarité quand auteurs avec qui proximité personnelle.

Même quand réduit seuil de similarité, même pattern repérable. (matrice de chaleur)

Donne confiance dans pertinence approche développée.

En agrégant past and future influence, voir comment chq claims selon les domaines disciplinaires. (diagramme de flux)

Co-citations network of Royal Society author (analyse de réseau)

Au lieu de considérer chaque œuvre comme produit individuel. Approche qui peut permettre aux académiques de mieux comprendre influences, etc. Espère que méthodologie permettra de découvrir des influences non repérées. Populations marginalisées, ect.

Article : https://arxiv.org/abs/2402.01661

### Commoning Biomedicine: An application of LLM technology to support historians of science

Pascal Belouin, Hassan El-Hajj, Alfred Freeborn

*The Commoning Biomedicine project aims to improve accessibility to a number of heterogenous oral history collections in biomedicine.*

*Integrating Large Language Model technology to our platform allowed us to improve metadata extraction and transcript summarization processes. Our talk will discuss the benefits of this approach and the challenges we faced.*

### La retorica dei Large Language Models: questioni etiche

Daniel Raffini

*L’intervento analizza in prospettiva etica la reotrica dei testi prodotti tramite LLMs. Si prenderanno in considerazione due aspetti: la simulazione dell'agency umana, che stimola una reazione empatica ingannevole, e l’utilizzo discriminatorio della lingua. L’analisi retorica mira ad affiancare l’etica dell’AI, fornendo uno strumento per intervenire sui sistemi.*

Collections d’histoire orale. Développement d’une plateforme pour aider les chercheurs à explorer des questions à partir enregistrement histoire orale.

Complications liées aux droits mais aussi aux formats et métadonnées. 

Commoning Biomedecine ComBio Platform

Présentation 600 entrées, développement d’un schème de métadonnées communs et interface de consultation.

LLM pour extraction de métadonnées des transcript. LLM avec grande fenêtre capturent meilleurs contextes compris dans le texte. 

Architecture : Scrapy Python librairie pour scrapper données (Scrapy), Backend Django

Metata extractor et Summarizer utilisant des longues chaines. Interaction avec OpenAI GPT 3.5. Composant utilisateur et interface administration.

Besoin d’une structure de méatdonnées unifiée. Développée de manière organique, type de médias, et éléments communs. JSON Schema Format pour standardiser données et validation.

Performance modèle ouverts pas très bonnes. Choix GPT propriétaire.

Transcripts de taille très variable --> impliquait approche flexible. Travail sur les prompts pour résumer avec MAP_REDUCE. Tokens limits cruciale pour déterminer les méthodes de résumés appropriées en fonction taille des textes.

https://combio.mpiwg-berlin.mpg.de

Discussion : question sur les erreurs de GPT.

Réalisation ensemble d’essais pour mesurer. Après plusieurs essais s’avérait réellement bon. Très surpris. Entre GPT 3.5 et 4, question de coûts. Mais avec 3.5 résumé de 600 enregistrements coûté seulement 30 euros !

### La retorica dei Large Language Models : Questioni etiche

Daniel Faffini, Sapienza

Un travail qui débute seulement 

AI et langage, test de Turing fondé sur usage langage. 

Darmounth proposal également comment utiliser les machines, importance du langage claire dès le début, comment un ordinateur peut être programmé pour utiliser le langage. Spécule qu’une grande partie de l’intelligence humaine liée au langage.

Cf. Monde philosophique contemporain, ex. Ludwig Wittgenstein qui le plus clairement sans doute a établi le lien entre la représentation de la réalité et du langage. Le monde est fait de langage.

3 ans plus tard, ce qu’écrivent finalement les scientifiques de Darmouth. Un arrière-plan philosophique.

Dans les années 70, NLP domaine qui débouche sur IA. Compréhension des règles de la syntaxe de la langage. Dernière étape de ce processus LLM en raison de leur grande adoption dans la vie de tous les jours.

Atlas Of AI Kate Crawford

The Ethics of Articical Intelligence, Luciano Fioridi

Liens entre éthique et rhétorique qui m’intéresse particulièrement ici. Car ensemble des questions éthiques écrites par des discours.

McKee H. Porter, Ethics for AI Writing : « What do humans need to know and what do machines need to klnow to write to and for each – and, importantly [...] ». Éthique dans le langage, raison pour laquelle propose un modèle où agent écriture rédige histoire pour un lecteur mais dans un triple social context. Celui de l’agent et de données, celui du lecteur, et le contexte social.

Transparence sur la présence de la machine un principe éthique McKee & Porter

Pose question conception et autorship. Question de la construction du contenu rhétorique du contenu. Contrat éditorial que le texte un moyen pour l’auteur de véhiculer un message pour une audiance.

Exemple machine qui construit un égo, ou self. Exemple publié dans le Guardian.

### What’s in an entity? Exploring Nested Named Entity Recognition in the Historical Land Register of Basel (1400-1700)

Ismail Prada Ziegler, Bern

*The Historical Land Register of Basel contains information about property transactions from late medieval to early modern times. In this submission I report my findings applying machine learning techniques to extract nested named entities from this pre-modern German-language corpus.*

The historical Land Register of BAsel, 1400-1700

Structure typique, qui vend la maison, à qui et raisons vente. Peut identifier plusieurs entités. Parfois incorporées les unes dans les autres.

Workflow pour préparer les données HTR avec TRanskribus 3.4

Lat Named Entity Extraction

souvent modélisée tâche comme Sequence tagging or Token Classification

pour textes Allemands spécificités, peu de ressources disponibles s

Shibuya/Hovy 2020, Second-BSest strategy

Mais système mauvais pour annoter longs segments, génère nbx erreures 40%. Particulièrement problématique pour description des maisons.

Recursive Decoding, création d’un échantillon annotation pour chaque couche de texte. Nested annotations. Alors regard texte, si trouve entité, alors regarde jusqu’à ce que ne puisse plus en trouver.

Résultats relativement similaires pour certaines catégories comme villes ou NE proche. Mais grandes différences de performances pour la description des maisons.

Strict matching si un token absent false match.

Alors, est-ce que c’est utilisable ?

Déjà utilisé comme module de recommandation. Comme tjrs pour ML système fonctionne bien pour les choses que vot régulièrement. Chance d’avoir des documents très similaires. Mais quand choses plus complexes parfois ne fonctionne pas.

Tt dépend de votre question de recherche. La performance varie beaucoup entre des mentions spécifqiues. Besoin de bien savoir ce qui fonctionne bien ou pas.

Conclusion, Nested Named Entity Recognition sur HLRB similar data peut approetr bons résultats. Ssystème State of the art pas toujours aussi bon sur les données des textes autres.

Besoin être attentif à ces questions pour historien.

### Leveraging Large Language Models to Generate a Knowledge Graph for Italian Literary Texts

Cristian Santini

*This paper outlines a methodology for Knowledge Extraction from historical literary texts in Italian using a combination of Large Language Models and fine-tuned models for Relation Extraction. The research aims to offer a novel way to extract and represent entities and relations from literary manuscripts.*

Recherche sur Leopardi, nombreuses ressources numérisées.

Plusieurs approches dans le domaine de l’extraction des connaissances.

- sequence-to-sequence relation Extratcion Model
  - useful for end to end
  - based on Wikidata schema
  - souvent biais à l’égard relations simples (dates de naiss, lieu naiss)
- Zero or few-shor RE with LLM
  - mais pas de schéma fiable
  - prompt hallucination

Conrtibution évaluer instruction-tuned LLMs pour extratcion triplets sémantique de textes littéraire. Proposer un pipeline qui combine seq2seq models avec LLM. Encodage en TEI

Cas usage, semi-diplomatic edition 41 lettres autographes de Leopardi encodées en TEI. Facsimile disponibles.

Approchae conssite à traiter fichiers XML par script pour extraire métadonnées, auteur, titre et URI, représentation en CIDOC CRM puis pipeline extraction qui utilise différents outils extraction. Composant qui lie à entités Wikidata, pis troisième modèle sequence encoding.

Zero-shot RE avec ChatGPT --> requête.

Renvoie bien des triplets mais forme intermédiaire car doit exprimer en langage naturel. Pas possible utiliser efficacement.

Ce que fait récupérer triplet de GPT et renvoie à REBEL pour produire statement sous forme de phrase puis SPARQL pour importer action et propriétés logiques.

Mais pb. Filtering with SBERT car produisait des erreurs. Par exemple lieu de travail et lieu de mort. Utilisation sequence encodeur SBERT avec similarité possible de retirer statement inconsistants produits par ChatGPT.

Analyse erreurs. Baseline mREBEL qui est un moteur extraction... nb triplets extrait très faible 40, 4 corrects. 0.10, 18 unique reation. Avec ChatGPT trop de relations 662 triplets, 607 corrects, 0.92%, 400 unique relation.

Chat GPT + REBEL bien meilleur.

Avantages

Possible enrichir donnés synthétiques avec informations sémantiques issues de Wikidata. Haute fibabilité LLM même pour langue historique. Enhanced explainabiliy.

Limitation : vulnérable à des cascades d’erreur. Manque supervision humaine. Fiabilité limitée de LLM en raisons hallucinations.

Juste début. Fuet développer stratégie pour importer axiomes d’ontologies pour raisonner. Souhaite également améliorer le rafinage des triples. Inclure supervision humaine dans le processus. Utiliser KG pour supporter récupération augmented generation et autres tâhces. Q&R etc.

https://sntcristian.github.io/leopardi_kg/

## Perspectives and Challenges for Digital Humanities Centers and Laboratories

### Nucleus

Nucleus from Grassroots initiative to pillar...

10 years ago, Lausanne. Momentum mais réalité des DH plus compliquée au niveau institutionnel. Création Nucleus, hétérogénéité 

Bottom up, et faible organisation hiérachique.

Après deux ans, après que près d’une centaine de personnes aient rejoint le centre. Retour modèle ancien comme résultat de cette organisation organique.

Moins ambitieux. Pourquoi tâche supplémentaire si faible hiérarchie. Absence de reconnaissance.

Groupes qui peuvent émerger ou disparaître très rapidement. Mais organisation organique qui nous permet de répondre de manière rapide à des nouveaux besoins. Mais approches à long terme difficiles.

Hérite de missions de l’Université, ce qui apporte un budget mais pas suffisamment de personnel de recherche.

### India

Au départ 3 chercherus en littérature et mis sur la porte que nous étions un lab.

Création normale d’un lab partie de l’écosystème. Chaque professeur son laboratoire, l’affiche pour les financements, etc. Un vocabulaire que comprennent les financeurs. Peut-être le premier laboratoire de ce type en Inde.

Formations et cours.

Développement portail accès ouvert pour publication en Inde. Trois mandats différents.

2014 à l’époque, idée de mentorat. Réalisation petits projets, travailler avec des étudiants. Alors un appel pour établir des centres d’excellence du gouvernement. 2022 reçu financement pour créer le centre. Plus grand de ce genre en Inde.

Indian Institute of Technology IIT Indore. Jaya Prakash Narayan National Center of Excellence in the Humanities

Volumes édité sur littérature indienne. Anthologie multilingue

### Center versus periphery : digital humanities networks

Recherche centres francophones

### The Center among the Labs : Reimagining the Center Beyond Community Building

Kristen Mapes, kristenmapes.com/dh2024-center

Structure à Michigan State University. Actuellement travail pour repenser le rôle de notre centre.

Indigenous land Granted to university in Michigan. Déclaration territoriale. Nécessité de reconsidérer rapport au territoire et reconnaitre individu. cf. Native Land project.

What is a DH Center

- homme for projects Grant-funded
- Physical Space
- Host for events and trainning
- Distributor of funding
- Colaborative unit (within beyond the University)
- Network of pratictioners and labs

Peut être un réseau de laboratoires et de labs.

Ombrella organisation, constellation, etc.

- DHI Lab, Faculty project, Mesh, LEADR, DHLC, Digital Scholarship Lab.
- DH@MSU

Quid modèle communautaire. Comment faire pour que les membres le mette dans leur signature de courriel.

Amplifying the work of scholars at our institution

identifier les opportunités pour des partenariats

Advocate pour augmenter les ressources et infrastructure pour tt le monde

Un changement mental, penser stratégiquement.

### Discussion

Intéressant de voir même problèmes sortant sur les ressources, etc. Question UCLDH merveilleux centre jusqu’à ce qu’ait nouveau Dean. Quid management des personnes au-dessus de vous ? https://www.ucl.ac.uk/digital-humanities/

Catherine Filipatrick dir associate Dean.

Where are the students ?

Graz centre pour 20 ans. 1er août devenu un département en DH. Maintenant assis à la même table. Centres toujours temporaires en Autriche. Plutôt difficile d’établir un département cependant. Est-ce que cela change la fonction du centre ?

Digital studies in arts and humanities à MSU pour programme 1er cycle plutôt que Humanités numérique car ne parle pas forcément aux parents.

Institute ? Car graduate students. Burden on 1st cycle.

Nom centre d’excellence déjà donné dans l’appel à financement. 

Quand créée un centre nbx enjeux. Départ à la retraite, etc. Deux choses importantes pour nous : student engagement, car possible grande influence. 2e chose training. 

Pensez-vous vous réduire, ou créer un focus sur la manière dont ce genre de méthodes sont applicables au succès des étudiants. Modèle réussite étudiant.

## Storytelling

### Fashion calendar

Grant Mellon. Collections spéciales. Adoption d’une approche démocratique, pas un gate keeper.

https://fashioncalendar.fitnyc.edu

Mise à disposition des numérisations IIIF, recherche plein texte. Mais listing transformés en données qui donnent lieu à des modélisations.

Gros pb de OCR. Pas de reconnaissance par défaut des colomnes. Travail manuel beuacoup trop long. 

TRavail avec une entreprise de AI [Explor.ai](https://www.explor.ai) pour développer script Python d’extraction. 

Problème de réconciliation des noms des designers et des marques. Recherche devant pouvoir être réalisées faiclement pour trouver les événéemnts. 35 780 noms et varaiations dans les données. 16 variations pour Calvin Klein (C Klein, etc.), or utilisateur besoin de pouvoir travailler avec une recherche simple.

Utilisation de OpenRefine et Wikidata qui pour ce domaine était plus efficace que la LOC.

8621 nombres uniques (vs 35 000). 5 800 peu connus.

Géocodage des localisations

- inspiré de Navigating The Green Book Biran Foo NYPL Labs 2016.
- 36 045 lieux listés dans les données
- Pb lieux historiques et adresses non uniformes
- Google Geocoding API

Feminist Digital Humanities, Critical cataloging & Data Visualization. Identification des marques, modular tags qui peuvent être mêlés pour créer différents types de données.

Livre à paraître en septembre.

À l’avenir voudrait travailler extraction spectacles de modes.

### Smell and Emotion: Recognising Emotions in Smell-Related Artworks

Vishal Patoliya

*Emotions and smell are underrepresented in digital art history. In this exploratory work, we show that recognising emotions from smell-related artworks is technically feasible but has room for improvement. Using style transfer and hyperparameter optimization we achieve a minor performance boost and open up the field for future extensions.*

[Pattern Recognition Lab](https://lme.tf.fau.de)

Traditionnellement dans le domaine patrimoniale émotions rôle marginale. Extension des concepts. Domain gap challenge, lack of emotion recognition in artworks.

Réseaux traités sur les images réelles et pas les œuvres d’art essayé de dépasser cet écueil. Exemple Œuvre où femme sent une fleur.

Datasets : EMOTIC EMOTIon recognition in Context dataset. Photo naturelles avec individuls, identifiés sur leurs émotions perçues. Images tirées de Google, COCO and Ade20K.

éléments émotions, 26 catégories discrètes, 3 variables continues : valence, arousal, Dominance.

ODOR-emotion, image tirées de Odeuropa Challenge sur la reconnaissance d’objets olfactifs. Étiquetage sous ensemble et données de tests.

Utlisation d’une stratégie de transfert stylistique. Obtenir des images qui ressemblent aux images du dataset cibles.

WikiArt - Artwork Dataset. Œuvres de genre pas utilisées car pb lors du transfert.

Architecture : CNN modèle

- Person-specific information body (bounding box)
- scence context information (entire image)
- ResNet-18 et ResNet-50 encodeur architecture

Trois modules : extraction, feature extraction, fusion network

Expérimentation et résultats

Modèles qui performent peu sur corpus historiques. Mauvaise classification. Besoin améliorer le modèle.

- introduction de body features, accroître taille du cadrage
- scene context module : replace Places365 pretrained backbone

Résulats améliore résultats sur Emotic mais pas sur ODOR-e. Augmenter information sur la taille des personnes cadrage, accroît performance.

Avec transfert de style. Avec ResNet50 meilleurs résultats. Modèles avec plus grand nombre de couches meilleures performances. Mais pas d’amélioration significative des performances.

Stryle transfert qui introduit des pertes au niveau des aspects faciaux. Besoin de développer des méthodes qui assurent plus de consistance dans ce traitement.

Ccl

Tjs gap, performances doivent êrte accrues.

#### Discussion

Question sémiotique visuelle des visages selon périodes historiques.

Qu’apporte reconnaissance émotions disciplinairement.

## Human figure...

### Man as point figure, Human pose retrieval in Art History

Stéfanie Scheider, travaille en DAH depuis 2016. Munich.

*Stefanie Schneider is a scientific assistant at the LMU Munich. Trained as a statistician and computer scientist, she has been working in the digital humanities since 2016. Her research interests include digital art history, cultural analytics, digital film studies with a focus on genre theory, and research software engineering.*

Investigation computationnelle des postures humaines dans le domaine patrimoine culturel. Preuve de concept qui peuvent conduire à plusieurs investigations dans ce domaine. Ex. Crucifixion.

Plus attentions travail humanistes de la Renaissance sur la charge gestuelle. Abstraction du corps humain que retrouve dans différentes disciplines, anatomie, physique et arts. Schlemmer, Durer, etc. Nombreux aspects qui connectent travail moderne et ancien.

Utilisation de primitives géométriques : plans, points, lignes, etc. Utilisés depuis longtemps par les chercheurs en HAR

Human pose estimation

évaluation des points d’articulation du corps, importants pour représentation vectorielle des postures.

Pipeline, basée sur une stratégie top > down, d’abord détection de la figure avec bounding boxes, puis détection des points pour établir le squelette.

Calculer des features descriptor puis transformations en features visuels puis restituer représentation.

Perceptron, deux têtes première détection, seconde régression.

Pour étendre le matérial, utilsation approche investion images. Augmentation des données annotées par manipulations géométriques comme des rotation.

5 dataset utilisé, 3 avec gens. 

- Coco 2017 
- puis transfert de style pour émuler spécificités HA.
- People-Art Westlake et al 2016
- PoPART Schneider und Vollmer 2023

Evaluation Bounding Boxes. Petites quantité qui doivent être inclure dans le processus d’entraînement. 

Keypoints

Semisuperivise certain degrès mais People-Art et PopART bien mieux

Human pose retrieval

Tâche où retrouver puis classifier figures humaines.

Séparer le traitement du haut du corps et du bas. Toutes configurations transformées en un descripteur de posture.

Probabilistic embeddings. Réfléchir distance dans espace euclidien. Ensuite chaque embeding est classifié.

Construction d’une taxonomie à partir de iconclass. 110 subnotation. Génération embedding. 

Data

Précision et rappel. 

#### Discussion

Embedding meilleur représentation que point seulement. 

### Probing historical image contextes : Enhancing visual archive retreival through Computer vision

Regrette que visa bloqué pour des raisons administratives dans le contexte tensions US/Chine. Particulièrement domaine IA. Espère que parviendra à mieux se comprendre.

Challenges et opportunités dans l’analyse Print media Images.

Dissémination des stocks photos 20th cent print média. CHallange pour les chercheurs tracer circulation de ces images.

Case study Jinchaji Pictorial series, publication photographique importante pour Parti communiste 1942-1948.

Essayer entrer dans l’esprit de ces créateurs. Valeur informative de ces images. Utiliser compiter vision pour faire cela.

Pipeline pour retrouver images développée par son équipe. 

Plusieurs corpus

- collection photographique
- magazine normalisée, utilisation outil cropping pour segmenter
- trois modèles pour pouvoir comparer similarité source, etc.

Identifier pattern dans la circulation de ces matériaux pour découvrir pattern dans la circulation de ces contenus.

Computer vision instrumental pour contextualiser contenus. Repérer des recadrage dans les versions imprimées. Possibilité de voir circulation de ces photographies. Autre ex qui montre que image originale losque publiée accompagnée variété de textes, légendes, etc.

Computer vision nous aide à repérer des phénomènes informations manquantes. Parfois variante à travers publication qui peuvent révéler décisions éditoriales.

Ex. image attribuée à un photographe. Légende qui confrontée fact check, en réalité pas le bon photographe, de même pas le bon endroit.

Situation frontière, possible légendage fautif pour tromper l’ennemi.

Image recadrée en deux photographies pour reproduction. Liée massacre de civils. Preuve invasions.

Source qui contient aussi photographie paysans. Republications multiples.

Lin Du

*Lin Du is currently a Postdoctoral Fellow at the National University of Singapore. She recently received her PhD from the Department of Asian Languages and Cultures at UCLA. Her dissertation employed computer vision approaches to analyze Chinese photojournalism during the wartime period. She earned her MA and BA degrees from Harvard University and Peking University, respectively. Her most recent paper is "Probing Historical Image Contexts: Enhancing Visual Archive Retrieval through Computer Vision" published in JOCCH: https://dl.acm.org/doi/10.1145/3631129*

Cropping tool

Du, Lin, Brandon Le, et Edouardo Honig. 2024. « Probing Historical Image Contexts: Enhancing Visual Archive Retrieval through Computer Vision ». *J. Comput. Cult. Herit.* 16 (4): 84:1-84:17. doi:[10.1145/3631129](https://doi.org/10.1145/3631129).

Possibilité travailler généalogie processus impression.

### Etiquetado automatico de catalogos de exposiciones para la extraccion de caracteristicas y entidades

Maria Luis Diez Platas

Une présentation réalisée par une équipe multidisciplinaire. 

https://github.com/Complexexhibit-project ??

Une ontologie. Plusieurs processus réalisés. Série de catalogues, étiquetage pour obtenir série de documents qui pourront faire l’objet d’un étiquetage automatique.

Préparation du corpus d’entraînement

Corpus de 100 catalogues d’exposition. Étiquetage manuel. Vérification entre étiquetteur. 

Sélection des catalogues avec critère de diversité. Échantillon représentatif, et classification qui permet de décider à quel type de catalogue confronté pour déterminer le traitement.

PDf --> Texte plan --> nettoyage --> Etiquetage.

Création d’un guide d’étiquetage et reconnaissance des entités-nommées.

- artistes
- institutions, et rôle etc.

Extraction des caractéristiques. 

Diversité étiquetage. Ensemble que convertit en archive.

Procesos. Ensemble que va transformer en passant par un modèle à partir des données d’entraînement.

- expression régulière
- système apprentissage automatique
- modèle d’apprentissage profond

Pour apprentissage automatique besoin de contexte. Textes complexes.

Modèle de mémoire. Modèle de mémoire pour éliminer le pb de contexte.

Préparation des dates pour entraînement.

