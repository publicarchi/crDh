# LP 10 août 2017, [LP-19](https://www.conftool.pro/dh2017/index.php?page=browseSessions&form_session=351&presentations=show)

## From usability testing and text analysis to user-response criticism

Questions de recherches analyser les réponses à partir de HCI Usability-related tests, aller vers l’interprétation. Savoir si l’analyse de texte peut être procédurée depuis les réponses utilisateurs. Peut-on produire une typologie des moyens utilisés par les utilisateurs.

Textexture, TXM (Heiden) et TheySay un package pour l’analyse de sentiment Guest 2016

Interface pour l’édition de sources historiques, 17 tests, observateur et enregistrement des manipulations. Et questionnaire.

Texttexture où possible de présenter des réseaux sur le texte. Représentation des réponses à certaines des tâches.

## Dominique

Poussé l’analyse avec des approches supervisées avec RapidMiner

- Arbres décisions
- Naïves Bayes
- KNN
- Support vector machine
- DL

Voir si performaient mieux un texte. Méthode d’échantillonnage. 

Résultats évalués en rappel et précisions. résultats entre 85 et 96%

Machie en mesure 4,5 x sur 5 identifier si discours d’une galerie commerciale ou galerie autogérée.

Les approches prédictives fonctionnent bien. Faire un transfert dans les milieux d’art pour accompagner les publics.

## Discussion

quelle sélection des termes, sont-ils sélectionnés par les programmes ou par les humains.

Les algorithmes de topic modeling font ce travail là. Suite de mots et pourcentage de documents dans lesquels va retrouver ces thèmes.

à partir de ces mots, nous qui les avons regroupés sous étiquette générique plus compréhensible qu’une suite de mots comme celle-là.

Lena demande si seulement des expositions monographiques ? 

Aussi des expositions de groupes. Grande variance sur la longueur des textes.

Savoir si test d’autres méthodes que LDN mais fait partie des choses qu’aimerait faire par la suite car de fait ici un biais interprétatif. Aimerait pouvoir intégrer plus de rigueurs ici. Un des points faibles de cette approche, passage aux labels.

Pourquoi choix de diviser le corpus ? au départ un seul corpus. Les centres d’artistes autogérés. Par la suite essayé de comparer avec autre corpus.

Aurait été intéressant d’aller chercher les textes théoriques au Québec, car sans doute plus riche pour voir comment parle de l’art. Car ici plutôt dans les lieux de diffusion plutôt que de réflexion.

Topic modeling qui travaille plutôt sur les mots que les segments. Le vrai discours est dans les segments, ce qui est sous-jacent à ce vocable là, ce sont les discours. Savoir quelles sont les thèses qui sont en jeux. Or cela serait beaucoup plus riche que d’avoir des appréciation synthétique par les mots.

## Questions perso

comparer les termes associés à un artiste plutôt que par galerie

## Modeling creativity

Tracking long-term lexical change

Track creativity in 20th century. Un terme surprennament moderne qui émerge au 20e. Souvent lié à la création et co-création plutôt qu’à la phénoménologie.

Peu de mot ont autant de connotation positive que créativité. 

De quoi parle-t-on quand parle de créativité ? 

Ici le voir depuis distant-reading angle. Google Ngram viewer. Tendance comparable même si plus tôt. Savoir si ce mot nécessaire pour voir l’autre terme émerger. Savoir si un changement de langage ou un shift.

Explorer ce graph plus en détails. Pour ce faire accéder aux collections HathiTrust Research Center. 17M volumes. 5 270 M pages

Voir comment requêtes la collection d’après plusieurs facettes. Ratios mots par millions. Aller plus loin et comprendre comment on parle de créativité et pas seulement quand.

Topic modeling, idée du topic modeling essayer de faire émerger les concepts sous-jacent qui créent le savoir sur la page. 

ex. stephen king "The dog barked at the speedy automobile" "The puppy barked at the fast car." très proches mais abstraitement très différent.

Topic modeling essaye d’extraire les idées d‘un "topic". Deux sorties. Le model : la clef pour nous indiquer quelles mots groupés ensemble, et à quel point. Le document : une description de ces topics à partir des documents.

Ensemble algorithme associés avec un pipeline de préparation. 

Résultats 

Développé un workflow pour analyser créativité. Religion, Zoology, Nature. Au cours des deux derniers siècles voit tomber les topics de religion, zoology, nature. Inversement voir émerger des notions de publicité, créativité, etc.

Le langage de la créativité et biaisé temporairement. Savoir si l’usage change ou seulement augmente ? Volonté de couvrir de petits sujets pour identifier de réels motifs dans le langage.

Approche en trois étapes :

- purpose page-level sampling
- date- weighted training
- standardized

Pre-processing

- removing the most common word
- cutting off sparse end of voc
- remove less tropical POS (e.g. adverbs, closed class types)

Purposing Sampling

instead of looking for creativity topic in the broader languor we looked at the langage around the discussion of creativity. 2 millions de volumes concernés.

Pour contrer les biais temporels. Développement de Weighted Training Order.

- Early texts in training have an outsize influence on the topics that emerge.

- what if we we miss early topics that existing but disappears?

  ajustement par décade

Weight(deacade)= 1/ n(decade)

pour que autant de chance d’être rencontrés.

Honeypot topics

how likely is any given topic to have generated to a document ?

- you need to formalize this assumption for training

- usually equal ; however, uneven priors have been found to be robust for text (Wallach, moon, and McCallum 2009)

  bien sur vrai car equal topic distribution est une lousy assumption given what we know about a text

idée de créer des topics honeypots, pour attraper tous les mots inintéressants et les emporter dans le grand topic.

Prochaines étapes, comparer word forms : creativity et creative

using the honeypot assumption as first step of hypeparametrization

disambiguating keyword shifts from general language change

evaluation

